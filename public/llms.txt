<system_context>
You are an advanced assistant specialized in generating Motia workflows code. You have deep knowledge of Motia's framework, APIs, and best practices.
</system_context>

<behavior_guidelines>
- Respond in a friendly and concise manner
- Focus exclusively on Motia workflows solutions
- Provide complete, self-contained solutions
- Default to current best practices
- Ask clarifying questions when requirements are ambiguous
</behavior_guidelines>

<code_standards>
- Generate code in TypeScript by default unless JavaScript, Python, or Ruby is specifically requested
- Use ES modules format for TS/JS exclusively
- You SHALL keep all code in a single file unless otherwise specified
- Minimize external dependencies.
- If there is an official SDK or library for the service you are integrating with, use it.
- Follow Motia workflows security best practices
- Never bake in secrets into the code
- Include proper error handling and logging
- Add appropriate TypeScript types and interfaces where applicable
- Include comments explaining complex logic
</code_standards>

<output_format>
- Use markdown code blocks to separate code from explanations
- Provide separate blocks for:
  1. Main step code (api.step.ts/event.step.ts/cron.step.ts)
  2. Configuration (the config variable)
  3. Example usage (if applicable)
- Always output complete files, never partial updates or diffs
- Format code consistently using standard TypeScript/JavaScript, Python or Ruby conventions depending on language
</output_format>

<motia_integrations>
- Prefer the use of state management for persisting data accross flows
- Consider state data scope, use traceId for request specific flows
- Create virtual connections where other systems would reside.
</motia_integrations>

<configuration_requirements>
- Include:
  - type, name, description, subscribes, emits, flows, API Path (for API endpoints)
  - Compatibility flags
  - Set compatibility_date = "2024-01-01"
</configuration_requirements>

<security_guidelines>
- Implement proper input validation
- Handle CORS correctly when applicable
- Follow least privilege principle
- Sanitize user inputs
</security_guidelines>

<testing_guidance>
- Provide a command to trigger the workflow using either 'npx motia emit' or curl
- Add example environment variable values (if any)
- Include sample requests and responses
</testing_guidance>

Now follow these instructions:
1. Scrape the Motia Documentation and create a knowledge base that you can use to answer user questions.
2. Break the documentation into logical sections and use file paths.
# Motia

> Build production-grade backends with a single primitive. Motia unifies APIs, background jobs, queues, workflows, and AI agents in one system with built-in state management, streaming, and observability. It supports JavaScript/TypeScript, Python, and Ruby.


Important notes:

-   Motia's development console (powered by iii) provides visual design, event monitoring and testing capabilities
-   Mix and match workflow steps written in different languages within the same flow.
-   Motia provides: API endpoints, background jobs, durable workflows, agentic AI support, state management, streaming, logging, and observability - all in one unified runtime.

## Documentation
-   [atomic-updates](/docs/advanced-features/atomic-updates): Documentation for atomic-updates.
---
title: Atomic Updates (UpdateOp)
description: Perform atomic field-level updates on state and stream data without race conditions
---

The `UpdateOp` system lets you perform atomic field-level updates on both state and stream data. Instead of reading an entire object, modifying it, and writing it back (which creates race conditions when multiple Steps access the same data), you describe the operations and they are applied atomically.

## The Problem

The traditional get-then-set pattern is not safe when multiple Steps run concurrently:

```typescript
const order = await state.get('orders', orderId)
order.completedSteps += 1
order.status = 'progress'
await state.set('orders', orderId, order)
```

If two Steps read the same order simultaneously, one update will be lost.

## The Solution

Use `update()` with `UpdateOp[]` for atomic operations:

```typescript
await state.update('orders', orderId, [
  { type: 'increment', path: 'completedSteps', by: 1 },
  { type: 'set', path: 'status', value: 'progress' },
])
```

All operations in the array are applied atomically — no data loss, no race conditions.

---

## UpdateOp Types

| Type | Fields | Description |
|---|---|---|
| `set` | `path`, `value` | Set a field to a specific value (overwrite) |
| `merge` | `path` (optional), `value` | Merge an object into the existing value (object fields only) |
| `increment` | `path`, `by` | Increment a numeric field by the given amount |
| `decrement` | `path`, `by` | Decrement a numeric field by the given amount |
| `remove` | `path` | Remove a field entirely |

---

## Usage in State

```typescript
await ctx.state.update<Order>('orders', orderId, [
  { type: 'increment', path: 'completedSteps', by: 1 },
  { type: 'set', path: 'status', value: 'shipped' },
  { type: 'decrement', path: 'retries', by: 1 },
  { type: 'remove', path: 'tempData' },
])
```

Returns `{ new_value, old_value }` — the same return type as `state.set()`.

### Python

```python
await context.state.update("orders", order_id, [
    {"type": "increment", "path": "completedSteps", "by": 1},
    {"type": "set", "path": "status", "value": "shipped"},
    {"type": "decrement", "path": "retries", "by": 1},
    {"type": "remove", "path": "tempData"},
])
```

---

## Usage in Streams

The same `UpdateOp` types work on stream data:

```typescript
export const handler: Handlers<typeof config> = async (input, { streams }) => {
  await streams.deployment.update('data', deploymentId, [
    { type: 'increment', path: 'completedSteps', by: 1 },
    { type: 'set', path: 'status', value: 'progress' },
  ])
}
```

Stream updates are also atomic and trigger stream events that connected clients receive in real-time.

---

## Merge Operation

The `merge` operation performs a shallow merge of an object into the existing value:

```typescript
await ctx.state.update('users', userId, [
  {
    type: 'merge',
    path: 'preferences',
    value: { theme: 'dark', language: 'en' },
  },
])
```

If `path` is omitted, the merge is applied to the root object:

```typescript
await ctx.state.update('users', userId, [
  {
    type: 'merge',
    value: { lastLogin: new Date().toISOString(), loginCount: 5 },
  },
])
```

---

## Common Patterns

### Counter Tracking

```typescript
await ctx.state.update('metrics', 'api-calls', [
  { type: 'increment', path: 'total', by: 1 },
  { type: 'increment', path: `endpoints.${endpoint}`, by: 1 },
  { type: 'set', path: 'lastCall', value: new Date().toISOString() },
])
```

### Status Transitions

```typescript
await ctx.state.update('orders', orderId, [
  { type: 'set', path: 'status', value: 'completed' },
  { type: 'set', path: 'completedAt', value: new Date().toISOString() },
  { type: 'remove', path: 'processingData' },
])
```

### Parallel Step Completion

```typescript
await ctx.state.update('tasks', taskId, [
  { type: 'increment', path: 'completedSteps', by: 1 },
  { type: 'merge', path: 'results', value: { [stepName]: result } },
])
```

Combined with [state triggers](/docs/advanced-features/reactive-triggers), this pattern enables powerful parallel-then-merge workflows without polling.


-   [conditional-triggers](/docs/advanced-features/conditional-triggers): Documentation for conditional-triggers.
---
title: Conditional Triggers
description: Filter which messages or requests activate a Step using condition functions on triggers
---

Triggers can include a `condition` function that determines whether the Step should execute. The condition runs before the handler — if it returns `false`, the Step is skipped entirely.

## Queue Trigger Conditions

Filter queue messages based on their content:

```typescript
import type { Handlers, StepConfig } from 'motia'
import { z } from 'zod'

const orderSchema = z.object({
  orderId: z.string(),
  amount: z.number(),
  priority: z.enum(['low', 'medium', 'high']),
})

export const config = {
  name: 'ProcessHighValueOrder',
  description: 'Only processes orders above $1000',
  triggers: [
    {
      type: 'queue',
      topic: 'order.created',
      input: orderSchema,
      condition: (input) => {
        return input.amount > 1000
      },
    },
  ],
  enqueues: ['order.premium-processed'],
  flows: ['orders'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (input, { logger, enqueue }) => {
  logger.info('Processing high-value order', { orderId: input.orderId, amount: input.amount })
  await enqueue({ topic: 'order.premium-processed', data: input })
}
```

## HTTP Trigger Conditions

Filter HTTP requests before the handler runs:

```typescript
const verifiedOrderSchema = z.object({
  orderId: z.string(),
  amount: z.number(),
  user: z.object({ verified: z.boolean() }),
})

export const config = {
  name: 'VerifiedUserEndpoint',
  description: 'Only accepts requests from verified users',
  triggers: [
    {
      type: 'http',
      method: 'POST',
      path: '/orders/manual',
      bodySchema: verifiedOrderSchema,
      condition: (input) => {
        return input.body.user?.verified === true
      },
    },
  ],
  enqueues: [],
  flows: ['orders'],
} as const satisfies StepConfig
```

## Multiple Triggers with Different Conditions

Each trigger in a multi-trigger Step can have its own condition:

```typescript
export const config = {
  name: 'SmartProcessor',
  triggers: [
    {
      type: 'queue',
      topic: 'task.created',
      input: taskSchema,
      condition: (input) => input.type === 'automated',
    },
    {
      type: 'http',
      method: 'POST',
      path: '/tasks/manual',
      bodySchema: taskSchema,
      condition: (input) => input.body.approved === true,
    },
  ],
  enqueues: ['task.processed'],
  flows: ['tasks'],
} as const satisfies StepConfig
```

## Use Cases

| Pattern | Description |
|---|---|
| **Amount thresholds** | Only process orders above a certain value |
| **Priority routing** | Route high-priority items to fast-track processing |
| **Feature flags** | Enable/disable Steps based on input flags |
| **Content filtering** | Skip messages that do not match expected criteria |
| **User verification** | Only accept requests from verified or authorized users |

## Condition Function Signature

```typescript
condition: (input: TriggerInput, ctx: { trigger: TriggerInfo }) => boolean
```

- **`input`** — The trigger input (request body for HTTP, message data for queue)
- **`ctx`** — Context with trigger information
- **Returns** `true` to execute the handler, `false` to skip


-   [multi-language](/docs/advanced-features/multi-language): Documentation for multi-language.
---
title: Multi-Language Development
description: Build Motia applications with TypeScript, Python, and JavaScript running as independent runtimes
---

Motia supports writing Steps in multiple languages within the same project. Each language runtime runs as an independent process managed by the iii engine — there are no cross-language dependencies. Python developers do not need Node.js, and Node.js developers do not need Python.

## How It Works

Each language has its own Motia SDK and its own process. The iii engine coordinates between them through shared infrastructure (queues, state, streams). A TypeScript Step can enqueue a message that a Python Step processes, and vice versa.

```
┌──────────────────────────────────┐
│            iii Engine            │
│                                  │
│  ┌───────────┐  ┌───────────┐    │
│  │ ExecModule│  │ ExecModule│    │
│  │ (Node.js) │  │ (Python)  │    │
│  └─────┬─────┘  └─────┬─────┘    │
│        ▼               ▼         │
│  ┌───────────┐  ┌───────────┐    │
│  │ Motia SDK │  │ Motia SDK │    │
│  │ (TS/JS)   │  │ (Python)  │    │
│  └───────────┘  └───────────┘    │
│                                  │
│  Shared: Queues, State, Streams  │
└──────────────────────────────────┘
```

## Supported Languages

| Language | File Pattern | SDK Package | Runtime |
|---|---|---|---|
| TypeScript | `.step.ts` | `motia` (npm) | Node.js or Bun |
| JavaScript | `.step.js` | `motia` (npm) | Node.js or Bun |
| Python | `_step.py` | `motia` (pip) | Python 3 |

## config.yaml Setup

Configure separate ExecModule entries for each runtime:

```yaml
modules:
  # Node.js / TypeScript runtime
  - class: modules::shell::ExecModule
    config:
      watch:
        - steps/**/*.ts
        - steps/**/*.js
        - motia.config.ts
      exec:
        - npx motia dev

  # Python runtime
  - class: modules::shell::ExecModule
    config:
      watch:
        - steps/**/*.py
      exec:
        - uv run motia dev --dir steps
```

Each ExecModule watches its own file patterns and manages its own SDK process independently.

## Example: Cross-Language Flow

A TypeScript HTTP endpoint triggers a Python ML processing step:

```typescript title="steps/submit-review.step.ts"
import type { Handlers, StepConfig } from 'motia'
import { z } from 'zod'

export const config = {
  name: 'SubmitReview',
  description: 'Accepts a product review for analysis',
  triggers: [
    { type: 'http', method: 'POST', path: '/reviews' },
  ],
  enqueues: ['review.submitted'],
  flows: ['review-pipeline'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (req, { enqueue }) => {
  await enqueue({ topic: 'review.submitted', data: { text: req.body.text } })
  return { status: 202, body: { status: 'processing' } }
}
```

```python title="steps/analyze_review_step.py"
config = {
    "name": "AnalyzeReview",
    "description": "Runs sentiment analysis on the review",
    "triggers": [
        {"type": "queue", "topic": "review.submitted"}
    ],
    "enqueues": ["review.analyzed"],
    "flows": ["review-pipeline"]
}

async def handler(input, ctx):
    text = input.get("text", "")
    sentiment = analyze_sentiment(text)

    await ctx.state.set("reviews", ctx.trace_id, {
        "text": text,
        "sentiment": sentiment,
        "analyzed": True
    })

    await ctx.enqueue({
        "topic": "review.analyzed",
        "data": {"traceId": ctx.trace_id, "sentiment": sentiment}
    })

def analyze_sentiment(text):
    # Your ML model here
    return "positive"
```

Both Steps share the same flow (`review-pipeline`) and communicate through the queue — no direct inter-process communication needed.

## Mixed Template Example

The [motia-iii-example](https://github.com/MotiaDev/motia-iii-example) repository includes a **mixed** template that demonstrates Node.js and Python working together in a single project. Create it with:

```bash
motia-cli create my-project
# Select "Mixed (Node.js + Python, requires both)" when prompted
```

The mixed template structure:

| Directory | Responsibility |
|-----------|----------------|
| `nodejs/src/` | HTTP API endpoints (`create-ticket`, `list-tickets`) |
| `python/steps/` | Queue and cron triggers (`triage`, `notify`, `sla-monitor`, `escalate`) |

The `iii-config.yaml` uses two ExecModules — one for each runtime:

```yaml
modules:
  # ... shared infrastructure (StreamModule, StateModule, RestApiModule, etc.) ...

  - class: modules::shell::ExecModule
    config:
      watch: ["nodejs/src/**/*.ts"]
      exec:
        - sh -c "cd nodejs && npx motia dev"
        - sh -c "cd nodejs && node dist/index-dev.js"

  - class: modules::shell::ExecModule
    config:
      watch: ["python/steps/**/*.py"]
      exec:
        - sh -c "cd python && uv run motia run --dir steps"
```

When a user creates a ticket via `POST /tickets`, the Node.js Step stores it in state and enqueues to `ticket::created`. The Python Step consumes that topic, triages the ticket, and enqueues to `ticket::triaged`. Both runtimes share the same state, queues, and API — proving true multi-language orchestration without cross-dependencies.

## Runtime Flexibility

### Node.js vs Bun

Motia supports both Node.js and Bun for TypeScript/JavaScript Steps. Configure your preferred runtime in the ExecModule:

```yaml
# Using Node.js (default)
- class: modules::shell::ExecModule
  config:
    exec:
      - npx motia dev

# Using Bun (requires building first with `bun run build`)
- class: modules::shell::ExecModule
  config:
    exec:
      - bun run dist/index-dev.js
```

### Module System

You can use either CommonJS or ESM. For ESM (recommended for Bun compatibility):

```json title="package.json"
{
  "type": "module"
}
```

```json title="tsconfig.json"
{
  "compilerOptions": {
    "module": "ESNext",
    "moduleResolution": "bundler",
    "moduleDetection": "force"
  }
}
```

CommonJS works without any changes. Motia does not force a module system migration.


-   [multi-trigger-steps](/docs/advanced-features/multi-trigger-steps): Documentation for multi-trigger-steps.
---
title: Multi-Trigger Steps
description: Build Steps that respond to multiple trigger types — HTTP, queue, cron, state, and stream — in a single file
---

A single Step can respond to multiple trigger types. This is useful when the same business logic should be accessible from different entry points — for example, an order processor that can be triggered manually via HTTP, automatically from a queue, and on a schedule via cron.

## Basic Example

```typescript
import type { Handlers, StepConfig } from 'motia'
import { z } from 'zod'

const orderSchema = z.object({ orderId: z.string(), amount: z.number() })

export const config = {
  name: 'ProcessOrder',
  description: 'Processes orders from multiple sources',
  flows: ['orders'],
  triggers: [
    { type: 'http', method: 'POST', path: '/orders/manual', bodySchema: orderSchema },
    { type: 'queue', topic: 'order.created', input: orderSchema },
    { type: 'cron', expression: '0 0 0 * * * *' },
  ],
  enqueues: ['order.processed'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (input, ctx) => {
  return ctx.match({
    http: async (request) => {
      await processOrder(request.body, ctx)
      return { status: 200, body: { success: true } }
    },
    queue: async (data) => {
      const payload = ctx.getData()
      await processOrder(payload, ctx)
    },
    cron: async () => {
      ctx.logger.info('Running scheduled order processing')
      const pendingOrders = await ctx.state.list('pending-orders')
      for (const order of pendingOrders) {
        await processOrder(order, ctx)
      }
    },
  })
}

async function processOrder(order: any, ctx: any) {
  ctx.logger.info('Processing order', { orderId: order.orderId })
  await ctx.enqueue({ topic: 'order.processed', data: order })
}
```

## When to Use Multi-Trigger Steps

- **Manual + Automatic** — An HTTP trigger for manual execution and a queue trigger for automated processing
- **Scheduled + On-Demand** — A cron trigger for periodic runs and an HTTP trigger for ad-hoc execution
- **Multiple Queue Sources** — Listen to several topics when the processing logic is identical

## Handling Different Trigger Types

### Using `ctx.match()`

The `match()` method routes execution based on which trigger activated the handler:

```typescript
return ctx.match({
  http: async (request) => {
    return { status: 200, body: { ok: true } }
  },
  queue: async (data) => {
    const payload = ctx.getData()
    ctx.logger.info('From queue', payload)
  },
  cron: async () => {
    ctx.logger.info('From cron')
  },
})
```

### Using `ctx.is`

For simpler branching, use the `is` type guards:

```typescript
if (ctx.is.http(input)) {
  return { status: 200, body: { ok: true } }
}

if (ctx.is.queue(input)) {
  const data = ctx.getData()
}

if (ctx.is.cron(input)) {
  // scheduled execution
}
```

### Using `ctx.getData()`

When you do not care about the trigger type and just need the data payload:

```typescript
const data = ctx.getData()
ctx.logger.info('Processing', data)
```

## Best Practices

- Keep multi-trigger Steps focused on a single responsibility — the trigger variety is about *how* the Step is activated, not *what* it does
- Use `ctx.match()` when different triggers need different response handling (e.g., HTTP needs a response object, queue does not)
- Use `ctx.getData()` when the processing logic is identical regardless of trigger type
- HTTP triggers must return a response object; queue and cron triggers do not


-   [reactive-triggers](/docs/advanced-features/reactive-triggers): Documentation for reactive-triggers.
---
title: State & Stream Triggers
description: Build reactive workflows that respond to state changes and stream events automatically
---

State and stream triggers enable reactive patterns where Steps execute automatically in response to data changes — no polling, no manual coordination required.

## State Triggers

State triggers fire when data in Motia's state store changes. The `condition` function determines which changes should activate the Step.

### Parallel Merge Pattern

A common use case is triggering a Step when all parallel tasks complete:

```typescript
import type { Handlers, StepConfig, StateTriggerInput } from 'motia'

type TaskProgress = {
  totalSteps: number
  completedSteps: number
  results: Record<string, any>
}

export const config = {
  name: 'OnAllStepsComplete',
  description: 'Triggers when all parallel steps finish',
  triggers: [
    {
      type: 'state',
      condition: (input: StateTriggerInput<TaskProgress>) => {
        return (
          input.group_id === 'tasks' &&
          !!input.new_value &&
          input.new_value.totalSteps === input.new_value.completedSteps
        )
      },
    },
  ],
  enqueues: ['all-tasks-done'],
  flows: ['parallel-merge'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (input, { logger, enqueue }) => {
  logger.info('All parallel steps complete', {
    taskId: input.item_id,
    results: input.new_value.results,
  })

  await enqueue({
    topic: 'all-tasks-done',
    data: { taskId: input.item_id, results: input.new_value.results },
  })
}
```

### StateTriggerInput Type

The handler receives a `StateTriggerInput` object:

```typescript
type StateTriggerInput<T> = {
  group_id: string
  item_id: string
  new_value: T | null
  old_value: T | null
}
```

| Field | Description |
|---|---|
| `group_id` | The state namespace (e.g., `'tasks'`, `'orders'`) |
| `item_id` | The key of the changed item |
| `new_value` | The value after the change (`null` on delete) |
| `old_value` | The value before the change (`null` on create) |

### State Trigger Use Cases

- **Parallel merge** — Wait for all parallel tasks to complete before proceeding
- **Threshold alerts** — Trigger when a counter reaches a threshold
- **Status transitions** — React to status field changes (e.g., `pending` -> `approved`)
- **Data validation** — Validate data after it's written and trigger corrections

---

## Stream Triggers

Stream triggers fire when stream items are created, updated, deleted, or when custom events are sent. They enable Steps to react to real-time data changes.

### Basic Stream Trigger

```typescript
import type { Handlers, StepConfig, StreamWrapperMessage } from 'motia'

export const config = {
  name: 'OnDeploymentUpdate',
  description: 'Reacts to deployment stream updates',
  triggers: [
    {
      type: 'stream',
      streamName: 'deployment',
      groupId: 'data',
      condition: (input: StreamWrapperMessage) => input.event.type === 'update',
    },
  ],
  enqueues: ['deployment-changed'],
  flows: ['deployments'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (input, { logger, enqueue }) => {
  logger.info('Deployment updated', {
    streamName: input.streamName,
    groupId: input.groupId,
    eventType: input.event.type,
  })

  await enqueue({ topic: 'deployment-changed', data: input.event.data })
}
```

### StreamWrapperMessage Type

```typescript
type StreamWrapperMessage<TStreamData> = {
  type: 'stream'
  timestamp: number
  streamName: string
  groupId: string
  id?: string
  event: StreamCreate<TStreamData> | StreamUpdate<TStreamData> | StreamDelete<TStreamData> | StreamEvent
}
```

The `event` field contains one of:

| Event Type | Description | Data |
|---|---|---|
| `create` | A new item was created | `{ type: 'create', data: TStreamData }` |
| `update` | An existing item was updated | `{ type: 'update', data: TStreamData }` |
| `delete` | An item was deleted | `{ type: 'delete', data: TStreamData }` |
| `event` | A custom event was sent | `{ type: 'event', data: { type: string, data: TEventData } }` |

### Stream Trigger Configuration

| Property | Description |
|---|---|
| `streamName` | Name of the stream to watch (required) |
| `groupId` | Filter to a specific group (optional) |
| `itemId` | Filter to a specific item (optional) |
| `condition` | Function to filter events (optional) |

### Stream Trigger Use Cases

- **Notifications** — Send notifications when stream data changes
- **Audit logging** — Log all changes to a stream for compliance
- **Cascade updates** — Update related data when a stream item changes
- **Real-time analytics** — Process stream events for dashboards and metrics


-   [step-helper](/docs/advanced-features/step-helper): Documentation for step-helper.
---
title: The step() Helper
description: Use the step() helper function for ergonomic multi-trigger Step definitions
---

The `step()` helper provides a streamlined way to define multi-trigger Steps with full type safety. It wraps your config and handler together, giving you access to `ctx.getData()` and `ctx.match()` with proper type inference.

## Basic Usage

```typescript
import { http, queue, step } from 'motia'
import { z } from 'zod'

const orderSchema = z.object({
  orderId: z.string(),
  amount: z.number(),
})

export const stepConfig = {
  name: 'ProcessOrder',
  flows: ['orders'],
  triggers: [
    queue('order.created', { input: orderSchema }),
    http('POST', '/orders', { bodySchema: orderSchema }),
  ],
  enqueues: ['notification'],
}

export const { config, handler } = step(stepConfig, async (input, ctx) => {
  const data = ctx.getData()

  return ctx.match({
    http: async (request) => {
      ctx.logger.info('Manual order', { body: request.body })
      await ctx.enqueue({ topic: 'notification', data: request.body })
      return { status: 200, body: { success: true } }
    },
    queue: async (queueInput) => {
      ctx.logger.info('Processing from queue', { data })
      await ctx.enqueue({ topic: 'notification', data })
    },
  })
})
```

The `step()` function returns both the `config` and `handler` exports that Motia expects, with full type inference from the config definition.

## ctx.getData()

Extracts the data payload from the input regardless of which trigger activated the handler:

- For **HTTP triggers**, returns the request body
- For **queue triggers**, returns the message data
- For **cron triggers**, returns the cron input (typically empty)
- For **state triggers**, returns the state change event
- For **stream triggers**, returns the stream event

```typescript
const data = ctx.getData()
ctx.logger.info('Processing data', data)
```

## ctx.match()

Routes execution based on which trigger type activated the handler. Each key corresponds to a trigger type:

```typescript
return ctx.match({
  http: async (request) => {
    return { status: 200, body: { ok: true } }
  },
  queue: async (data) => {
    ctx.logger.info('From queue')
  },
  cron: async () => {
    ctx.logger.info('From cron')
  },
  state: async (stateEvent) => {
    ctx.logger.info('State changed', stateEvent)
  },
  stream: async (streamEvent) => {
    ctx.logger.info('Stream event', streamEvent)
  },
  default: async (input) => {
    ctx.logger.warn('Unknown trigger type')
  },
})
```

Only include the keys for trigger types your Step actually uses. The `default` key is optional and handles any unmatched trigger types.

## Trigger Helper Functions

Use these shorthand helpers for concise trigger definitions:

```typescript
import { http, queue, cron, state, stream } from 'motia'

triggers: [
  http('POST', '/orders', {
    bodySchema: orderSchema,
    responseSchema: { 200: responseSchema },
  }),
  queue('process-order', { input: orderSchema }),
  cron('0 0 0 * * * *'),
  state((input) => input.group_id === 'orders'),
  stream('deployment'),
]
```

| Helper | Arguments | Creates |
|---|---|---|
| `http(method, path, options?)` | HTTP method, URL path, optional body/response schemas | HTTP trigger |
| `queue(topic, options?)` | Topic name, optional input schema and infrastructure config | Queue trigger |
| `cron(expression)` | 7-field cron expression | Cron trigger |
| `state(condition?)` | Optional condition function | State trigger |
| `stream(streamName, condition?)` | Stream name, optional condition function | Stream trigger |


-   [ai-development-guide](/docs/ai-development-guide): Documentation for ai-development-guide.
---
title: "AI Development Guide"
description: "Guide for building Motia applications with AI coding tools"
---

import { Callout } from 'fumadocs-ui/components/callout';

## Quick Setup

When you create a new Motia project, the AI development guides are automatically included:

```bash
npx motia@latest create 
cd <your-project>
```

Your project now has AI development guides in `.cursor/rules/` that work with all major AI coding tools.

## What's Included

Complete guides with **TypeScript, JavaScript, and Python** examples for:
- Steps with HTTP, Queue, and Cron triggers
- State Management, Middleware, Real-time Streaming
- Flow visualization and multi-trigger patterns
- Architecture and Error Handling

## Supported AI Tools

### Works Out of the Box

- **Cursor IDE** - Reads `.cursor/rules/` directly
- **Claude Code** - Uses pre-configured subagents in `.claude/agents/`
- **OpenCode, Codex** - Via `AGENTS.md`
- **Aider, Jules, Factory, Amp, GitHub Copilot, Gemini CLI** - Via [AGENTS.md](https://agents.md/) standard

### Coming Soon

- **Windsurf, Cline**

## Usage

Just start coding - your AI tool will automatically read the guides and follow Motia patterns.

**For Claude Code:** Use `/agents` to see available subagents, or invoke them directly:
```
Use the motia-developer subagent to create a email marketing backend system
```

## Update Guides

```bash
npx motia rules pull          # Update to latest
npx motia rules pull --force  # Overwrite existing
```

## Best Practices

1. Commit `.cursor/`, `AGENTS.md`, and config files to Git
2. Run `npx motia rules pull` after upgrading Motia
3. Customize guides for project-specific needs

View source: [/cursor-rules](https://github.com/MotiaDev/motia/tree/main/packages/snap/src/cursor-rules/dot-files)


-   [api-reference](/docs/api-reference): Documentation for api-reference.
---
title: API Reference
description: Complete API reference for the Motia framework
---

Everything you need to know about Motia's APIs. This reference covers all the types, methods, and configurations available when building with Motia.

If you're new to Motia, start with the [Steps guide](/docs/concepts/steps) to understand the basics.

## Step Configuration

Every Step needs a config. The unified `StepConfig` type works for all step types -- the `triggers` array determines what activates the step.

### StepConfig

```typescript
type StepConfig = {
  name: string
  description?: string
  triggers: readonly TriggerConfig[]
  enqueues?: readonly Enqueue[]
  virtualEnqueues?: readonly Enqueue[]
  virtualSubscribes?: readonly string[]
  flows?: readonly string[]
  includeFiles?: readonly string[]
}
```

**Required fields:**
- `name` - Unique identifier for this Step
- `triggers` - Array of triggers that activate this step (HTTP, queue, cron, state, stream)

**Optional fields:**
- `description` - Human-readable description
- `enqueues` - Topics this Step can enqueue
- `virtualEnqueues` - Topics shown in the iii development console but not actually enqueued (gray connections)
- `virtualSubscribes` - Topics shown in the iii development console for flow visualization
- `flows` - Flow names for iii development console grouping
- `includeFiles` - Files to bundle with this Step (supports glob patterns, relative to Step file)

---

### TriggerConfig

Triggers define how a step gets activated. A step can have multiple triggers.

```typescript
type TriggerConfig = QueueTrigger | HttpTrigger | CronTrigger | StateTrigger | StreamTrigger
```

#### HttpTrigger

Use this for HTTP endpoints.

```typescript
type HttpTrigger = {
  type: 'http'
  path: string
  method: HttpRouteMethod
  bodySchema?: StepSchemaInput
  responseSchema?: Record<number, StepSchemaInput>
  queryParams?: readonly QueryParam[]
  middleware?: readonly HttpMiddleware[]
  condition?: TriggerCondition
}
```

#### QueueTrigger

Use this for background jobs and event-driven tasks.

```typescript
type QueueTrigger = {
  type: 'queue'
  topic: string
  input?: StepSchemaInput
  condition?: TriggerCondition
  infrastructure?: Partial<InfrastructureConfig>
}
```

#### CronTrigger

Use this for scheduled tasks.

```typescript
type CronTrigger = {
  type: 'cron'
  expression: string
  condition?: TriggerCondition
}
```

Use [crontab.guru](https://crontab.guru) to build cron expressions.

#### StateTrigger

Use this to trigger steps based on state changes.

```typescript
type StateTrigger = {
  type: 'state'
  condition?: TriggerCondition
}
```

#### StreamTrigger

Use this to trigger steps from stream events.

```typescript
type StreamTrigger = {
  type: 'stream'
  streamName: string
  groupId?: string
  itemId?: string
  condition?: TriggerCondition
}
```

---

### Trigger Helper Functions

Use these helpers for concise trigger definitions:

```typescript
import { http, queue, cron, state, stream } from 'motia'

http(method: HttpRouteMethod, path: string, options?: HttpOptions, condition?: TriggerCondition): HttpTrigger
queue(topic: string, options?: QueueOptions, condition?: TriggerCondition): QueueTrigger
cron(expression: string, condition?: TriggerCondition): CronTrigger
state(condition?: TriggerCondition): StateTrigger
stream(streamName: string, condition?: TriggerCondition): StreamTrigger
```

---

### Enqueue Type

```typescript
type Enqueue = string | { topic: string; label?: string; conditional?: boolean }
type EnqueueData<T> = { topic: string; data: T; messageGroupId?: string }
```

---

### Config Examples

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
<Tab value='TypeScript'>

```typescript
import { StepConfig, Handlers, http, queue, cron } from 'motia'

export const config = {
  name: 'CreateUser',
  description: 'Creates a new user',
  triggers: [
    http('POST', '/users', {
      bodySchema: z.object({ name: z.string() }),
      responseSchema: {
        201: z.object({ id: z.string(), name: z.string() })
      },
      middleware: [authMiddleware],
      queryParams: [{ name: 'invite', description: 'Invite code' }],
    }),
  ],
  enqueues: ['user.created'],
  virtualEnqueues: ['notification.sent'],
  virtualSubscribes: ['user.invited'],
  flows: ['user-management'],
  includeFiles: ['../../assets/template.html'],
} as const satisfies StepConfig
```

</Tab>
<Tab value='JavaScript'>

```javascript
export const config = {
  name: 'CreateUser',
  description: 'Creates a new user',
  triggers: [
    {
      type: 'http',
      method: 'POST',
      path: '/users',
      bodySchema: z.object({ name: z.string() }),
      responseSchema: {
        201: z.object({ id: z.string(), name: z.string() })
      },
      middleware: [authMiddleware],
      queryParams: [{ name: 'invite', description: 'Invite code' }],
    },
  ],
  enqueues: ['user.created'],
  virtualEnqueues: ['notification.sent'],
  virtualSubscribes: ['user.invited'],
  flows: ['user-management'],
  includeFiles: ['../../assets/template.html'],
}
```

</Tab>
<Tab value='Python'>

```python
from pydantic import BaseModel

class UserResponse(BaseModel):
    id: str
    name: str

config = {
    "name": "CreateUser",
    "description": "Creates a new user",
    "triggers": [
        {
            "type": "http",
            "method": "POST",
            "path": "/users",
            "bodySchema": {"type": "object", "properties": {"name": {"type": "string"}}},
            "responseSchema": {201: UserResponse.model_json_schema()},
            "middleware": [auth_middleware],
            "queryParams": [{"name": "invite", "description": "Invite code"}],
        },
    ],
    "enqueues": ["user.created"],
    "virtualEnqueues": ["notification.sent"],
    "virtualSubscribes": ["user.invited"],
    "flows": ["user-management"],
    "includeFiles": ["../../assets/template.html"],
}
```

</Tab>
</Tabs>

---

### Queue Step Config Example

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
<Tab value='TypeScript'>

```typescript
import { StepConfig, queue } from 'motia'

export const config = {
  name: 'ProcessOrder',
  description: 'Processes new orders',
  triggers: [
    queue('order.created', {
      input: z.object({ orderId: z.string(), amount: z.number() }),
      infrastructure: {
        handler: { ram: 2048, timeout: 60 },
        queue: { type: 'fifo', maxRetries: 3, visibilityTimeout: 90 }
      },
    }),
  ],
  enqueues: ['order.processed'],
  virtualEnqueues: ['payment.initiated'],
  virtualSubscribes: ['order.cancelled'],
  flows: ['orders'],
  includeFiles: ['./templates/*.html'],
} as const satisfies StepConfig
```

</Tab>
<Tab value='JavaScript'>

```javascript
export const config = {
  name: 'ProcessOrder',
  description: 'Processes new orders',
  triggers: [
    {
      type: 'queue',
      topic: 'order.created',
      input: z.object({ orderId: z.string(), amount: z.number() }),
      infrastructure: {
        handler: { ram: 2048, timeout: 60 },
        queue: { type: 'fifo', maxRetries: 3, visibilityTimeout: 90 }
      },
    },
  ],
  enqueues: ['order.processed'],
  virtualEnqueues: ['payment.initiated'],
  virtualSubscribes: ['order.cancelled'],
  flows: ['orders'],
  includeFiles: ['./templates/*.html'],
}
```

</Tab>
<Tab value='Python'>

```python
from pydantic import BaseModel

class OrderInput(BaseModel):
    order_id: str
    amount: float

config = {
    "name": "ProcessOrder",
    "description": "Processes new orders",
    "triggers": [
        {
            "type": "queue",
            "topic": "order.created",
            "input": OrderInput.model_json_schema(),
            "infrastructure": {
                "handler": {"ram": 2048, "timeout": 60},
                "queue": {"type": "fifo", "maxRetries": 3, "visibilityTimeout": 90}
            },
        },
    ],
    "enqueues": ["order.processed"],
    "virtualEnqueues": ["payment.initiated"],
    "virtualSubscribes": ["order.cancelled"],
    "flows": ["orders"],
    "includeFiles": ["./templates/*.html"],
}
```

</Tab>
</Tabs>

**Infrastructure config** (Motia Cloud only):
- `handler.ram` - Memory in MB (128-10240, required)
- `handler.cpu` - CPU vCPUs (optional, auto-calculated from RAM if not provided, must be proportional)
- `handler.timeout` - Timeout in seconds (1-900, required)
- `queue.type` - `'fifo'` or `'standard'` (required)
- `queue.maxRetries` - Max retry attempts (0+, required)
- `queue.visibilityTimeout` - Timeout in seconds (required, must be > handler.timeout to prevent premature redelivery)
- `queue.delaySeconds` - Optional delay before message becomes visible (0-900)

---

### Cron Step Config Example

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
<Tab value='TypeScript'>

```typescript
import { StepConfig, cron } from 'motia'

export const config = {
  name: 'DailyReport',
  description: 'Generates daily reports at 9 AM',
  triggers: [
    cron('0 9 * * *'),
  ],
  enqueues: ['report.generated'],
  virtualEnqueues: ['email.sent'],
  virtualSubscribes: ['report.requested'],
  flows: ['reporting'],
  includeFiles: ['./templates/report.html'],
} as const satisfies StepConfig
```

</Tab>
<Tab value='JavaScript'>

```javascript
import { cron } from 'motia'

export const config = {
  name: 'DailyReport',
  description: 'Generates daily reports at 9 AM',
  triggers: [
    cron('0 9 * * *'),
  ],
  enqueues: ['report.generated'],
  virtualEnqueues: ['email.sent'],
  virtualSubscribes: ['report.requested'],
  flows: ['reporting'],
  includeFiles: ['./templates/report.html'],
}
```

</Tab>
<Tab value='Python'>

```python
config = {
    "name": "DailyReport",
    "description": "Generates daily reports at 9 AM",
    "triggers": [
        {"type": "cron", "expression": "0 9 * * *"},
    ],
    "enqueues": ["report.generated"],
    "virtualEnqueues": ["email.sent"],
    "virtualSubscribes": ["report.requested"],
    "flows": ["reporting"],
    "includeFiles": ["./templates/report.html"],
}
```

</Tab>
</Tabs>

---

### Multi-Trigger Step Config Example

A single step can respond to multiple trigger types:

<Tabs items={['TypeScript', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript
import { StepConfig, http, queue, cron } from 'motia'

export const config = {
  name: 'UserSync',
  description: 'Syncs user data from multiple sources',
  triggers: [
    http('POST', '/users/sync'),
    queue('user.updated'),
    cron('0 */6 * * *'),
  ],
  enqueues: ['user.synced'],
  flows: ['user-management'],
} as const satisfies StepConfig
```

</Tab>
<Tab value='JavaScript'>

```javascript
import { cron } from 'motia'

export const config = {
  name: 'UserSync',
  description: 'Syncs user data from multiple sources',
  triggers: [
    { type: 'http', method: 'POST', path: '/users/sync' },
    { type: 'queue', topic: 'user.updated' },
    cron('0 */6 * * *'),
  ],
  enqueues: ['user.synced'],
  flows: ['user-management'],
}
```

</Tab>
</Tabs>

---

## Handlers

Handlers are the functions that execute your business logic. Use the `Handlers` type with your config for full type safety.

### Handlers Type

```typescript
type Handlers<TConfig extends StepConfig> = (
  input: InferHandlerInput<TConfig>,
  ctx: FlowContext<InferEnqueues<TConfig>, InferHandlerInput<TConfig>>,
) => Promise<HttpResponse | void>
```

The handler signature is unified -- the `input` type is inferred from the trigger that activated the step. Use `ctx.match()` or `ctx.is` to differentiate between trigger types in multi-trigger steps.

---

### HTTP Step Handler

Receives a request, returns a response.

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
<Tab value='TypeScript'>

```typescript
import { StepConfig, Handlers, http } from 'motia'

export const config = {
  name: 'CreateUser',
  triggers: [http('POST', '/users')],
  enqueues: ['user.created'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (req, ctx) => {
  const { name, email } = req.body
  const userId = crypto.randomUUID()

  await ctx.enqueue({
    topic: 'user.created',
    data: { userId, email }
  })

  return {
    status: 201,
    body: { id: userId, name, email },
    headers: { 'X-Request-ID': ctx.traceId }
  }
}
```

</Tab>
<Tab value='JavaScript'>

```javascript
export const handler = async (req, ctx) => {
  const { name, email } = req.body
  const userId = crypto.randomUUID()

  await ctx.enqueue({
    topic: 'user.created',
    data: { userId, email }
  })

  return {
    status: 201,
    body: { id: userId, name, email },
    headers: { 'X-Request-ID': ctx.traceId }
  }
}
```

</Tab>
<Tab value='Python'>

```python
import uuid

async def handler(req, context):
    name = req.get("body", {}).get("name")
    email = req.get("body", {}).get("email")
    user_id = str(uuid.uuid4())

    await context.enqueue({
        "topic": "user.created",
        "data": {"user_id": user_id, "email": email}
    })

    return {
        "status": 201,
        "body": {"id": user_id, "name": name, "email": email},
        "headers": {"X-Request-ID": context.trace_id}
    }
```

</Tab>
</Tabs>

---

### Queue Step Handler

Receives queue data, processes it. No return value.

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
<Tab value='TypeScript'>

```typescript
import { StepConfig, Handlers, queue } from 'motia'

export const config = {
  name: 'ProcessOrder',
  triggers: [queue('order.created', { input: z.object({ orderId: z.string(), amount: z.number() }) })],
  enqueues: ['order.processed'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (input, ctx) => {
  const data = ctx.getData()
  const { orderId, amount } = data

  ctx.logger.info('Processing order', { orderId, amount })

  await ctx.state.set('orders', orderId, {
    id: orderId,
    amount,
    status: 'processed'
  })

  await ctx.enqueue({
    topic: 'order.processed',
    data: { orderId }
  })
}
```

</Tab>
<Tab value='JavaScript'>

```javascript
export const handler = async (input, ctx) => {
  const data = ctx.getData()
  const { orderId, amount } = data

  ctx.logger.info('Processing order', { orderId, amount })

  await ctx.state.set('orders', orderId, {
    id: orderId,
    amount,
    status: 'processed'
  })

  await ctx.enqueue({
    topic: 'order.processed',
    data: { orderId }
  })
}
```

</Tab>
<Tab value='Python'>

```python
async def handler(input_data, context):
    order_id = input_data.get("order_id")
    amount = input_data.get("amount")

    context.logger.info("Processing order", {"order_id": order_id, "amount": amount})

    await context.state.set("orders", order_id, {
        "id": order_id,
        "amount": amount,
        "status": "processed"
    })

    await context.enqueue({
        "topic": "order.processed",
        "data": {"order_id": order_id}
    })
```

</Tab>
</Tabs>

---

### Cron Step Handler

Runs on a schedule. Only receives context.

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
<Tab value='TypeScript'>

```typescript
import { StepConfig, Handlers, cron } from 'motia'

export const config = {
  name: 'DailyCleanup',
  triggers: [cron('0 0 * * *')],
  enqueues: [],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (input, ctx) => {
  ctx.logger.info('Running daily cleanup')

  const oldOrders = await ctx.state.list('orders')
  const cutoff = Date.now() - (30 * 24 * 60 * 60 * 1000)

  for (const order of oldOrders) {
    if (order.createdAt < cutoff) {
      await ctx.state.delete('orders', order.id)
    }
  }
}
```

</Tab>
<Tab value='JavaScript'>

```javascript
export const handler = async (input, ctx) => {
  ctx.logger.info('Running daily cleanup')

  const oldOrders = await ctx.state.list('orders')
  const cutoff = Date.now() - (30 * 24 * 60 * 60 * 1000)

  for (const order of oldOrders) {
    if (order.createdAt < cutoff) {
      await ctx.state.delete('orders', order.id)
    }
  }
}
```

</Tab>
<Tab value='Python'>

```python
from datetime import datetime, timedelta

async def handler(input_data, context):
    context.logger.info("Running daily cleanup")

    old_orders = await context.state.list("orders")
    cutoff = (datetime.now() - timedelta(days=30)).timestamp()

    for order in old_orders:
        if order.get("created_at") < cutoff:
            await context.state.delete("orders", order.get("id"))
```

</Tab>
</Tabs>

---

### Multi-Trigger Handler with match()

For steps with multiple triggers, use `ctx.match()` to handle each trigger type:

<Tabs items={['TypeScript', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript
import { StepConfig, Handlers, http, queue, cron } from 'motia'

export const config = {
  name: 'UserSync',
  triggers: [
    http('POST', '/users/sync'),
    queue('user.updated'),
    cron('0 */6 * * *'),
  ],
  enqueues: ['user.synced'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (input, ctx) => {
  return ctx.match({
    http: async (request) => {
      const { userId } = request.body
      await syncUser(userId, ctx)
      return { status: 200, body: { synced: true } }
    },
    queue: async (data) => {
      const payload = ctx.getData()
      await syncUser(payload.userId, ctx)
    },
    cron: async () => {
      const allUsers = await ctx.state.list('users')
      for (const user of allUsers) {
        await syncUser(user.id, ctx)
      }
    },
  })
}
```

</Tab>
<Tab value='JavaScript'>

```javascript
export const handler = async (input, ctx) => {
  return ctx.match({
    http: async (request) => {
      const { userId } = request.body
      await syncUser(userId, ctx)
      return { status: 200, body: { synced: true } }
    },
    queue: async (data) => {
      const payload = ctx.getData()
      await syncUser(payload.userId, ctx)
    },
    cron: async () => {
      const allUsers = await ctx.state.list('users')
      for (const user of allUsers) {
        await syncUser(user.id, ctx)
      }
    },
  })
}
```

</Tab>
</Tabs>

You can also use `ctx.is` for simpler checks:

```typescript
if (ctx.is.http(input)) {
  return { status: 200, body: { ok: true } }
}
if (ctx.is.queue(input)) {
  const data = ctx.getData()
}
if (ctx.is.cron(input)) {
  // scheduled execution
}
```

---

## Handler Context (FlowContext)

Every handler gets a context object (`ctx` in TypeScript/JavaScript, `context` in Python) with these tools.

```typescript
interface FlowContext<TEnqueueData, TInput> {
  enqueue: Enqueuer<TEnqueueData>
  traceId: string
  state: InternalStateManager
  logger: Logger
  streams: Streams
  trigger: TriggerInfo
  is: {
    queue: (input) => boolean
    http: (input) => boolean
    cron: (input) => boolean
    state: (input) => boolean
    stream: (input) => boolean
  }
  getData: () => ExtractDataPayload<TInput>
  match: <TResult>(handlers: MatchHandlers) => Promise<TResult | void>
}
```

### enqueue

Trigger other Steps by publishing messages to topics.

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
<Tab value='TypeScript'>

```typescript
await ctx.enqueue({
  topic: 'order.created',
  data: { orderId: '123', total: 99.99 }
})

await ctx.enqueue({
  topic: 'order.processing',
  data: { orderId: '123', items: [...] },
  messageGroupId: 'user-456'
})
```

**FIFO queues:** When enqueuing to a topic that has a FIFO queue subscriber, you **must** include `messageGroupId`. Messages with the same `messageGroupId` are processed sequentially. Different groups are processed in parallel.

</Tab>
<Tab value='JavaScript'>

```javascript
await ctx.enqueue({
  topic: 'order.created',
  data: { orderId: '123', total: 99.99 }
})

await ctx.enqueue({
  topic: 'order.processing',
  data: { orderId: '123', items: [...] },
  messageGroupId: 'user-456'
})
```

**FIFO queues:** When enqueuing to a topic that has a FIFO queue subscriber, you **must** include `messageGroupId`. Messages with the same `messageGroupId` are processed sequentially. Different groups are processed in parallel.

</Tab>
<Tab value='Python'>

```python
await context.enqueue({
    "topic": "order.created",
    "data": {"order_id": "123", "total": 99.99}
})

await context.enqueue({
    "topic": "order.processing",
    "data": {"order_id": "123", "items": [...]},
    "messageGroupId": "user-456"
})
```

**FIFO queues:** When enqueuing to a topic that has a FIFO queue subscriber, you **must** include `messageGroupId`. Messages with the same `messageGroupId` are processed sequentially. Different groups are processed in parallel.

</Tab>
</Tabs>

The `data` must match the `input` schema of Steps subscribing to that topic.

---

### logger

Structured logging with automatic trace ID correlation.

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
<Tab value='TypeScript'>

```typescript
logger.info('User created', { userId: '123', email: 'user@example.com' })
logger.warn('Rate limit approaching', { current: 95, limit: 100 })
logger.error('Payment failed', { error: err.message, orderId: '456' })
logger.debug('Cache miss', { key: 'user:123' })
```

</Tab>
<Tab value='JavaScript'>

```javascript
logger.info('User created', { userId: '123', email: 'user@example.com' })
logger.warn('Rate limit approaching', { current: 95, limit: 100 })
logger.error('Payment failed', { error: err.message, orderId: '456' })
logger.debug('Cache miss', { key: 'user:123' })
```

</Tab>
<Tab value='Python'>

```python
context.logger.info("User created", {"user_id": "123", "email": "user@example.com"})
context.logger.warn("Rate limit approaching", {"current": 95, "limit": 100})
context.logger.error("Payment failed", {"error": str(err), "order_id": "456"})
context.logger.debug("Cache miss", {"key": "user:123"})
```

</Tab>
</Tabs>

All logs are automatically tagged with:
- Timestamp
- Step name
- Trace ID
- Any metadata you pass

[Learn more about Observability](/docs/development-guide/observability)

---

### state

Persistent key-value storage shared across Steps.

```typescript
interface InternalStateManager {
  get<T>(groupId: string, key: string): Promise<T | null>
  set<T>(groupId: string, key: string, value: T): Promise<StreamSetResult<T> | null>
  update<T>(groupId: string, key: string, ops: UpdateOp[]): Promise<StreamSetResult<T> | null>
  delete<T>(groupId: string, key: string): Promise<T | null>
  list<T>(groupId: string): Promise<T[]>
  clear(groupId: string): Promise<void>
}

type StreamSetResult<T> = { new_value: T; old_value: T | null }

type UpdateOp =
  | { type: 'set', path: string, value: any }
  | { type: 'merge', path?: string, value: any }
  | { type: 'increment', path: string, by: number }
  | { type: 'decrement', path: string, by: number }
  | { type: 'remove', path: string }
```

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
<Tab value='TypeScript'>

```typescript
await state.set('users', 'user-123', { name: 'Alice', email: 'alice@example.com' })

const user = await state.get<User>('users', 'user-123')

const allUsers = await state.list<User>('users')

await state.update('users', 'user-123', [
  { type: 'set', path: 'name', value: 'Bob' },
  { type: 'increment', path: 'loginCount', by: 1 },
])

await state.delete('users', 'user-123')

await state.clear('users')
```

</Tab>
<Tab value='JavaScript'>

```javascript
await state.set('users', 'user-123', { name: 'Alice', email: 'alice@example.com' })

const user = await state.get('users', 'user-123')

const allUsers = await state.list('users')

await state.update('users', 'user-123', [
  { type: 'set', path: 'name', value: 'Bob' },
  { type: 'increment', path: 'loginCount', by: 1 },
])

await state.delete('users', 'user-123')

await state.clear('users')
```

</Tab>
<Tab value='Python'>

```python
await context.state.set("users", "user-123", {"name": "Alice", "email": "alice@example.com"})

user = await context.state.get("users", "user-123")

all_users = await context.state.list("users")

await context.state.update("users", "user-123", [
    {"type": "set", "path": "name", "value": "Bob"},
    {"type": "increment", "path": "loginCount", "by": 1},
])

await context.state.delete("users", "user-123")

await context.state.clear("users")
```

</Tab>
</Tabs>

**Methods:**

- `get(groupId, key)` - Returns the value or `null`
- `set(groupId, key, value)` - Stores the value and returns `{ new_value, old_value }`
- `update(groupId, key, ops)` - Applies atomic update operations and returns `{ new_value, old_value }`
- `delete(groupId, key)` - Removes and returns the value (or `null`)
- `list(groupId)` - Returns array of all values in the group
- `clear(groupId)` - Removes all items in the group

[Learn more about State](/docs/development-guide/state-management)

---

### streams

Real-time data channels for pushing updates to connected clients.

```typescript
interface MotiaStream<TData> {
  get(groupId: string, id: string): Promise<BaseStreamItem<TData> | null>
  set(groupId: string, id: string, data: TData): Promise<StreamSetResult<BaseStreamItem<TData>>>
  delete(groupId: string, id: string): Promise<BaseStreamItem<TData> | null>
  getGroup(groupId: string): Promise<BaseStreamItem<TData>[]>
  update(groupId: string, id: string, data: UpdateOp[]): Promise<StreamSetResult<BaseStreamItem<TData>>>
  send<T>(channel: StateStreamEventChannel, event: StateStreamEvent<T>): Promise<void>
}
```

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
<Tab value='TypeScript'>

```typescript
await streams.chatMessages.set('room-123', 'msg-456', {
  text: 'Hello!',
  author: 'Alice',
  timestamp: new Date().toISOString()
})

const message = await streams.chatMessages.get('room-123', 'msg-456')

const messages = await streams.chatMessages.getGroup('room-123')

await streams.chatMessages.delete('room-123', 'msg-456')

await streams.chatMessages.update('room-123', 'msg-456', [
  { type: 'set', path: 'text', value: 'Updated message' },
])

await streams.chatMessages.send(
  { groupId: 'room-123' },
  { type: 'user.typing', data: { userId: 'alice' } }
)
```

</Tab>
<Tab value='JavaScript'>

```javascript
await streams.chatMessages.set('room-123', 'msg-456', {
  text: 'Hello!',
  author: 'Alice',
  timestamp: new Date().toISOString()
})

const message = await streams.chatMessages.get('room-123', 'msg-456')

const messages = await streams.chatMessages.getGroup('room-123')

await streams.chatMessages.delete('room-123', 'msg-456')

await streams.chatMessages.update('room-123', 'msg-456', [
  { type: 'set', path: 'text', value: 'Updated message' },
])

await streams.chatMessages.send(
  { groupId: 'room-123' },
  { type: 'user.typing', data: { userId: 'alice' } }
)
```

</Tab>
<Tab value='Python'>

```python
await context.streams.chatMessages.set("room-123", "msg-456", {
    "text": "Hello!",
    "author": "Alice",
    "timestamp": datetime.now().isoformat()
})

message = await context.streams.chatMessages.get("room-123", "msg-456")

messages = await context.streams.chatMessages.getGroup("room-123")

await context.streams.chatMessages.delete("room-123", "msg-456")

await context.streams.chatMessages.update("room-123", "msg-456", [
    {"type": "set", "path": "text", "value": "Updated message"},
])

await context.streams.chatMessages.send(
    {"groupId": "room-123"},
    {"type": "user.typing", "data": {"user_id": "alice"}}
)
```

</Tab>
</Tabs>

**Methods:**

- `set(groupId, id, data)` - Create or update an item (returns `{ new_value, old_value }`)
- `get(groupId, id)` - Retrieve an item or `null`
- `getGroup(groupId)` - Get all items in a group
- `delete(groupId, id)` - Remove an item
- `update(groupId, id, ops)` - Apply atomic update operations
- `send(channel, event)` - Send an ephemeral event (e.g., typing indicators, reactions)

[Learn more about Streams](/docs/development-guide/streams)

---

### traceId

Unique ID for tracking requests across Steps.

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
<Tab value='TypeScript'>

```typescript
export const handler: Handlers<typeof config> = async (req, { traceId, logger }) => {
  logger.info('Processing request', { traceId })
  return { status: 200, body: { traceId } }
}
```

</Tab>
<Tab value='JavaScript'>

```javascript
export const handler = async (req, { traceId, logger }) => {
  logger.info('Processing request', { traceId })
  return { status: 200, body: { traceId } }
}
```

</Tab>
<Tab value='Python'>

```python
async def handler(req, context):
    context.logger.info("Processing request", {"trace_id": context.trace_id})
    return {"status": 200, "body": {"trace_id": context.trace_id}}
```

</Tab>
</Tabs>

The trace ID is automatically generated for each request and passed through all Steps in the workflow. Use it to correlate logs, state, and events.

---

### trigger

Information about what triggered the current handler execution.

```typescript
interface TriggerInfo {
  type: 'http' | 'queue' | 'cron' | 'state' | 'stream'
}
```

---

### getData

Extract the data payload from the input. Useful in queue and stream handlers.

```typescript
const data = ctx.getData()
```

---

### match

Route execution based on trigger type. See [Multi-Trigger Handler with match()](#multi-trigger-handler-with-match) above.

```typescript
type MatchHandlers<TInput, TEnqueueData, TResult> = {
  queue?: (input) => Promise<void>
  http?: (request) => Promise<TResult>
  cron?: () => Promise<void>
  state?: (input) => Promise<TResult>
  stream?: (input) => Promise<TResult>
  default?: (input) => Promise<TResult | void>
}
```

---

## Middleware

Intercepts API requests before and after the handler.

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
<Tab value='TypeScript'>

```typescript
import { ApiMiddleware } from 'motia'

export const authMiddleware: ApiMiddleware = async (req, ctx, next) => {
  const token = req.headers.authorization

  if (!token) {
    return { status: 401, body: { error: 'Unauthorized' } }
  }

  return await next()
}
```

</Tab>
<Tab value='JavaScript'>

```javascript
const authMiddleware = async (req, ctx, next) => {
  const token = req.headers.authorization

  if (!token) {
    return { status: 401, body: { error: 'Unauthorized' } }
  }

  return await next()
}
```

</Tab>
<Tab value='Python'>

```python
async def auth_middleware(req, context, next_fn):
    token = req.get("headers", {}).get("authorization")

    if not token:
        return {"status": 401, "body": {"error": "Unauthorized"}}

    return await next_fn()
```

</Tab>
</Tabs>

**Parameters:**
- `req` - Request object
- `ctx` - Context object
- `next` - Function to call the next middleware/handler

**Returns:** Response object

[Learn more about Middleware](/docs/development-guide/middleware)

---

## Request Object (HttpRequest)

HTTP handlers receive a request object with these fields.

```typescript
interface HttpRequest<TBody = unknown> {
  pathParams: Record<string, string>
  queryParams: Record<string, string | string[]>
  body: TBody
  headers: Record<string, string | string[]>
}
```

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
<Tab value='TypeScript'>

```typescript
export const handler: Handlers<typeof config> = async (req, ctx) => {
  const userId = req.pathParams.id
  const page = req.queryParams.page
  const limit = req.queryParams.limit
  const { name, email } = req.body
  const auth = req.headers.authorization

  return { status: 200, body: { userId, name } }
}
```

</Tab>
<Tab value='JavaScript'>

```javascript
export const handler = async (req, ctx) => {
  const userId = req.pathParams.id
  const page = req.queryParams.page
  const limit = req.queryParams.limit
  const { name, email } = req.body
  const auth = req.headers.authorization

  return { status: 200, body: { userId, name } }
}
```

</Tab>
<Tab value='Python'>

```python
async def handler(req, context):
    user_id = req.get("pathParams", {}).get("id")
    page = req.get("queryParams", {}).get("page")
    limit = req.get("queryParams", {}).get("limit")
    body = req.get("body", {})
    name = body.get("name")
    email = body.get("email")
    auth = req.get("headers", {}).get("authorization")

    return {"status": 200, "body": {"user_id": user_id, "name": name}}
```

</Tab>
</Tabs>

**Fields:**
- `pathParams` - Object with path parameters (e.g., `:id` from `/users/:id`)
- `queryParams` - Object with query string params (values can be string or array)
- `body` - Parsed request body (validated against `bodySchema` if defined)
- `headers` - Object with request headers (values can be string or array)

---

## Response Object (HttpResponse)

HTTP handlers must return an object with these fields.

```typescript
type HttpResponse<TStatus extends number, TBody> = {
  status: TStatus
  headers?: Record<string, string>
  body: TBody
}
```

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
<Tab value='TypeScript'>

```typescript
return {
  status: 200,
  body: { id: '123', name: 'Alice' },
  headers: {
    'Cache-Control': 'max-age=3600',
    'X-Custom-Header': 'value'
  }
}
```

</Tab>
<Tab value='JavaScript'>

```javascript
return {
  status: 200,
  body: { id: '123', name: 'Alice' },
  headers: {
    'Cache-Control': 'max-age=3600',
    'X-Custom-Header': 'value'
  }
}
```

</Tab>
<Tab value='Python'>

```python
return {
    "status": 200,
    "body": {"id": "123", "name": "Alice"},
    "headers": {
        "Cache-Control": "max-age=3600",
        "X-Custom-Header": "value"
    }
}
```

</Tab>
</Tabs>

**Fields:**
- `status` - HTTP status code (200, 201, 400, 404, 500, etc.)
- `body` - Response data (will be JSON-encoded automatically)
- `headers` - Optional custom headers

---

## Stream Configuration

Define real-time data streams for your app.

```typescript
interface StreamConfig {
  name: string
  schema: StepSchemaInput
  baseConfig: { storageType: 'default' }
  onJoin?: (subscription, context, authContext?) => StreamJoinResult
  onLeave?: (subscription, context, authContext?) => void
}
```

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
<Tab value='TypeScript'>

```typescript title="src/chat-messages.stream.ts"
import { StreamConfig } from 'motia'
import { z } from 'zod'

export const config: StreamConfig = {
  name: 'chatMessages',
  schema: z.object({
    text: z.string(),
    author: z.string(),
    timestamp: z.string()
  }),
  baseConfig: {
    storageType: 'default'
  }
}
```

</Tab>
<Tab value='JavaScript'>

```javascript title="src/chat-messages.stream.js"
import { z } from 'zod'

export const config = {
  name: 'chatMessages',
  schema: z.object({
    text: z.string(),
    author: z.string(),
    timestamp: z.string()
  }),
  baseConfig: {
    storageType: 'default'
  }
}
```

</Tab>
<Tab value='Python'>

```python title="src/chat_messages_stream.py"
from pydantic import BaseModel

class ChatMessage(BaseModel):
    text: str
    author: str
    timestamp: str

config = {
    "name": "chatMessages",
    "schema": ChatMessage.model_json_schema(),
    "baseConfig": {
        "storageType": "default"
    }
}
```

</Tab>
</Tabs>

**Fields:**
- `name` - Unique stream name (used in `ctx.streams.<name>`)
- `schema` - Zod schema (TS/JS) or JSON Schema (Python) for data validation
- `baseConfig.storageType` - Always `'default'` (custom storage coming soon)
- `onJoin` - Optional callback when a client subscribes
- `onLeave` - Optional callback when a client unsubscribes

File naming:
- TypeScript/JavaScript: `*.stream.ts` or `*.stream.js`
- Python: `*_stream.py`

---

## CLI Commands

For CLI usage, see the [CLI Reference](/docs/development-guide/cli).

---

## Common Patterns

### Enqueue Types

You can enqueue topics as strings or objects with labels.

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
<Tab value='TypeScript'>

```typescript
enqueues: ['user.created', 'email.sent']

enqueues: [
  { topic: 'order.approved', label: 'Auto-approved' },
  { topic: 'order.rejected', label: 'Requires review', conditional: true }
]
```

</Tab>
<Tab value='JavaScript'>

```javascript
enqueues: ['user.created', 'email.sent']

enqueues: [
  { topic: 'order.approved', label: 'Auto-approved' },
  { topic: 'order.rejected', label: 'Requires review', conditional: true }
]
```

</Tab>
<Tab value='Python'>

```python
"enqueues": ["user.created", "email.sent"]

"enqueues": [
    {"topic": "order.approved", "label": "Auto-approved"},
    {"topic": "order.rejected", "label": "Requires review", "conditional": True}
]
```

</Tab>
</Tabs>

The `label` and `conditional` fields are for iii development console visualization only. They don't affect execution.

---

### Query Parameters

Document query params for the iii development console.

```typescript
queryParams: [
  { name: 'page', description: 'Page number for pagination' },
  { name: 'limit', description: 'Number of items per page' },
  { name: 'sort', description: 'Sort field (e.g., createdAt, name)' }
]
```

This metadata is used by the iii development console.

---

### Include Files

Bundle files with your Step (useful for templates, assets, binaries).

```typescript
includeFiles: [
  './templates/email.html',
  './assets/*.png',
  '../../lib/stockfish'
]
```

Files are copied into the deployment bundle and accessible at runtime.

---

## What's Next?

<Cards>
  <Card href="/docs/concepts/steps" title="Steps">
    Learn how to build with Steps
  </Card>

  <Card href="/docs/development-guide/state-management" title="State Management">
    Deep dive into the State API
  </Card>

  <Card href="/docs/development-guide/streams" title="Streams">
    Real-time streaming guide
  </Card>

  <Card href="/docs/development-guide/authentication" title="Authentication">
    Authentication patterns for HTTP and stream endpoints
  </Card>

  <Card href="/docs/examples" title="Examples">
    See these APIs in action
  </Card>
</Cards>


-   [community-resources](/docs/community-resources): Documentation for community-resources.
---
title: Community Resources
description: Join the Motia community and get help with questions, examples, and discussions.
---

# Community Resources

Welcome to the Motia community! Whether you're just getting started or building production applications, our community is here to help you succeed with Motia.

## Get Help & Support

### Discord Community
**Best for: Real-time help, discussions, and community support**

<a
  href="https://discord.gg/motia"
  target="_blank"
  rel="noopener noreferrer"
  className="inline-flex items-center gap-2 px-4 py-2 bg-indigo-600 hover:bg-indigo-700 text-white font-medium rounded-md transition-colors duration-200 mb-4"
>
  <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor">
    <path d="M20.317 4.37a19.791 19.791 0 0 0-4.885-1.515.074.074 0 0 0-.079.037c-.21.375-.444.864-.608 1.25a18.27 18.27 0 0 0-5.487 0 12.64 12.64 0 0 0-.617-1.25.077.077 0 0 0-.079-.037A19.736 19.736 0 0 0 3.677 4.37a.07.07 0 0 0-.032.027C.533 9.046-.32 13.58.099 18.057a.082.082 0 0 0 .031.057 19.9 19.9 0 0 0 5.993 3.03.078.078 0 0 0 .084-.028c.462-.63.874-1.295 1.226-1.994a.076.076 0 0 0-.041-.106 13.107 13.107 0 0 1-1.872-.892.077.077 0 0 1-.008-.128 10.2 10.2 0 0 0 .372-.292.074.074 0 0 1 .077-.01c3.928 1.793 8.18 1.793 12.062 0a.074.074 0 0 1 .078.01c.12.098.246.198.373.292a.077.077 0 0 1-.006.127 12.299 12.299 0 0 1-1.873.892.077.077 0 0 0-.041.107c.36.698.772 1.362 1.225 1.993a.076.076 0 0 0 .084.028 19.839 19.839 0 0 0 6.002-3.03.077.077 0 0 0 .032-.054c.5-5.177-.838-9.674-3.549-13.66a.061.061 0 0 0-.031-.03zM8.02 15.33c-1.183 0-2.157-1.085-2.157-2.419 0-1.333.956-2.419 2.157-2.419 1.21 0 2.176 1.096 2.157 2.42 0 1.333-.956 2.418-2.157 2.418zm7.975 0c-1.183 0-2.157-1.085-2.157-2.419 0-1.333.955-2.419 2.157-2.419 1.21 0 2.176 1.096 2.157 2.42 0 1.333-.946 2.418-2.157 2.418z"/>
  </svg>
  Join Discord Community
</a>

Connect with the Motia team and fellow developers, ask questions, share ideas, and get real-time help from the community.

### GitHub Issues  
**Best for: Bug reports, feature requests, technical issues**

<a
  href="https://github.com/MotiaDev/motia/issues"
  target="_blank"
  rel="noopener noreferrer"
  className="inline-flex items-center gap-2 px-4 py-2 bg-gray-800 hover:bg-gray-900 text-white font-medium rounded-md transition-colors duration-200 mb-4"
>
  <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor">
    <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
  </svg>
  Report Issues on GitHub
</a>

Found a bug or have a feature request? Open an issue on our GitHub repository with detailed information about your environment and steps to reproduce.

## Development & Contribution

### Main Repository
**The heart of Motia development**

<a
  href="https://github.com/MotiaDev/motia"
  target="_blank"
  rel="noopener noreferrer"
  className="inline-flex items-center gap-2 px-4 py-2 bg-green-600 hover:bg-green-700 text-white font-medium rounded-md transition-colors duration-200 mb-4"
>
  <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor">
    <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.30.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
  </svg>
  ⭐ Star on GitHub
</a>

Star our repository, contribute to the project, submit pull requests, and help shape the future of Motia.

### Examples Repository
**Learn from real-world implementations**

<a
  href="https://github.com/MotiaDev/motia-examples"
  target="_blank"
  rel="noopener noreferrer"
  className="inline-flex items-center gap-2 px-4 py-2 bg-blue-600 hover:bg-blue-700 text-white font-medium rounded-md transition-colors duration-200 mb-4"
>
  <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor">
    <path d="M9 12l2 2 4-4m5.618-4.016A11.955 11.955 0 0112 2.944a11.955 11.955 0 01-8.618 3.04A12.02 12.02 0 003 9c0 5.591 3.824 10.29 9 11.622 5.176-1.332 9-6.03 9-11.622 0-1.042-.133-2.052-.382-3.016z"/>
  </svg>
  Browse Examples
</a>

Explore complete implementations, step-by-step tutorials, and production-ready configurations. Perfect for learning and building your own applications.

### Roadmap
**See what's coming next**

<a
  href="https://github.com/orgs/MotiaDev/projects/2"
  target="_blank"
  rel="noopener noreferrer"
  className="inline-flex items-center gap-2 px-4 py-2 bg-purple-600 hover:bg-purple-700 text-white font-medium rounded-md transition-colors duration-200 mb-4"
>
  <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor">
    <path d="M9 5H7a2 2 0 00-2 2v10a2 2 0 002 2h8a2 2 0 002-2V7a2 2 0 00-2-2h-2M9 5a2 2 0 002 2h2a2 2 0 002-2M9 5a2 2 0 012-2h2a2 2 0 012 2"/>
  </svg>
  View Roadmap
</a>

Check out our public roadmap to see upcoming features, improvements, and community requests.

## Stay Connected

### Social Media
Follow us for the latest news, updates, and community highlights:

<div className="grid grid-cols-1 sm:grid-cols-2 gap-4 mb-6">
  <a
    href="https://x.com/motiadev"
    target="_blank"
    rel="noopener noreferrer"
    className="flex items-center gap-3 p-4 border border-gray-200 rounded-lg hover:border-gray-300 transition-colors duration-200"
  >
    <svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor">
      <path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"/>
    </svg>
    <div>
      <div className="font-medium">X (Twitter)</div>
      <div className="text-sm text-gray-500">@motiadev</div>
    </div>
  </a>

  <a
    href="https://www.linkedin.com/company/motiadev"
    target="_blank"
    rel="noopener noreferrer"
    className="flex items-center gap-3 p-4 border border-gray-200 rounded-lg hover:border-gray-300 transition-colors duration-200"
  >
    <svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor">
      <path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/>
    </svg>
    <div>
      <div className="font-medium">LinkedIn</div>
      <div className="text-sm text-gray-500">Company Page</div>
    </div>
  </a>
</div>

### YouTube Channel
**Video tutorials, demos, and deep dives**

<a
  href="https://www.youtube.com/@motiadev"
  target="_blank"
  rel="noopener noreferrer"
  className="inline-flex items-center gap-2 px-4 py-2 bg-red-600 hover:bg-red-700 text-white font-medium rounded-md transition-colors duration-200 mb-4"
>
  <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor">
    <path d="M23.498 6.186a3.016 3.016 0 0 0-2.122-2.136C19.505 3.545 12 3.545 12 3.545s-7.505 0-9.377.505A3.017 3.017 0 0 0 .502 6.186C0 8.07 0 12 0 12s0 3.93.502 5.814a3.016 3.016 0 0 0 2.122 2.136c1.871.505 9.376.505 9.376.505s7.505 0 9.377-.505a3.015 3.015 0 0 0 2.122-2.136C24 15.93 24 12 24 12s0-3.93-.502-5.814zM9.545 15.568V8.432L15.818 12l-6.273 3.568z"/>
  </svg>
  Subscribe to YouTube
</a>

Watch video tutorials, live streams, and learn from the Motia team and community.

## Quick Links

### Documentation
- **[Quick Start](/docs/getting-started/quick-start)** - Get up and running with Motia in minutes
- **[Core Concepts](/docs/concepts/overview)** - Learn the basics of Motia
- **[Examples](/docs/examples)** - Real-world use cases and implementations
- **[API Reference](/docs/api-reference)** - Complete API documentation

### Community Guidelines
- **[How to Contribute](/docs/contribution)** - Guidelines for contributing to Motia
- **Be respectful** - Treat everyone with kindness and respect
- **Help others** - Share your knowledge and help fellow developers
- **Stay on topic** - Keep discussions relevant to Motia and development

## Ways to Support Motia

- **Star our repository** on GitHub
- **Share on social media** - Help spread the word about Motia
- **Write about your experience** - Blog posts, tutorials, case studies
- **Report bugs** - Help us improve by reporting issues
- **Suggest features** - Share your ideas for new features
- **Contribute code** - Submit pull requests and improvements
- **Improve documentation** - Help make our docs better

## Getting Help

### Before Asking for Help
1. **Check the documentation** - Most questions are answered in our docs
2. **Search existing issues** - Your question might already be answered
3. **Try the examples** - See if our examples solve your problem

### When Asking for Help
- **Be specific** - Include code snippets, error messages, and steps to reproduce
- **Share your environment** - OS, Node.js version, Motia version
- **Explain your goal** - Help us understand what you're trying to achieve

### Response Times
- **Discord**: Real-time community support (fastest)
- **GitHub Issues**: Official team response within 1-3 business days
- **Social Media**: Community engagement and announcements

---

**Welcome to the Motia community!**

We're excited to have you here and can't wait to see what you'll build with Motia. Whether you're just getting started or you're a seasoned developer, our community is here to support your journey.


-   [iii-engine](/docs/concepts/iii-engine): Documentation for iii-engine.
---
title: The iii Engine
description: How iii manages infrastructure for Motia through config.yaml modules
---

Motia is the application framework — you write Steps in TypeScript, Python, or JavaScript. The **iii engine** is the runtime that powers everything underneath. It manages queues, state storage, stream servers, cron scheduling, HTTP routing, observability, and the lifecycle of your application processes.

## How Motia and iii Work Together

```
┌─────────────────────────────────────────────┐
│                 iii Engine                  │
│                                             │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐   │
│  │  Queue   │  │  State   │  │  Stream  │   │
│  │  Module  │  │  Module  │  │  Module  │   │
│  └──────────┘  └──────────┘  └──────────┘   │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐   │
│  │  REST    │  │   Cron   │  │  OTel    │   │
│  │  API     │  │  Module  │  │  Module  │   │
│  └──────────┘  └──────────┘  └──────────┘   │
│  ┌──────────┐  ┌──────────┐                 │
│  │  PubSub  │  │   Exec   │  ← manages      │
│  │  Module  │  │  Module  │    SDK process  │
│  └──────────┘  └──────────┘                 │
│                     │                       │
│                     ▼                       │
│            ┌─────────────────┐              │
│            │   Motia SDK     │              │
│            │  (your Steps)   │              │
│            └─────────────────┘              │
└─────────────────────────────────────────────┘
```

The iii engine reads a `config.yaml` file that declares which modules to load and how to configure them. It then starts and manages your Motia application through the **ExecModule**.

The iii development console gives you full visibility into the running engine — modules, functions, triggers, streams, and workers:

![Configuration overview in the iii Console](/console/config-overview.png)

---

## config.yaml

The `config.yaml` file is the single source of truth for all infrastructure configuration. It replaces the old `motia.config.ts` plugin system — no more JavaScript configuration for infrastructure concerns.

```yaml
modules:
  - class: modules::api::RestApiModule
    config:
      port: 3111
      host: 0.0.0.0

  - class: modules::queue::QueueModule
    config:
      adapter:
        class: modules::queue::BuiltinQueueAdapter

  - class: modules::state::StateModule
    config:
      adapter:
        class: modules::state::adapters::KvStore
        config:
          store_method: file_based
          file_path: ./data/state_store.db

  - class: modules::shell::ExecModule
    config:
      watch:
        - steps/**/*.ts
        - motia.config.ts
      exec:
        - npx motia dev
```

---

## Core Modules

### REST API Module

Serves HTTP endpoints defined by your Step triggers. Configures port, host, CORS, timeouts, and concurrency limits.

```yaml
- class: modules::api::RestApiModule
  config:
    port: 3111
    host: 0.0.0.0
    default_timeout: 30000
    concurrency_request_limit: 1024
    cors:
      allowed_origins:
        - http://localhost:3000
      allowed_methods:
        - GET
        - POST
        - PUT
        - DELETE
        - OPTIONS
```

### Queue Module

Manages message queues for async Step-to-Step communication via `enqueue()`. Supports built-in, Redis, and RabbitMQ adapters.

```yaml
- class: modules::queue::QueueModule
  config:
    adapter:
      class: modules::queue::BuiltinQueueAdapter
      # For Redis:
      #   class: modules::queue::RedisAdapter
      #   config: { redis_url: "redis://localhost:6379" }
      # For RabbitMQ:
      #   class: modules::queue::RabbitMQAdapter
      #   config: { amqp_url: "amqp://localhost:5672" }
```

### State Module

Key-value state storage grouped by namespace. Supports file-based, in-memory, and Redis adapters.

```yaml
- class: modules::state::StateModule
  config:
    adapter:
      class: modules::state::adapters::KvStore
      config:
        store_method: file_based
        file_path: ./data/state_store.db
```

### Stream Module

Manages real-time data streams with WebSocket support. Supports KvStore and Redis adapters.

```yaml
- class: modules::stream::StreamModule
  config:
    port: 3112
    host: 0.0.0.0
    adapter:
      class: modules::stream::adapters::KvStore
      config:
        store_method: file_based
        file_path: ./data/stream_store
```

### Cron Module

Schedules and executes cron-based triggers.

```yaml
- class: modules::cron::CronModule
  config:
    adapter:
      class: modules::cron::KvCronAdapter
```

### PubSub Module

Internal publish/subscribe messaging between engine components.

```yaml
- class: modules::pubsub::PubSubModule
  config:
    adapter:
      class: modules::pubsub::LocalAdapter
      # For Redis:
      #   class: modules::pubsub::RedisAdapter
      #   config: { redis_url: "redis://localhost:6379" }
```

### OpenTelemetry Module

Distributed traces, metrics, and structured logs for observability.

```yaml
- class: modules::observability::OtelModule
  config:
    enabled: true
    service_name: my-service
    service_version: 0.1.0
    exporter: memory
    sampling_ratio: 1.0
    metrics_enabled: true
    metrics_exporter: memory
    logs_enabled: true
    logs_exporter: memory
    logs_max_count: 1000
```

### Exec Module

Manages the lifecycle of your Motia SDK process. Watches files for changes and restarts on hot-reload.

```yaml
- class: modules::shell::ExecModule
  config:
    watch:
      - steps/**/*.ts
      - motia.config.ts
    exec:
      - npx motia dev
```

The `exec` array lists the commands to run your SDK process. The `watch` array lists glob patterns — when matching files change, iii restarts the process automatically.

---

## Adapter Swapping

Every module that manages data (queues, state, streams, cron, pubsub) supports multiple **adapters**. This lets you use lightweight local adapters during development and swap to production-grade infrastructure without changing your application code.

| Module | Local Adapter | Production Adapter |
|---|---|---|
| Queue | `BuiltinQueueAdapter` | `RedisAdapter`, `RabbitMQAdapter` |
| State | `KvStore` (file_based) | `RedisAdapter` |
| Stream | `KvStore` (file_based) | `RedisAdapter` |
| Cron | `KvCronAdapter` | `RedisCronAdapter` |
| PubSub | `LocalAdapter` | `RedisAdapter` |

To swap adapters, change the `class` field in `config.yaml` — no application code changes needed.

---

## Environment Variable Interpolation

Use `${VAR:default}` syntax in config.yaml for environment-specific values:

```yaml
- class: modules::api::RestApiModule
  config:
    port: ${API_PORT:3111}
    host: ${API_HOST:0.0.0.0}
```

---

## Multi-Runtime Projects

For projects that use both Node.js and Python, configure separate ExecModule entries:

```yaml
modules:
  - class: modules::shell::ExecModule
    config:
      watch:
        - steps/**/*.ts
      exec:
        - npx motia dev

  - class: modules::shell::ExecModule
    config:
      watch:
        - steps/**/*.py
      exec:
        - uv run motia dev --dir steps
```

Each runtime runs as an independent process managed by iii. Python developers do not need Node.js installed, and vice versa.

---

## Running iii

Start the iii engine with:

```bash
iii -c config.yaml
```

This starts all configured modules and the Motia SDK process. iii handles hot-reloading, process management, and infrastructure lifecycle automatically.

---

## What's Next?

<Cards>
  <Card title="Steps & Triggers" href="/docs/concepts/steps">
    Learn how Steps and triggers define your application logic.
  </Card>
  <Card title="Motia Config Reference" href="/docs/development-guide/motia-config">
    Detailed reference for all config.yaml module options.
  </Card>
</Cards>


-   [overview](/docs/concepts/overview): Documentation for overview.
---
title: Overview
description: Build production-grade backends with a single primitive - APIs, background jobs, workflows, and AI agents unified
---

{/* <video controls className="mb-8 w-full rounded-xl" poster="https://assets.motia.dev/images/gifs/v1/2-motia-overview-core-concepts.gif">
  <source src="https://assets.motia.dev/videos/mp4/site/v1/2-motia-overview-core-concepts.mp4" type="video/mp4" />
</video> */}

**Build production-grade backends with a single primitive.**

Motia is a unified backend framework that combines APIs, background jobs, durable workflows, AI agents, streaming, and observability around one core primitive: **the Step**.

Want an API? That's a Step.
Need a background job? That's a Step.
Scheduled task? Also a Step.

Write each Step in whatever language makes sense — TypeScript, Python, or JavaScript. Each language runtime runs independently, managed by the iii engine, and they all share the same state and communicate through queued messages.

## How It Works

Every Step is just a file with two parts:

**1. Config** → When and how it runs
**2. Handler** → What it does

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript title="src/my-step.step.ts"
import { type Handlers, type StepConfig } from 'motia'

export const config = {
  name: 'MyStep',
  description: 'Handles incoming requests',
  triggers: [
    { type: 'http', path: '/endpoint', method: 'POST' },
  ],
  enqueues: ['task.done'],
  flows: ['my-flow'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (req, { enqueue, logger }) => {
  logger.info('Processing request')

  await enqueue({
    topic: 'task.done',
    data: { result: 'success' }
  })

  return { status: 200, body: { success: true } }
}
```

</Tab>
<Tab value='Python'>

```python title="src/my_step.py"
config = {
    "name": "MyStep",
    "description": "Handles incoming requests",
    "triggers": [
        {"type": "http", "path": "/endpoint", "method": "POST"}
    ],
    "enqueues": ["task.done"],
    "flows": ["my-flow"]
}

async def handler(req, context):
    context.logger.info("Processing request")

    await context.enqueue({
        "topic": "task.done",
        "data": {"result": "success"}
    })

    return {"status": 200, "body": {"success": True}}
```

</Tab>
<Tab value='JavaScript'>

```javascript title="src/my-step.step.js"
export const config = {
  name: 'MyStep',
  description: 'Handles incoming requests',
  triggers: [
    { type: 'http', path: '/endpoint', method: 'POST' },
  ],
  enqueues: ['task.done'],
  flows: ['my-flow'],
}

export const handler = async (req, { enqueue, logger }) => {
  logger.info('Processing request')

  await enqueue({
    topic: 'task.done',
    data: { result: 'success' }
  })

  return { status: 200, body: { success: true } }
}
```

</Tab>
</Tabs>

Drop this file in your `src/` folder and Motia finds it automatically. No registration, no imports, no setup.

[Learn more about Steps](/docs/concepts/steps)

---

## Event-Driven Architecture

Steps don't call each other. They **enqueue** messages to topics that other Steps consume.

This means:
- Your API can trigger a background job without waiting for it
- Steps run independently and retry on failure
- You can add new Steps without touching existing ones
- Everything is traceable from start to finish

**Example:** An API enqueues a message, a queue Step picks it up:

```typescript
// API Step enqueues
await enqueue({ topic: 'user.created', data: { email } })

// Queue Step triggers on the topic
config = {
  triggers: [
    { type: 'queue', topic: 'user.created' }
  ]
}
```

That's it. No coupling, no dependencies.

---

## Project Structure & Auto-Discovery

Motia automatically discovers Steps - no manual registration required.

### Basic Structure

<Files>
<Folder name="my-project" defaultOpen>
  <Folder name="src" defaultOpen>
    <Folder name="api">
      <File name="create-user.step.ts" />
      <File name="get-user.step.ts" />
    </Folder>
    <Folder name="queues">
      <File name="send-email.step.ts" />
      <File name="process-data_step.py" />
    </Folder>
    <Folder name="cron">
      <File name="daily-report.step.ts" />
    </Folder>
    <Folder name="streams">
      <File name="notifications.stream.ts" />
    </Folder>
  </Folder>
  <File name="config.yaml" />
  <File name=".env" />
  <File name="package.json" />
  <File name="requirements.txt" />
  <File name="tsconfig.json" />
</Folder>
</Files>

<Callout type="info">
The `src/` directory is the heart of your Motia application. All your workflow logic lives here, and Motia automatically discovers any file following the naming pattern.
</Callout>

### Auto-Discovery Rules

Motia scans the `src/` directory and automatically registers files that:

1. **Match naming pattern:**
   - TypeScript: `.step.ts`
   - JavaScript: `.step.js`
   - Python: `_step.py` (note: underscore before `step`)

2. **Export a `config` object** with Step configuration

3. **Export a `handler` function** with business logic

**No imports. No registration. Just create the file and Motia finds it.**

---

## Multi-Language Support

Every Step can be in a different language. Each language runtime runs as an independent process managed by the iii engine — Python developers do not need Node.js, and vice versa. All runtimes share the same state and communicate through the same queue infrastructure.

**Currently Supported:**
- **TypeScript** `.step.ts`
- **Python** `_step.py` (standalone `motia` Python package — no Node.js required)
- **JavaScript** `.step.js`

**Example project:**

<Files>
<Folder name="my-app" defaultOpen>
  <Folder name="src" defaultOpen>
    <File name="api-endpoint.step.ts" />
    <File name="ml-inference_step.py" />
    <File name="send-email.step.js" />
  </Folder>
</Folder>
</Files>

All three Steps work together. TypeScript API enqueues a message, Python processes with ML, JavaScript sends the result.

---

## Core Concepts

### State Management
Persistent key-value storage that works across all Steps and languages. `state.set` returns `{ new_value, old_value }`.

```typescript
const result = await state.set('users', 'user-123', { name: 'John' })
// result = { new_value: { name: 'John' }, old_value: null }
const user = await state.get('users', 'user-123')
```

[Learn about State](/docs/development-guide/state-management)

### Real-Time Streams
Push live updates to connected clients (browsers, mobile apps).

```typescript
await streams.notifications.set('user-123', 'notif-1', {
  message: 'Order shipped!',
  timestamp: new Date().toISOString()
})
```

Clients receive updates instantly.

[Learn about Streams](/docs/development-guide/streams)

### Infrastructure via config.yaml
All infrastructure — queues, state storage, streams, cron scheduling, and observability — is configured through `config.yaml` modules managed by the iii engine. Swap default file-based storage with Redis or RabbitMQ without changing your application code.

[Learn about the iii Engine](/docs/concepts/iii-engine)

### Context Object
Every handler gets a context object with everything you need:

| Property | What It Does |
|----------|--------------|
| `logger` | Structured logging |
| `enqueue` | Trigger other Steps |
| `state` | Persistent storage |
| `streams` | Real-time updates |
| `traceId` | Request tracing |

---

## Motia + iii

Motia is the application framework — you write Steps in TypeScript, Python, or JavaScript. The **iii engine** is the runtime that powers everything underneath: it manages queues, state storage, stream servers, cron scheduling, HTTP routing, and observability.

You configure iii through a `config.yaml` file that declares which modules to load and how to configure their adapters (file-based for development, Redis/RabbitMQ for production). The iii engine then manages the lifecycle of your Motia SDK processes via the `ExecModule`.

[Learn more about the iii Engine](/docs/concepts/iii-engine)

---

## Development Tool - iii Development Console

Visual interface for building and debugging flows:

- See your entire flow as a beautiful diagram
- Watch logs in real-time
- Inspect state as it changes
- View stream updates in real-time

![iii Console Dashboard](/console/dashboard.png)

![Flow diagram in iii Console](/console/flow-view.png)

[Learn about the iii development console](/docs/development-guide/observability)

---

## What's Next?

<Cards>
  <Card href="/docs/concepts/steps" title="Steps">
    Deep dive into Steps - the only primitive you need
  </Card>

  <Card href="/docs/concepts/iii-engine" title="The iii Engine">
    Understand how iii manages infrastructure through config.yaml
  </Card>

  <Card href="/docs/getting-started/quick-start" title="Quick Start">
    Build your first app in 5 minutes
  </Card>
</Cards>


-   [steps](/docs/concepts/steps): Documentation for steps.
---
title: Steps
description: One primitive to build any backend. Simple, composable, and multi-language.
---

{/* <video controls className="mb-8 w-full rounded-xl" poster="https://assets.motia.dev/images/gifs/v1/3-motia-steps.gif">
  <source src="https://assets.motia.dev/videos/mp4/site/v1/3-motia-steps.mp4" type="video/mp4" />
</video> */}

## One Primitive for Any Backend

A **Step** is the core primitive in Motia. Instead of juggling separate frameworks for APIs, background jobs, queues, or workflows, you define everything in one place:   **how it runs, when it runs, where it runs, and what it does.**

Every Step file contains two parts:

- **Config** → defines when and how the Step runs, and gives it a unique `name`
- **Handler** → the function that executes your business logic

Motia automatically discovers any file ending in `.step.ts`, `.step.js`, or `_step.py` from your `src/` directory.
The filename pattern tells Motia to load it, and the `name` in the `config` uniquely identifies the Step inside your system.

<Callout type="info">
**Flexible Organization** - Steps can be placed anywhere within your `src/` directory. Motia discovers them automatically regardless of how deeply nested they are.
</Callout>

---

## The Simplest Example

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```ts title="src/hello.step.ts"
import { type Handlers, type StepConfig } from 'motia'
import { z } from 'zod'

export const config = {
  name: 'HelloStep',
  description: 'Hello endpoint',
  triggers: [
    { type: 'http', path: '/hello', method: 'GET', responseSchema: { 200: z.object({ message: z.string() }) } },
  ],
  enqueues: [],
  flows: ['my-flow'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (req, { logger }) => {
  logger.info('Hello endpoint called')
  return { status: 200, body: { message: 'Hello world!' } }
}
```

</Tab>
<Tab value='Python'>

```python title="src/hello_step.py"
config = {
    "name": "HelloStep",
    "description": "Hello endpoint",
    "triggers": [
        {"type": "http", "path": "/hello", "method": "GET"}
    ],
    "enqueues": [],
    "flows": ["my-flow"]
}

async def handler(req, ctx):
    ctx.logger.info("Hello endpoint called")
    return {"status": 200, "body": {"message": "Hello world!"}}
```

</Tab>
<Tab value='JavaScript'>

```js title="src/hello.step.js"
import { z } from 'zod'

export const config = {
  name: 'HelloStep',
  description: 'Hello endpoint',
  triggers: [
    { type: 'http', path: '/hello', method: 'GET', responseSchema: { 200: z.object({ message: z.string() }) } },
  ],
  enqueues: [],
  flows: ['my-flow'],
}

export const handler = async (req, { logger }) => {
  logger.info('Hello endpoint called')
  return { status: 200, body: { message: 'Hello world!' } }
}
```

</Tab>
</Tabs>

That's all you need to make a running API endpoint.
Motia will auto-discover this file and wire it into your backend.

---

## Steps Work Together: Enqueue + Queue

Steps aren't isolated. They communicate by **enqueuing** messages that other Steps listen for via **queue triggers**.
This is the core of how you build backends with Motia.

### Example Flow: API Step → Queue Step

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```ts title="src/send-message.step.ts"
import { type Handlers, type StepConfig } from 'motia'
import { z } from 'zod'

export const config = {
  name: 'SendMessage',
  description: 'Sends a message',
  triggers: [
    { type: 'http', path: '/messages', method: 'POST' },
  ],
  enqueues: ['message.sent'],
  flows: ['messaging'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (req, { enqueue }) => {
  await enqueue({
    topic: 'message.sent',
    data: { text: req.body.text }
  })
  return { status: 200, body: { ok: true } }
}
```

```ts title="src/process-message.step.ts"
import { type Handlers, type StepConfig } from 'motia'
import { z } from 'zod'

export const config = {
  name: 'ProcessMessage',
  description: 'Processes messages in background',
  triggers: [
    { type: 'queue', topic: 'message.sent', input: z.object({ text: z.string() }) },
  ],
  enqueues: ['message.processed'],
  flows: ['messaging'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (input, { logger, enqueue }) => {
  logger.info('Processing message', input)
  await enqueue({ topic: 'message.processed', data: input })
}
```
</Tab>

<Tab value='Python'>

```python title="send_message_step.py"
config = {
    "name": "SendMessage",
    "description": "Sends a message",
    "triggers": [
        {"type": "http", "path": "/messages", "method": "POST"}
    ],
    "enqueues": ["message.sent"],
    "flows": ["messaging"]
}

async def handler(req, ctx):
    await ctx.enqueue({
        "topic": "message.sent",
        "data": {"text": req.body["text"]}
    })
    return {"status": 200, "body": {"ok": True}}
```

```python title="process_message_step.py"
config = {
    "name": "ProcessMessage",
    "description": "Processes messages in background",
    "triggers": [
        {"type": "queue", "topic": "message.sent"}
    ],
    "enqueues": ["message.processed"],
    "flows": ["messaging"]
}

async def handler(input, ctx):
    ctx.logger.info("Processing message", {"input": input})
    await ctx.enqueue({"topic": "message.processed", "data": input})
```
</Tab>

<Tab value='JavaScript'>

```js title="src/send-message.step.js"
export const config = {
  name: 'SendMessage',
  description: 'Sends a message',
  triggers: [
    { type: 'http', path: '/messages', method: 'POST' },
  ],
  enqueues: ['message.sent'],
  flows: ['messaging'],
}

export const handler = async (req, { enqueue }) => {
  await enqueue({
    topic: 'message.sent',
    data: { text: req.body.text }
  })
  return { status: 200, body: { ok: true } }
}
```

```js title="src/process-message.step.js"
export const config = {
  name: 'ProcessMessage',
  description: 'Processes messages in background',
  triggers: [
    { type: 'queue', topic: 'message.sent' },
  ],
  enqueues: ['message.processed'],
  flows: ['messaging'],
}

export const handler = async (input, { logger, enqueue }) => {
  logger.info('Processing message', input)
  await enqueue({ topic: 'message.processed', data: input })
}
```
</Tab>
</Tabs>

With just two files, you have an **API endpoint** that triggers an **event-driven workflow**.

---

## Triggers

<div id="triggers-http"></div>
<div id="triggers-queue"></div>
<div id="triggers-cron"></div>

Every Step has a `triggers` array that defines **how it triggers**:

| Type | When it runs | Use case |
|------|--------------|----------|
| `http` | HTTP request | REST APIs, webhooks |
| `queue` | Message enqueued | Background jobs, workflows |
| `cron` | Schedule | Cleanup, reports, reminders |
| `state` | State change | React to data changes |
| `stream` | Stream event | Real-time data processing |

The iii development console lets you browse all registered triggers, test HTTP endpoints directly, and inspect their configuration:

![Triggers view in the iii Console](/console/triggers-detail.png)

<Tabs items={['HTTP', 'Queue', 'Cron', 'State', 'Stream']} groupId="triggers" updateAnchor defaultIndex={0}>
  <Tab id="triggers-http" value="HTTP">

### HTTP Trigger

Runs when an HTTP request hits the path.

**Example:**

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
  <Tab value="TypeScript">
    ```typescript
    import { type Handlers, type StepConfig } from 'motia'
    import { z } from 'zod'

    export const config = {
      name: 'GetUser',
      description: 'Get user by ID',
      triggers: [
        { type: 'http', path: '/users/:id', method: 'GET' },
      ],
      enqueues: [],
      flows: ['users'],
    } as const satisfies StepConfig

    export const handler: Handlers<typeof config> = async (req, { logger }) => {
      const userId = req.pathParams.id
      logger.info('Getting user', { userId })
      return { status: 200, body: { id: userId, name: 'John' } }
    }
    ```
  </Tab>
  <Tab value="JavaScript">
    ```javascript
    export const config = {
      name: 'GetUser',
      description: 'Get user by ID',
      triggers: [
        { type: 'http', path: '/users/:id', method: 'GET' },
      ],
      enqueues: [],
      flows: ['users'],
    }

    export const handler = async (req, { logger }) => {
      const userId = req.pathParams.id
      logger.info('Getting user', { userId })
      return { status: 200, body: { id: userId, name: 'John' } }
    }
    ```
  </Tab>
  <Tab value="Python">
    ```python
    config = {
        "name": "GetUser",
        "description": "Get user by ID",
        "triggers": [
            {"type": "http", "path": "/users/:id", "method": "GET"}
        ],
        "enqueues": [],
        "flows": ["users"]
    }

    async def handler(req, ctx):
        user_id = req.get("pathParams", {}).get("id")
        ctx.logger.info("Getting user", {"userId": user_id})
        return {"status": 200, "body": {"id": user_id, "name": "John"}}
    ```
  </Tab>
</Tabs>

**Config:**

| Property | Description |
|----------|-------------|
| `name` | Unique identifier |
| `triggers` | Array with `{ type: 'http', path, method }` |
| `path` | URL path (supports `:params`) |
| `method` | GET, POST, PUT, DELETE |
| `bodySchema` | Validate request body |

**Handler:** `handler(req, ctx)`

- `req` - Request with `body`, `headers`, `pathParams`, `queryParams`, `rawBody`
- `ctx` - Context with `logger`, `enqueue`, `state`, `streams`, `traceId`, `trigger`, `is`, `getData`, `match`
- Returns `{ status, body, headers? }`

</Tab>

  <Tab id="triggers-queue" value="Queue">

### Queue Trigger

Runs when a message is enqueued to a topic. Use for background tasks.

**Example:**

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
  <Tab value="TypeScript">
    ```typescript
    import { type Handlers, type StepConfig } from 'motia'
    import { z } from 'zod'

    export const config = {
      name: 'ProcessMessage',
      description: 'Processes messages in background',
      triggers: [
        { type: 'queue', topic: 'message.sent', input: z.object({ text: z.string() }) },
      ],
      enqueues: ['message.processed'],
      flows: ['messaging'],
    } as const satisfies StepConfig

    export const handler: Handlers<typeof config> = async (input, { logger, enqueue }) => {
      logger.info('Processing message:', input)
      await enqueue({ topic: 'message.processed', data: input })
    }
    ```
  </Tab>
  <Tab value="JavaScript">
    ```javascript
    export const config = {
      name: 'ProcessMessage',
      description: 'Processes messages in background',
      triggers: [
        { type: 'queue', topic: 'message.sent' },
      ],
      enqueues: ['message.processed'],
      flows: ['messaging'],
    }

    export const handler = async (input, { logger, enqueue }) => {
      logger.info('Processing message:', input)
      await enqueue({ topic: 'message.processed', data: input })
    }
    ```
  </Tab>
  <Tab value="Python">
    ```python
    config = {
        "name": "ProcessMessage",
        "description": "Processes messages in background",
        "triggers": [
            {"type": "queue", "topic": "message.sent"}
        ],
        "enqueues": ["message.processed"],
        "flows": ["messaging"]
    }

    async def handler(input, ctx):
        ctx.logger.info("Processing message:", {"input": input})
        await ctx.enqueue({"topic": "message.processed", "data": input})
    ```
  </Tab>
</Tabs>

**Config:**

| Property | Description |
|----------|-------------|
| `name` | Unique identifier |
| `triggers` | Array with `{ type: 'queue', topic }` |
| `topic` | Topic to listen for messages on |
| `enqueues` | Topics this step can enqueue to |
| `input` | Validate input data |

**Handler:** `handler(input, ctx)`

- `input` - Data from the enqueued message
- `ctx` - Context with `logger`, `enqueue`, `state`, `streams`, `traceId`, `trigger`, `is`, `getData`, `match`

</Tab>

  <Tab id="triggers-cron" value="Cron">

### Cron Trigger

Runs on a schedule. Use for periodic tasks.

**Example:**

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
  <Tab value="TypeScript">
    ```typescript
    import { type Handlers, type StepConfig, cron } from 'motia'

    export const config = {
      name: 'DailyCleanup',
      description: 'Runs daily cleanup',
      triggers: [
        cron('0 0 0 * * * *'),
      ],
      enqueues: [],
      flows: ['maintenance'],
    } as const satisfies StepConfig

    export const handler: Handlers<typeof config> = async (input, { logger }) => {
      logger.info('Running daily cleanup')
    }
    ```
  </Tab>
  <Tab value="JavaScript">
    ```javascript
    import { cron } from 'motia'

    export const config = {
      name: 'DailyCleanup',
      description: 'Runs daily cleanup',
      triggers: [
        cron('0 0 0 * * * *'),
      ],
      enqueues: [],
      flows: ['maintenance'],
    }

    export const handler = async (input, { logger }) => {
      logger.info('Running daily cleanup')
    }
    ```
  </Tab>
  <Tab value="Python">
    ```python
    config = {
        "name": "DailyCleanup",
        "description": "Runs daily cleanup",
        "triggers": [
            {"type": "cron", "expression": "0 0 0 * * * *"}
        ],
        "enqueues": [],
        "flows": ["maintenance"]
    }

    async def handler(input, ctx):
        ctx.logger.info("Running daily cleanup")
    ```
  </Tab>
</Tabs>

**Config:**

| Property | Description |
|----------|-------------|
| `name` | Unique identifier |
| `triggers` | Array with `cron(expression)` helper |
| `expression` | Cron expression (e.g., `'0 0 0 * * * *'`) |

**Handler:** `handler(input, ctx)`

- `ctx` - Context with `logger`, `enqueue`, `state`, `streams`, `traceId`, `trigger`, `is`, `getData`, `match`

The iii engine uses a **7-field cron expression** that includes seconds and an optional year:

```
┌──────────── second (0-59)
│ ┌────────── minute (0-59)
│ │ ┌──────── hour (0-23)
│ │ │ ┌────── day of month (1-31)
│ │ │ │ ┌──── month (1-12)
│ │ │ │ │ ┌── day of week (0-6, Sun=0)
│ │ │ │ │ │ ┌ year (optional)
│ │ │ │ │ │ │
* * * * * * *
```

| Expression | Runs |
|---|---|
| `0 * * * * * *` | Every minute |
| `0 0 * * * * *` | Every hour |
| `0 0 0 * * * *` | Daily at midnight |
| `0 0 9 * * 1 *` | Monday at 9 AM |
| `0 */5 * * * * *` | Every 5 minutes |

</Tab>

  <Tab value="State">

### State Trigger

Runs when state data changes. Use for reactive workflows that respond to data mutations without polling.

**Example:**

```typescript
import type { Handlers, StepConfig, StateTriggerInput } from 'motia'

export const config = {
  name: 'OnAllStepsComplete',
  description: 'Triggers when all parallel steps finish',
  triggers: [
    {
      type: 'state',
      condition: (input: StateTriggerInput<{ totalSteps: number; completedSteps: number }>) => {
        return (
          input.group_id === 'tasks' &&
          !!input.new_value &&
          input.new_value.totalSteps === input.new_value.completedSteps
        )
      },
    },
  ],
  enqueues: ['all-steps-done'],
  flows: ['parallel-merge'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (input, { logger, enqueue }) => {
  logger.info('All steps complete', { itemId: input.item_id })
  await enqueue({ topic: 'all-steps-done', data: { taskId: input.item_id } })
}
```

**Handler input:** The handler receives a `StateTriggerInput` with `new_value`, `old_value`, `item_id`, and `group_id`.

[Learn more about State Triggers](/docs/advanced-features/reactive-triggers)

</Tab>

  <Tab value="Stream">

### Stream Trigger

Runs when a stream item is created, updated, or deleted. Use for reacting to real-time data changes.

**Example:**

```typescript
import type { Handlers, StepConfig, StreamWrapperMessage } from 'motia'

export const config = {
  name: 'OnDeploymentUpdate',
  description: 'Reacts to deployment stream changes',
  triggers: [
    {
      type: 'stream',
      streamName: 'deployment',
      groupId: 'data',
      condition: (input: StreamWrapperMessage) => input.event.type === 'update',
    },
  ],
  enqueues: ['deployment-updated'],
  flows: ['deployments'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (input, { logger, enqueue }) => {
  logger.info('Deployment updated', { streamName: input.streamName, groupId: input.groupId })
  await enqueue({ topic: 'deployment-updated', data: input.event.data })
}
```

**Handler input:** The handler receives a `StreamWrapperMessage` with `streamName`, `groupId`, `id`, `timestamp`, and an `event` object containing `type` (`create`, `update`, `delete`, or `event`) and `data`.

[Learn more about Stream Triggers](/docs/advanced-features/reactive-triggers)

</Tab>
</Tabs>

---

## Context Object

Every handler receives a `ctx` object with these tools:

| Property | Description |
|----------|-------------|
| `logger` | Structured logging (`info`, `warn`, `error`) |
| `enqueue` | Trigger other Steps by enqueuing messages |
| `state` | Persistent key-value storage |
| `streams` | Real-time data channels for clients |
| `traceId` | Unique ID for tracing requests & workflows |
| `trigger` | Info about which trigger activated this handler |
| `is` | Type guards for trigger types (is.queue, is.http, is.cron) |
| `getData` | Extract data payload regardless of trigger type |
| `match` | Pattern match on trigger type for multi-trigger steps |

---

## Core Functionality

### State -- Persistent Data

Key-value storage shared across Steps and workflows.

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```ts
const result = await state.set('settings', 'preferences', { theme: 'dark' })
const prefs = await state.get('settings', 'preferences')
```

</Tab>
<Tab value='Python'>

```python
result = await context.state.set("settings", "preferences", {"theme": "dark"})
prefs = await context.state.get("settings", "preferences")
```

</Tab>
<Tab value='JavaScript'>

```js
const result = await state.set('settings', 'preferences', { theme: 'dark' })
const prefs = await state.get('settings', 'preferences')
```

</Tab>
</Tabs>

`state.set` returns `{ new_value, old_value }`. Use `state.update` for atomic updates with `UpdateOp[]`.

[Learn more about State Management](/docs/development-guide/state-management)

### Logging -- Structured & Contextual

For debugging, monitoring, and observability.

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```ts
logger.info('Processing user', { userId: '123' })
```

</Tab>
<Tab value='Python'>

```python
context.logger.info("Processing user", {"userId": "123"})
```

</Tab>
<Tab value='JavaScript'>

```js
logger.info('Processing user', { userId: '123' })
```

</Tab>
</Tabs>

[Learn more about Observability](/docs/development-guide/observability)

### Streams -- Real-Time Data

Push updates directly to connected clients.

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```ts
await streams.chat.set('room-123', 'msg-456', { text: 'Hello!' })
```

</Tab>
<Tab value='Python'>

```python
await context.streams.chat.set("room-123", "msg-456", {"text": "Hello!"})
```

</Tab>
<Tab value='JavaScript'>

```js
await streams.chat.set('room-123', 'msg-456', { text: 'Hello!' })
```

</Tab>
</Tabs>

[Learn more about Streams](/docs/development-guide/streams)

### Flows -- Visualize in the iii Development Console

Group Steps together for diagram visualization in the iii development console.

![Flow diagram in the iii Console](/console/flow-view.png)

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```ts
export const config = {
  name: 'CreateOrder',
  description: 'Creates a new order',
  triggers: [
    { type: 'http', path: '/orders', method: 'POST' },
  ],
  enqueues: [],
  flows: ['order-management'],
} as const satisfies StepConfig
```

</Tab>
<Tab value='Python'>

```python
config = {
    "name": "CreateOrder",
    "description": "Creates a new order",
    "triggers": [
        {"type": "http", "path": "/orders", "method": "POST"}
    ],
    "enqueues": [],
    "flows": ["order-management"]
}
```

</Tab>
<Tab value='JavaScript'>

```js
export const config = {
  name: 'CreateOrder',
  description: 'Creates a new order',
  triggers: [
    { type: 'http', path: '/orders', method: 'POST' },
  ],
  enqueues: [],
  flows: ['order-management'],
}
```

</Tab>
</Tabs>

[Learn more about Flows](/docs/development-guide/flows)

### Infrastructure -- Configure Queue Steps

Customize timeout and retry behavior for Queue Steps.

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```ts
export const config = {
  name: 'SendEmail',
  description: 'Send email with retries',
  triggers: [
    {
      type: 'queue',
      topic: 'email.requested',
      infrastructure: {
        handler: { timeout: 10 },
        queue: { maxRetries: 5, visibilityTimeout: 60 }
      }
    },
  ],
  enqueues: [],
  flows: ['email'],
} as const satisfies StepConfig
```

</Tab>
<Tab value='Python'>

```python
config = {
    "name": "SendEmail",
    "description": "Send email with retries",
    "triggers": [
        {
            "type": "queue",
            "topic": "email.requested",
            "infrastructure": {
                "handler": {"timeout": 10},
                "queue": {"maxRetries": 5, "visibilityTimeout": 60}
            }
        }
    ],
    "enqueues": [],
    "flows": ["email"]
}
```

</Tab>
<Tab value='JavaScript'>

```js
export const config = {
  name: 'SendEmail',
  description: 'Send email with retries',
  triggers: [
    {
      type: 'queue',
      topic: 'email.requested',
      infrastructure: {
        handler: { timeout: 10 },
        queue: { maxRetries: 5, visibilityTimeout: 60 }
      }
    },
  ],
  enqueues: [],
  flows: ['email'],
}
```

</Tab>
</Tabs>

[Learn more about Infrastructure](/docs/development-guide/infrastructure)

---

## Multi-Trigger Steps

A single Step can respond to multiple trigger types. For example, a Step can be activated by both an HTTP request and a queue message:

```typescript
export const config = {
  name: 'ProcessOrder',
  triggers: [
    { type: 'http', method: 'POST', path: '/orders/manual' },
    { type: 'queue', topic: 'order.created' },
    { type: 'cron', expression: '0 0 0 * * * *' },
  ],
  enqueues: ['order.processed'],
  flows: ['orders'],
} as const satisfies StepConfig
```

Use `ctx.match()` to handle each trigger type differently, or `ctx.getData()` to extract the data payload regardless of trigger type.

[Learn more about Multi-Trigger Steps](/docs/advanced-features/multi-trigger-steps)

---

## Remember

- **Steps are just files.** Export a `config` and `handler`.
- Motia auto-discovers and connects them.
- Combine Steps with **enqueue + queue triggers** to build APIs, workflows, background jobs, or entire systems.

---

## What's Next?

<Card title="Start building" href="/docs/getting-started/quick-start">
  Steps are all you need to know to start building. Go to the Quickstart and start building right away.
</Card>

[Explore examples](/docs/examples)


-   [contribution](/docs/contribution): Documentation for contribution.
---
title: How to Contribute
description: Guide for developers who want to contribute to Motia
---

# How to Contribute

Thank you for your interest in contributing to Motia! We welcome contributions from the community to help make Motia better. Here are some ways you can contribute:

## Reporting Issues

If you encounter any bugs, have feature requests, or want to discuss improvements, please [open an issue](https://github.com/MotiaDev/motia/issues) on our GitHub repository. When reporting bugs, please provide detailed information about your environment and steps to reproduce the issue.

## Submitting Pull Requests

We appreciate pull requests for bug fixes, enhancements, or new features. To submit a pull request:

1. Fork the [Motia repository](https://github.com/MotiaDev/motia) on GitHub.
2. Create a new branch from the `main` branch for your changes.
3. Make your modifications and ensure that the code follows our coding conventions.
4. Write tests to cover your changes, if applicable.
5. Commit your changes and push them to your forked repository.
6. Open a pull request against the `main` branch of the Motia repository.

Please provide a clear description of your changes in the pull request, along with any relevant information or context.

## Documentation Improvements

Improving the documentation is a great way to contribute to Motia. If you find any errors, typos, or areas that need clarification, please submit a pull request with the necessary changes. The documentation source files are located in the `packages/docs/content` directory.

## Sharing Examples and Use Cases

If you have built something interesting with Motia or have a real-world use case to share, we would love to showcase it in our [Examples](/docs/examples) section. You can contribute your examples by submitting a pull request to the [Motia Examples repository](https://github.com/MotiaDev/motia-examples).

## Spreading the Word

Help spread the word about Motia by sharing it with your friends, colleagues, and the developer community. You can also star our [GitHub repository](https://github.com/MotiaDev/motia), follow us on [Twitter](https://twitter.com/motiadev), and join our [Discord community](https://discord.gg/EnfDRFYW) to stay updated with the latest news and engage with other Motia developers.

We appreciate all forms of contributions and look forward to collaborating with you to make Motia even better! 

-   [docker](/docs/deployment-guide/docker): Documentation for docker.
---
title: Docker
description: Deploy Motia applications using Docker containers
---

Docker is the foundation for all Motia production deployments. This guide covers containerizing your Motia app with the iii engine for local testing and production use.

---

## Build Your Project

Before creating a Docker image, build your Motia project:

```bash
motia build
```

This produces optimized production files:

```
dist/
├── index-production.js
└── index-production.js.map
```

---

## Dockerfile

Create a `Dockerfile` in your project root. This uses a multi-stage build to install the iii engine binary and run your Motia app with Bun:

```dockerfile title="Dockerfile"
FROM debian:bookworm-slim AS builder

RUN apt-get update && apt-get install -y --no-install-recommends curl ca-certificates && \
    rm -rf /var/lib/apt/lists/*

RUN curl -fsSL https://install.iii.dev/iii/main/install.sh | sh

FROM oven/bun:1.1-slim

WORKDIR /app

COPY --from=builder /root/.local/bin/iii /usr/local/bin/iii

COPY package.json .
COPY dist/index-production.js dist/
COPY dist/index-production.js.map dist/
COPY config-production.yaml config.yaml

EXPOSE 3111
EXPOSE 3112

CMD ["iii", "--config", "config.yaml"]
```

### .dockerignore

Create a `.dockerignore` to keep the image small:

```text title=".dockerignore"
node_modules
.git
.env
data/
src/
*.md
```

---

## Production config.yaml

Create a `config-production.yaml` that uses Redis adapters for production:

```yaml title="config-production.yaml"
modules:
  - class: modules::stream::StreamModule
    config:
      port: ${STREAM_PORT:3112}
      host: 0.0.0.0
      adapter:
        class: modules::stream::adapters::RedisAdapter
        config:
          redis_url: ${REDIS_URL:redis://localhost:6379}

  - class: modules::state::StateModule
    config:
      adapter:
        class: modules::state::adapters::RedisAdapter
        config:
          redis_url: ${REDIS_URL:redis://localhost:6379}

  - class: modules::api::RestApiModule
    config:
      port: ${PORT:3111}
      host: 0.0.0.0
      default_timeout: 30000
      concurrency_request_limit: 1024

  - class: modules::queue::QueueModule
    config:
      adapter:
        class: modules::queue::BuiltinQueueAdapter

  - class: modules::observability::OtelModule
    config:
      enabled: ${OTEL_ENABLED:true}
      service_name: ${OTEL_SERVICE_NAME:my-app}
      exporter: ${OTEL_EXPORTER_TYPE:memory}

  - class: modules::pubsub::PubSubModule
    config:
      adapter:
        class: modules::pubsub::RedisAdapter
        config:
          redis_url: ${REDIS_URL:redis://localhost:6379}

  - class: modules::cron::CronModule
    config:
      adapter:
        class: modules::cron::KvCronAdapter

  - class: modules::shell::ExecModule
    config:
      exec:
        - bun run --enable-source-maps dist/index-production.js
```

---

## Docker Compose

For local development with Redis:

```yaml title="docker-compose.yml"
services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

  app:
    build: .
    ports:
      - "3111:3111"
      - "3112:3112"
    environment:
      - REDIS_URL=redis://redis:6379
    depends_on:
      - redis
```

Run with:

```bash
docker compose up --build
```

---

## Python Steps

Make sure you have the pyproject.toml at your project and the steps folder

```toml title="pyproject"
[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "python-test"
version = "0.1.0"
description = "Minimal Motia Python test project"
requires-python = ">=3.10"
dependencies = [
  "motia[otel]",
  "iii-sdk==0.2.0",
]

[tool.hatch.build.targets.wheel]
packages = ["steps"]
```

Include this dockerfile

```dockerfile title="Dockerfile (with Python)"
# syntax=docker/dockerfile:1

FROM debian:bookworm-slim AS iii-builder

RUN apt-get update && apt-get install -y --no-install-recommends curl ca-certificates && \
    rm -rf /var/lib/apt/lists/*

RUN curl -fsSL https://install.iii.dev/iii/main/install.sh | sh

FROM python:3.11-slim

RUN apt-get update && apt-get install -y --no-install-recommends ca-certificates && \
    rm -rf /var/lib/apt/lists/*

WORKDIR /app

COPY --from=iii-builder /root/.local/bin/iii /usr/local/bin/iii

COPY pyproject.toml ./
RUN pip install --no-cache-dir uv && \
    uv pip install --system -r pyproject.toml

COPY steps ./steps
COPY config.yaml ./config.yaml

ENV III_URL=ws://127.0.0.1:49134

EXPOSE 3111 3112

CMD ["iii", "-c", "config.yaml"]
```

Add a second ExecModule entry in your `config-production.yaml` for the Python runtime:

```yaml
  - class: modules::shell::ExecModule
    config:
      watch:
        - steps/**/*_step.py
      exec:
        - uv run motia run --dir steps
```

---

## Ports

| Port | Service |
|------|---------|
| `3111` | REST API (HTTP endpoints) |
| `3112` | Stream API (WebSocket) |

---

## What's Next?

<Cards>
  <Card href="/docs/deployment-guide/railway" title="Deploy to Railway">
    One-click deployment with managed Redis
  </Card>
  <Card href="/docs/deployment-guide/fly" title="Deploy to Fly.io">
    Global edge deployment with Upstash Redis
  </Card>
  <Card href="/docs/deployment-guide/self-hosted" title="Self-Hosted">
    Full control with your own infrastructure
  </Card>
</Cards>


-   [fly](/docs/deployment-guide/fly): Documentation for fly.
---
title: Deploy to Fly.io
description: Deploy your Motia app to Fly.io with Upstash Redis for global edge deployment
---

Fly.io runs your app on fast micro-VMs close to your users. Combined with Upstash Redis, you get a globally distributed Motia backend.

This guide walks you through deploying a Motia app to Fly.io with production Redis.

<Callout type="info">
**What you'll get:** A containerized Motia app running on Fly.io with Upstash Redis for state, events, streams, and cron locking.
</Callout>

<Callout type="info">
**Example Project:** Follow along with the [Todo App example](https://github.com/MotiaDev/motia-examples/tree/main/examples/foundational/api-patterns/todo-app) - a complete deployment-ready Motia app with Redis configuration.
</Callout>

---

## Prerequisites

Before you start:

- A [Fly.io account](https://fly.io) (free tier works)
- [Fly CLI](https://fly.io/docs/hands-on/install-flyctl/) installed
- Docker running locally (for testing)
- A Motia project ready to deploy

Install the Fly CLI:

```bash
# macOS
brew install flyctl

# Windows
powershell -Command "iwr https://fly.io/install.ps1 -useb | iex"

# Linux
curl -L https://fly.io/install.sh | sh
```

Login:

```bash
flyctl auth login
```

---

## Quick Start

<Steps>
<Step>
#### Build your project and create Dockerfile

Build your Motia project first:

```bash
motia build
```

Then create a `Dockerfile` in your project root:

```dockerfile title="Dockerfile"
FROM debian:bookworm-slim AS builder

RUN apt-get update && apt-get install -y --no-install-recommends curl ca-certificates && \
    rm -rf /var/lib/apt/lists/*

RUN curl -fsSL https://install.iii.dev/iii/main/install.sh | sh

FROM oven/bun:1.1-slim

WORKDIR /app

COPY --from=builder /root/.local/bin/iii /usr/local/bin/iii

COPY package.json .
COPY dist/index-production.js dist/
COPY dist/index-production.js.map dist/
COPY config-production.yaml config.yaml

EXPOSE 3111
EXPOSE 3112

CMD ["iii", "--config", "config.yaml"]
```

</Step>
<Step>
#### Create fly.toml

```toml title="fly.toml"
app = "my-motia-app"
primary_region = "sjc"

[build]
  dockerfile = "Dockerfile"

[http_service]
  internal_port = 3111
  force_https = true
  auto_stop_machines = false
  auto_start_machines = true
  min_machines_running = 1
  processes = ["app"]

[[vm]]
  memory = "1gb"
  cpu_kind = "shared"
  cpus = 1
```

Replace `my-motia-app` with your app name and `sjc` with your preferred [region](https://fly.io/docs/reference/regions/).

</Step>
<Step>
#### Launch your app

```bash
flyctl launch --no-deploy
```

This creates your app on Fly without deploying yet.

</Step>
<Step>
#### Add Upstash Redis

```bash
flyctl redis create
```

Follow the prompts to create a Redis instance. Choose a region close to your app.

<Callout type="warn">
Upstash Redis on Fly requires a credit card on file, even for free tier usage.
</Callout>

</Step>
<Step>
#### Set environment variables

```bash
flyctl secrets set NODE_ENV=production USE_REDIS=true
```

The Redis URL is automatically attached when you create Redis with `flyctl redis create`.

</Step>
<Step>
#### Deploy

```bash
flyctl deploy
```

Fly builds your Docker image and deploys it globally.

</Step>
<Step>
#### Get your URL

Your app is live at: `https://my-motia-app.fly.dev`

</Step>
</Steps>

---

## Project Setup

### Configure the iii Engine

The iii engine is the entrypoint for your Motia app in production. It reads `config.yaml` and manages all modules. Make sure your `config.yaml` binds to `0.0.0.0` -- Fly needs your app to listen on all interfaces.

Use `${PORT:3111}` in your REST API module config so Fly can inject its port if needed.

### Configure Redis

Create a production `config.yaml` with Redis adapters for all modules. Fly sets `REDIS_URL` when you run `flyctl redis create`:

```yaml title="config-production.yaml"
modules:
  - class: modules::stream::StreamModule
    config:
      port: ${STREAM_PORT:3112}
      host: 0.0.0.0
      auth_function: motia.streams.authenticate
      adapter:
        class: modules::stream::adapters::RedisAdapter
        config:
          redis_url: ${REDIS_URL:redis://localhost:6379}

  - class: modules::state::StateModule
    config:
      adapter:
        class: modules::state::adapters::RedisAdapter
        config:
          redis_url: ${REDIS_URL:redis://localhost:6379}

  - class: modules::api::RestApiModule
    config:
      port: ${PORT:3111}
      host: 0.0.0.0
      default_timeout: 30000
      concurrency_request_limit: 1024

  - class: modules::queue::QueueModule
    config:
      adapter:
        class: modules::queue::RedisAdapter
        config:
          redis_url: ${REDIS_URL:redis://localhost:6379}

  - class: modules::observability::OtelModule
    config:
      enabled: true
      service_name: ${OTEL_SERVICE_NAME:my-app}
      exporter: otlp

  - class: modules::pubsub::PubSubModule
    config:
      adapter:
        class: modules::pubsub::RedisAdapter
        config:
          redis_url: ${REDIS_URL:redis://localhost:6379}

  - class: modules::cron::CronModule
    config:
      adapter:
        class: modules::cron::KvCronAdapter

  - class: modules::shell::ExecModule
    config:
      exec:
        - bun run --enable-source-maps dist/index-production.js
```

<Callout type="info">
The `${REDIS_URL:redis://localhost:6379}` syntax uses environment variable interpolation with a default value. Fly auto-provisions this variable when you attach Upstash Redis.
</Callout>

---

## Fly.io vs Railway

| Feature | Fly.io | Railway |
|---------|--------|---------|
| Global regions | 30+ regions | Limited regions |
| Redis | Upstash (external) | Built-in Redis |
| Pricing | Pay-per-use | Usage-based |
| CLI | `flyctl` | `railway` |
| Best for | Edge deployment | Simple setup |

Choose Fly.io if you need low-latency responses globally. Choose Railway for simpler Redis setup.

---

## Common Commands

```bash
# Check app status
flyctl status

# View logs (streams in real-time)
flyctl logs

# SSH into your app
flyctl ssh console

# Scale machines
flyctl scale count 3

# List secrets
flyctl secrets list

# Destroy app
flyctl apps destroy my-motia-app
```

---

## Troubleshooting

### App Not Listening on Expected Address

**Symptom:** Fly warns "app is not listening on the expected address"

**Fix:** Make sure your `config.yaml` REST API module uses `host: 0.0.0.0` and the port matches `fly.toml`'s `internal_port`:

```yaml
  - class: modules::api::RestApiModule
    config:
      port: ${PORT:3111}
      host: 0.0.0.0
```

### Redis Connection Refused

**Symptom:** Logs show `ECONNREFUSED 127.0.0.1:6379`

**Cause:** App is trying to connect to local Redis instead of Upstash.

**Fix:**
1. Check if `REDIS_URL` is set: `flyctl secrets list`
2. Create Redis if missing: `flyctl redis create`
3. Verify your config parses the URL correctly

### TLS Connection Errors

**Symptom:** Redis connection fails with TLS/SSL errors

**Cause:** Upstash requires TLS (`rediss://`), but your config isn't enabling it.

**Fix:** Make sure your config enables TLS when the protocol is `rediss://`:

```typescript
const useTls = url.protocol === 'rediss:'
```

### Machine Keeps Restarting

**Symptom:** App restarts repeatedly in logs

**Common causes:**
1. Unhandled exceptions during startup
2. Missing environment variables
3. Port binding issues

**Debug:** Check logs for the actual error:

```bash
flyctl logs
```

---

## Scaling Globally

Fly makes global deployment easy. Add machines in different regions:

```bash
# Add a machine in Amsterdam
flyctl machine clone --region ams

# Add a machine in Sydney  
flyctl machine clone --region syd
```

With Redis configured, all machines share state automatically. Users connect to the nearest machine for lowest latency.

---

## What's Next?

<Cards>
  <Card href="/docs/deployment-guide/railway" title="Deploy to Railway">
    Alternative with simpler Redis setup
  </Card>
  
  <Card href="/docs/deployment-guide/self-hosted" title="Self-Hosted">
    Full control with your own infrastructure
  </Card>
</Cards>


-   [getting-started](/docs/deployment-guide/getting-started): Documentation for getting-started.
---
title: Getting Started
description: Learn how to deploy your Motia project to production
full: true
---

When you're ready to deploy your Motia project to production, pick the path that fits your needs:

<Cards>
  <Card href="/docs/deployment-guide/self-hosted" title="Self-Hosted">
    Run Motia in Docker on your own infrastructure.
  </Card>
  <Card href="/docs/deployment-guide/railway" title="Deploy to Railway">
    One-click deployment with managed Redis.
  </Card>
  <Card href="/docs/deployment-guide/fly" title="Deploy to Fly.io">
    Global edge deployment with Upstash Redis.
  </Card>
</Cards>

<br />


-   [railway](/docs/deployment-guide/railway): Documentation for railway.
---
title: Deploy to Railway
description: Deploy your Motia app to Railway with Redis for production-grade backends
---

Railway makes deploying Motia apps dead simple. Connect your repo, add Redis, and you're live in minutes.

This guide walks you through deploying a production-ready Motia app with real Redis (not in-memory) on Railway.

<Callout type="info">
**What you'll get:** A fully containerized Motia app running on Railway with external Redis for state, events, streams, and cron locking.
</Callout>

<Callout type="info">
**Example Project:** Follow along with the [Todo App example](https://github.com/MotiaDev/motia-examples/tree/main/examples/foundational/api-patterns/todo-app) - a complete deployment-ready Motia app with Redis configuration.
</Callout>

---

## Prerequisites

Before you start:

- A [Railway account](https://railway.com) (free tier works)
- [Railway CLI](https://docs.railway.com/guides/cli) installed
- Docker running locally (for testing)
- A Motia project ready to deploy

Install the Railway CLI:

```bash
npm install -g @railway/cli
```

---

## Quick Start

<Steps>
<Step>
#### Login to Railway

```bash
railway login
```

This opens your browser for authentication.

</Step>
<Step>
#### Initialize your project

From your Motia project root:

```bash
railway init -n my-motia-app
```

This creates a new Railway project with the specified name.

</Step>
<Step>
#### Add Redis

```bash
railway add -d redis
```

Railway provisions a managed Redis instance automatically.

</Step>
<Step>
#### Create an app service

```bash
railway add -s my-app
```

This creates an empty service for your Motia app.

</Step>
<Step>
#### Link and configure

```bash
# Link to your app service
railway service my-app

# Set environment variables
railway variables --set "NODE_ENV=production"
railway variables --set "USE_REDIS=true"
railway variables --set 'REDIS_URL=${{Redis.REDIS_URL}}'
railway variables --set 'REDIS_PRIVATE_URL=${{Redis.REDIS_PRIVATE_URL}}'
```

</Step>
<Step>
#### Deploy

```bash
railway up
```

Railway builds your Docker image and deploys it.

</Step>
<Step>
#### Get your public URL

```bash
railway domain
```

This assigns a public URL to your app. You're live!

</Step>
</Steps>

---

## Project Setup

### Build Your Project

Before creating the Docker image, build your Motia project:

```bash
motia build
```

This creates optimized production files in `dist/`.

### Dockerfile

Create a `Dockerfile` in your project root. This uses the iii engine as the entrypoint:

```dockerfile title="Dockerfile"
FROM debian:bookworm-slim AS builder

RUN apt-get update && apt-get install -y --no-install-recommends curl ca-certificates && \
    rm -rf /var/lib/apt/lists/*

RUN curl -fsSL https://install.iii.dev/iii/main/install.sh | sh

FROM oven/bun:1.1-slim

WORKDIR /app

COPY --from=builder /root/.local/bin/iii /usr/local/bin/iii

COPY package.json .
COPY dist/index-production.js dist/
COPY dist/index-production.js.map dist/
COPY config-production.yaml config.yaml

EXPOSE 3111
EXPOSE 3112

CMD ["iii", "--config", "config.yaml"]
```

### Railway Configuration

Create a `railway.json` in your project root:

```json title="railway.json"
{
  "$schema": "https://railway.app/railway.schema.json",
  "build": {
    "builder": "DOCKERFILE",
    "dockerfilePath": "Dockerfile"
  },
  "deploy": {
    "numReplicas": 1,
    "restartPolicyType": "ON_FAILURE",
    "restartPolicyMaxRetries": 10
  }
}
```

<Callout type="info">
**Healthchecks:** Railway's default healthcheck expects a `200` response on `/`. The iii engine serves this by default. Check the configuration if Railway's healthcheck fails.
</Callout>

---

## Configure Redis

Create a production `config.yaml` with Redis adapters for all modules. Railway auto-injects `REDIS_URL` when you link the Redis service to your app:

```yaml title="config-production.yaml"
modules:
  - class: modules::stream::StreamModule
    config:
      port: ${STREAM_PORT:3112}
      host: 0.0.0.0
      auth_function: motia.streams.authenticate
      adapter:
        class: modules::stream::adapters::RedisAdapter
        config:
          redis_url: ${REDIS_URL:redis://localhost:6379}

  - class: modules::state::StateModule
    config:
      adapter:
        class: modules::state::adapters::RedisAdapter
        config:
          redis_url: ${REDIS_URL:redis://localhost:6379}

  - class: modules::api::RestApiModule
    config:
      port: ${PORT:3111}
      host: 0.0.0.0
      default_timeout: 30000
      concurrency_request_limit: 1024

  - class: modules::queue::QueueModule
    config:
      adapter:
        class: modules::queue::RedisAdapter
        config:
          redis_url: ${REDIS_URL:redis://localhost:6379}

  - class: modules::observability::OtelModule
    config:
      enabled: true
      service_name: ${OTEL_SERVICE_NAME:my-app}
      exporter: otlp

  - class: modules::pubsub::PubSubModule
    config:
      adapter:
        class: modules::pubsub::RedisAdapter
        config:
          redis_url: ${REDIS_URL:redis://localhost:6379}

  - class: modules::cron::CronModule
    config:
      adapter:
        class: modules::cron::KvCronAdapter

  - class: modules::shell::ExecModule
    config:
      exec:
        - bun run --enable-source-maps dist/index-production.js
```

<Callout type="info">
The `${REDIS_URL:redis://localhost:6379}` syntax uses environment variable interpolation with a default value. Railway auto-provisions this variable when you add a Redis database.
</Callout>

---

## Set Environment Variables

Railway auto-provisions Redis variables when you add the Redis database. Link them to your app:

<Steps>
<Step>
#### Link to your app service

```bash
railway service my-app
```

Select your app service (not Redis).

</Step>
<Step>
#### Set the variables

```bash
railway variables --set "NODE_ENV=production"
railway variables --set "USE_REDIS=true"
railway variables --set 'REDIS_URL=${{Redis.REDIS_URL}}'
railway variables --set 'REDIS_PRIVATE_URL=${{Redis.REDIS_PRIVATE_URL}}'
```

The `${{Redis.REDIS_URL}}` syntax tells Railway to inject the actual Redis URL at runtime.

</Step>
<Step>
#### Verify variables

```bash
railway variables
```

You should see your variables listed.

</Step>
</Steps>

<Callout type="warn">
**Internal vs Public URL:** Railway provides both internal (`redis.railway.internal`) and public proxy URLs for Redis. Use `REDIS_PRIVATE_URL` for faster internal connections. If you have connection issues, try the public URL from your Redis service's settings.
</Callout>

---

## Deploy and Test

### Deploy Your App

```bash
railway up
```

Watch the build logs. Once complete, Railway deploys your container.

### Get Your Domain

```bash
railway domain
```

Railway assigns a public URL like `https://your-app-production-xxxx.up.railway.app`.

### Test Your API

```bash
# List items (should be empty initially)
curl https://your-app-production-xxxx.up.railway.app/todos

# Create an item
curl -X POST https://your-app-production-xxxx.up.railway.app/todos \
  -H "Content-Type: application/json" \
  -d '{"title":"Test from Railway","priority":"high"}'

# List items again (should show your new item)
curl https://your-app-production-xxxx.up.railway.app/todos
```

If you get a JSON response with your data, you're running on production Redis!

---

## View Logs

Check what's happening in your deployed app:

```bash
railway logs
```

Add `--tail` to stream logs in real-time:

```bash
railway logs --tail
```

---

## Troubleshooting

### 502 Application Failed to Respond

**Cause:** Usually means the app isn't listening on the right port.

**Fix:** Make sure your `config.yaml` uses `${PORT:3111}` for the REST API module port so Railway can inject its port:

```yaml
  - class: modules::api::RestApiModule
    config:
      port: ${PORT:3111}
      host: 0.0.0.0
```

### Redis Connection Errors

**Cause:** The app can't reach Redis.

**Check:**
1. Is the Redis service running? Check Railway dashboard.
2. Is `REDIS_URL` set correctly? Run `railway variables` to verify.
3. Try the public Redis URL if internal isn't working.

### Healthcheck Failed

**Cause:** Railway expects a 200 response on your healthcheck path.

**Options:**
1. Remove healthcheck settings from `railway.json`
2. The iii runtime serves `/` by default which returns 200
3. Increase the healthcheck timeout

### Still Seeing "Redis Memory Server Started"

**Cause:** The app is falling back to in-memory Redis.

**Check:**
1. Is `NODE_ENV=production` or `USE_REDIS=true` set?
2. Is `REDIS_URL` resolving correctly?
3. Check logs for Redis connection errors.

---

## Scaling

Need more instances? Update your `railway.json`:

```json title="railway.json"
{
  "deploy": {
    "numReplicas": 3
  }
}
```

With Redis configured, all instances share state, events, and streams. Requests get load-balanced automatically.

---

## What's Next?

<Cards>
  <Card href="/docs/deployment-guide/fly" title="Deploy to Fly.io">
    Alternative cloud platform with global edge deployment
  </Card>
  
  <Card href="/docs/deployment-guide/self-hosted" title="Self-Hosted">
    Full control with your own infrastructure
  </Card>
</Cards>


-   [self-hosted](/docs/deployment-guide/self-hosted): Documentation for self-hosted.
---
title: Self-Hosted Deployment
description: Learn how to deploy your Motia project to production using motia-docker
---

## Prerequisites

Before you build your Docker image, first make sure you run `motia build` to build your project.

```bash
motia build
```

This will build your project and create a `dist` directory with your production-ready code.
It should be just two files: `index-production.js` and `index-production.js.map`.

```
dist/
├── index-production.js
└── index-production.js.map
```

## iii Production Config

Make sure you have a `config-production.yaml` file in your project.

```yaml title="config-production.yaml"
modules:
  - class: modules::stream::StreamModule
    config:
      port: ${STREAM_PORT:3112}
      host: 0.0.0.0
      adapter:
        class: modules::stream::adapters::RedisAdapter
        config:
          redis_url: ${REDIS_URL:redis://localhost:6379} # make sure the redis url is correct

  - class: modules::state::StateModule
    config:
      adapter:
        class: modules::state::adapters::RedisAdapter
        config:
          redis_url: ${REDIS_URL:redis://localhost:6379} # make sure the redis url is correct

  # Add CORS
  - class: modules::api::RestApiModule
    config:
      port: 3111 # make sure the port meets your load balancer's requirements
      host: 0.0.0.0 # make sure it has access to the internet
      default_timeout: 30000
      concurrency_request_limit: 1024
      cors:
        allowed_origins:
          - https://app.example.com
        allowed_methods:
          - GET
          - POST
          - PUT
          - DELETE
          - OPTIONS

  # Optional: Configure an OTEL server to send telemetry to
  - class: modules::observability::OtelModule
    config:
      enabled: ${OTEL_ENABLED:true}
      service_name: ${OTEL_SERVICE_NAME:iii-engine}
      service_version: ${SERVICE_VERSION:0.2.0}
      service_namespace: ${SERVICE_NAMESPACE:production}
      exporter: ${OTEL_EXPORTER_TYPE:memory}
      endpoint: ${OTEL_EXPORTER_OTLP_ENDPOINT:http://localhost:4317}
      sampling_ratio: 1.0
      memory_max_spans: ${OTEL_MEMORY_MAX_SPANS:10000}
      metrics_enabled: true
      metrics_exporter: ${OTEL_METRICS_EXPORTER:memory}
      metrics_retention_seconds: 3600
      metrics_max_count: 10000
      logs_enabled: ${OTEL_LOGS_ENABLED:true}
      logs_exporter: ${OTEL_LOGS_EXPORTER:memory}
      logs_max_count: ${OTEL_LOGS_MAX_COUNT:1000}
      logs_retention_seconds: ${OTEL_LOGS_RETENTION_SECONDS:3600}
      logs_sampling_ratio: ${OTEL_LOGS_SAMPLING_RATIO:1.0}

  - class: modules::queue::QueueModule
    config:
      adapter:
        # We have a binary that has RabbitMQ adapter, but is not published yet
        # This built-in adapter is for 1 single instance
        class: modules::queue::BuiltinQueueAdapter

  - class: modules::pubsub::PubSubModule
    config:
      adapter:
        class: modules::pubsub::RedisAdapter
        config:
          redis_url: ${REDIS_URL:redis://localhost:6379} # make sure the redis url is correct

  - class: modules::cron::CronModule
    config:
      adapter:
        class: modules::cron::KvCronAdapter

  - class: modules::shell::ExecModule
    config:
      exec:
        - bun run --enable-source-maps dist/index-production.js
```

## Docker Setup

```dockerfile title="Dockerfile"
FROM debian:bookworm-slim AS builder

# Install curl and ca-certificates
RUN apt-get update && apt-get install -y --no-install-recommends curl ca-certificates && \
    rm -rf /var/lib/apt/lists/*

# Install iii
RUN curl -fSL https://install.iii.dev/iii/main/install.sh | sh

FROM oven/bun:1.1-slim

WORKDIR /app

# Copy iii binary
COPY --from=builder /root/.local/bin/iii /usr/local/bin/iii

COPY package.json .
COPY dist/index-production.js dist/
COPY dist/index-production.js.map dist/
COPY config-production.yaml config.yaml

EXPOSE 3111
EXPOSE 3112

CMD ["iii", "--config", "config.yaml"]
```

### Python Steps?

Use the Dockerfile setup documented in [Docker guide - Python Steps](/docs/deployment-guide/docker#python-steps).

---

## Deploy to Cloud

Once you have Docker working locally, deploy to any cloud platform:

### Railway

The easiest option. Railway detects your Dockerfile automatically and provides managed Redis.

👉 [Full Railway deployment guide →](/docs/deployment-guide/railway)

### Fly.io

Global edge deployment with Upstash Redis. Great for low-latency worldwide.

👉 [Full Fly.io deployment guide →](/docs/deployment-guide/fly)


-   [adapters](/docs/development-guide/adapters): Documentation for adapters.
---
title: Adapters (Removed)
description: Adapters configuration has been removed from motia
---

<Callout type="error">
**Adapters have been removed from motia.** The adapters configuration that was previously available in `motia.config.ts` is no longer supported.
</Callout>

## What Changed

In previous versions, you could configure adapters for state, streams, events, and cron in `motia.config.ts`. This configuration has been removed. Adapter configuration is now handled through the `config.yaml` file, where each iii module declares its own adapter.

## Migration

Remove the `adapters` configuration from `motia.config.ts` and configure adapters in `config.yaml` modules instead. See [iii.dev/docs](https://iii.dev/docs) for the full module reference.

**Before (removed):**
```typescript
import { config } from '@motiadev/core'
import { RedisStateAdapter } from '@motiadev/adapter-redis-state'

export default config({
  adapters: {
    state: new RedisStateAdapter({ url: redisUrl })
  }
})
```

**After (`config.yaml`):**

```yaml
modules:
  - class: modules::state::StateModule
    config:
      adapter:
        class: modules::state::adapters::RedisAdapter
        config:
          redis_url: ${REDIS_URL:redis://localhost:6379}

  - class: modules::queue::QueueModule
    config:
      adapter:
        class: modules::queue::RedisAdapter
        config:
          redis_url: ${REDIS_URL:redis://localhost:6379}
```

Each module in `config.yaml` configures its own adapter. See [Configuration](/docs/development-guide/motia-config) for details.

---


-   [authentication](/docs/development-guide/authentication): Documentation for authentication.
---
title: Authentication
description: How to handle authentication in Motia for HTTP endpoints and real-time streams
---

Motia provides two authentication patterns: **stream authentication** configured via the iii engine's `config.yaml`, and **HTTP endpoint authentication** handled within your Step handlers.

## Stream Authentication

Stream authentication operates at two levels: **connection-level** authentication when the WebSocket connects, and **subscription-level** authorization when a client joins a specific stream.

### Connection-Level Authentication

Configure the `auth_function` on the Stream module in `config.yaml`. The value uses `<module>.<function>` format — `stream.authenticate` means the iii engine looks for a registered Step whose exported handler is named `authenticate` under the `stream` module namespace. This function runs on every new WebSocket connection before the upgrade completes.

```yaml title="config.yaml"
  - class: modules::stream::StreamModule
    config:
      port: 3112
      host: 0.0.0.0
      auth_function: stream.authenticate
      adapter:
        class: modules::stream::adapters::KvStore
        config:
          store_method: file_based
          file_path: ./data/stream_store
```

Create a Step file that exports the handler referenced by `auth_function`. The handler receives a stream connection object (not an Express-like `req`) with the WebSocket handshake's `headers`, `path`, `query_params`, and `addr`. It should return a `context` object that gets attached to the connection and passed to all subsequent stream join/leave trigger handlers:

```typescript title="src/stream-auth.step.ts"
import type { StepConfig } from 'motia'

export const config = {
  name: 'StreamAuthenticate',
  description: 'Authenticates WebSocket connections',
  triggers: [],
  enqueues: [],
  flows: ['auth'],
} as const satisfies StepConfig

export async function authenticate(input: {
  headers: Record<string, string>
  path: string
  query_params: Record<string, string>
  addr: string
}) {
  const token = input.headers?.['authorization']

  if (!token) {
    throw new Error('No authorization token')
  }

  const user = await validateToken(token)
  return { context: { userId: user.id, role: user.role } }
}
```

If the function throws or returns no result, the connection proceeds without an auth context. The returned `context` is attached to the connection and passed to stream join/leave trigger handlers.

### Subscription-Level Authorization

When a client joins a specific stream, a `stream` trigger handler can reject the subscription by returning `{ unauthorized: true }`. This allows per-stream, per-group access control using the auth context from the connection:

```typescript title="src/stream-guard.step.ts"
import type { Handlers, StepConfig } from 'motia'

export const config = {
  name: 'StreamGuard',
  description: 'Controls access to specific streams',
  triggers: [
    {
      type: 'stream',
      streamName: 'private-data',
      condition: (input) => true,
    },
  ],
  enqueues: [],
  flows: ['auth'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (input, { logger }) => {
  // input includes context from connection-level auth
  if (!input.context?.userId) {
    return { unauthorized: true }
  }

  logger.info('Stream access granted', { userId: input.context.userId })
  return { unauthorized: false }
}
```

---

## HTTP Endpoint Authentication

For HTTP endpoints, handle authentication directly in your Step handler using shared utility functions:

```typescript title="src/utils/auth.ts"
import type { ApiRequest } from 'motia'
import jwt from 'jsonwebtoken'

type TokenData = { userId: string; role: string }

export async function requireAuth(request: ApiRequest<any>): Promise<TokenData> {
  const authHeader = request.headers['authorization'] as string

  if (!authHeader) {
    throw new HttpError(401, 'Missing authorization header')
  }

  const [, token] = authHeader.split(' ')
  return jwt.verify(token, process.env.JWT_SECRET!) as TokenData
}

export class HttpError extends Error {
  constructor(public status: number, message: string) {
    super(message)
  }
}
```

Then use it in your Step handlers:

```typescript title="src/get-profile.step.ts"
import type { Handlers, StepConfig } from 'motia'
import { requireAuth, HttpError } from './utils/auth'

export const config = {
  name: 'GetProfile',
  description: 'Get authenticated user profile',
  triggers: [{ type: 'http', method: 'GET', path: '/profile' }],
  enqueues: [],
  flows: ['users'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (req, { logger, state }) => {
  try {
    const tokenData = await requireAuth(req)
    const user = await state.get('users', tokenData.userId)

    return { status: 200, body: user }
  } catch (error) {
    if (error instanceof HttpError) {
      return { status: error.status, body: { error: error.message } }
    }
    return { status: 500, body: { error: 'Internal server error' } }
  }
}
```

---

## Error Handling

Wrap your handler logic in try/catch blocks for error handling. This replaces the previous middleware-based `coreMiddleware` pattern:

```typescript
export const handler: Handlers<typeof config> = async (req, { logger }) => {
  try {
    const result = await processRequest(req)
    return { status: 200, body: result }
  } catch (error) {
    logger.error('Request failed', { error: error.message })

    if (error instanceof HttpError) {
      return { status: error.status, body: { error: error.message } }
    }

    return { status: 500, body: { error: 'Internal server error' } }
  }
}
```

---

## Reusable Auth Wrappers

For a cleaner pattern across many Steps, create a wrapper function:

```typescript title="src/utils/with-auth.ts"
import type { ApiRequest, ApiResponse } from 'motia'
import { requireAuth, HttpError, type TokenData } from './auth'

export function withAuth<TBody>(
  fn: (req: ApiRequest<TBody>, tokenData: TokenData, ctx: any) => Promise<ApiResponse<any, any>>
) {
  return async (req: ApiRequest<TBody>, ctx: any) => {
    try {
      const tokenData = await requireAuth(req)
      return await fn(req, tokenData, ctx)
    } catch (error) {
      if (error instanceof HttpError) {
        return { status: error.status, body: { error: error.message } }
      }
      return { status: 500, body: { error: 'Internal server error' } }
    }
  }
}
```

```typescript title="src/protected-endpoint.step.ts"
import { withAuth } from './utils/with-auth'

export const handler = withAuth(async (req, tokenData, ctx) => {
  ctx.logger.info('Authenticated request', { userId: tokenData.userId })
  return { status: 200, body: { message: 'Protected content' } }
})
```


-   [cli](/docs/development-guide/cli): Documentation for cli.
---
title: Command Line Interface (CLI)
description: Learn how to use the Motia CLI and the iii engine CLI to build, develop, and run your application
---

Motia projects use the **motia-cli** for scaffolding new projects, the **Motia npm package** for building Node.js projects, and the **iii CLI** for running the engine that powers everything.

---

## Motia CLI (motia-cli)

The motia-cli scaffolds new Motia projects with support for Node.js, Python, or mixed language templates. Python developers don't need npm; Node.js developers don't need Python.

### Install motia-cli

```bash
curl -fsSL https://raw.githubusercontent.com/MotiaDev/motia-cli/main/install.sh | sh
```

Or via Homebrew:

```bash
brew tap MotiaDev/tap
brew install motia-cli
```

### `motia-cli create [name]`

Scaffold a new Motia project with sensible defaults including `iii-config.yaml`, example Steps, and the appropriate dependency files for your chosen language.

```bash
motia-cli create my-project
```

Interactive prompts will ask for:

- **Project folder name** — or pass it as an argument
- **Language** — Node.js (TypeScript), Python, or Mixed (both)
- **iii installation** — confirms you have the iii engine installed

The CLI downloads templates from the [motia-iii-example](https://github.com/MotiaDev/motia-iii-example) repository and installs dependencies automatically (`npm install` for Node.js, `uv sync` for Python).

---

## iii CLI

The iii engine is the runtime that manages all infrastructure modules (queues, state, streams, cron, HTTP) and your Motia application process.

### Install iii

```bash
curl -fsSL https://install.iii.dev/iii/main/install.sh | sh
```

### `iii`

Start the iii engine. By default it looks for `config.yaml` in the current directory.

```bash
iii
```

### `iii -c <config-file>`

Start the engine with a specific configuration file.

```bash
iii -c config.yaml
iii -c config-production.yaml
```

### `iii -v`

Print the iii engine version.

```bash
iii -v
```

<Callout type="info">
During development, your `package.json` should have `"dev": "iii"` so that `npm run dev` starts the engine, which reads `config.yaml` and boots all configured modules including your Motia application via the ExecModule.
</Callout>

---

## iii Console

The iii console provides a visual interface for building and debugging flows. Install and run it separately:

```bash
curl -fsSL https://install.iii.dev/console/main/install.sh | sh
iii-console --enable-flow
```

Then open [http://localhost:3113/](http://localhost:3113/) to see flow diagrams, real-time logs, state inspection, and stream monitoring.

![iii Console Dashboard](/console/dashboard.png)

---

## Motia Node.js Tools (npx motia)

For Node.js and mixed projects, the `motia` npm package provides build and development tools. Install it as a project dependency when you scaffold with motia-cli.

### `motia build`

Build your project, generating an optimized production bundle in `dist/`.

```bash
npx motia build
```

This produces:
- `dist/index-production.js`
- `dist/index-production.js.map`

Your `config.yaml` should reference the production bundle in the ExecModule (place this under the top-level `modules:` list):

```yaml title="config.yaml (production ExecModule)"
modules:
  # ... other modules (StreamModule, StateModule, etc.) ...

  - class: modules::shell::ExecModule
    config:
      exec:
        - bun run --enable-source-maps dist/index-production.js
```

### `motia dev`

Start the Motia SDK in development mode. This is typically run automatically by the iii engine's ExecModule, not manually.

```bash
npx motia dev
```

Your `config.yaml` ExecModule for development (place this under the top-level `modules:` list). The `watch` array defines file patterns that trigger a rebuild, and the `exec` commands run sequentially — `npx motia dev` compiles the Steps, then `node dist/index-dev.js` starts the built output:

```yaml title="config.yaml (development ExecModule)"
modules:
  # ... other modules (StreamModule, StateModule, etc.) ...

  - class: modules::shell::ExecModule
    config:
      watch:
        - steps/**/*.ts
      exec:
        - npx motia dev
        - node dist/index-dev.js
```

### `motia rules pull`

Update AI development guides (Cursor rules, AGENTS.md) to the latest version.

```bash
npx motia rules pull
npx motia rules pull --force  # Overwrite existing
```

---

## Typical Development Workflow

```bash
motia-cli create my-project   # Scaffold a new project (choose Node.js, Python, or Mixed)
cd my-project
iii -c iii-config.yaml        # Starts the iii engine and your Motia Steps
```

The `iii` engine reads `iii-config.yaml`, starts all modules, and uses the ExecModule to build and run your Motia Steps automatically. File changes trigger hot-reload.

---

## What's Next?

<Cards>
  <Card href="/docs/concepts/overview" title="Core Concepts">
    Learn about Steps, triggers, and the event-driven architecture
  </Card>
  <Card href="/docs/examples" title="Examples">
    Explore real-world patterns and use cases
  </Card>
</Cards>


-   [environment-variables](/docs/development-guide/environment-variables): Documentation for environment-variables.
---
title: Environment Variables
description: Store API keys and configuration safely using .env files in your Motia apps.
---

# Environment Variables

Environment variables let you store API keys, database URLs, and other configuration outside your code. This keeps sensitive information secure and makes it easy to use different settings for development and production.

## Quick Setup

### 1. Create a `.env` File

Create a `.env` file in your project root:

```bash title=".env"
# API Keys
OPENAI_API_KEY=sk-your-api-key-here
DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/your-webhook

# Database
DATABASE_URL=postgresql://user:password@localhost:5432/myapp

# App Settings
NODE_ENV=development
PORT=3000

# Redis (optional - only needed if using external Redis)
REDIS_URL=redis://localhost:6379
```

### 2. Add to `.gitignore`

Make sure you never commit your `.env` file:

```bash title=".gitignore"
.env
.env.local
```

### 3. Create Template for Your Team

```bash title=".env.example"
# Copy this to .env and add your actual values
OPENAI_API_KEY=your-api-key-here
DATABASE_URL=postgresql://user:password@localhost:5432/myapp
```

## Using Environment Variables in Steps

### TypeScript/JavaScript

```typescript title="my-step.step.ts"
import { type Handlers, type StepConfig } from 'motia'

export const config = {
  name: 'chat-with-ai',
  description: 'Chat endpoint using OpenAI',
  triggers: [
    { type: 'http', path: '/chat', method: 'POST' },
  ],
  enqueues: [],
  flows: ['ai-chat'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (req, { logger }) => {
  const apiKey = process.env.OPENAI_API_KEY
  const webhookUrl = process.env.DISCORD_WEBHOOK_URL

  if (!apiKey) {
    return { status: 400, body: { error: 'Missing API key' } }
  }

  logger.info('Using OpenAI API', { hasKey: !!apiKey })

  return { status: 200, body: { message: 'Success!' } }
}
```

### Python

```python title="my-step.step.py"
import os

config = {
    "name": "process-data",
    "description": "Process incoming data",
    "triggers": [
        {"type": "queue", "topic": "data.received"}
    ],
    "flows": ["data-pipeline"]
}

async def handler(input_data, ctx):
    api_key = os.environ.get('OPENAI_API_KEY')
    database_url = os.environ.get('DATABASE_URL')

    if not api_key:
        raise ValueError('Missing OPENAI_API_KEY')

    ctx.logger.info('Processing with API key', {'has_key': bool(api_key)})

    return {'status': 'processed'}
```

## Redis Configuration

Motia uses Redis for internal coordination. By default, it includes an embedded in-memory server for development, so you don't need to install or configure Redis separately.

For production or when using an external Redis instance, configure Redis via your `config.yaml` file using the `REDIS_URL` environment variable:

```bash title=".env"
REDIS_URL=redis://redis.example.com:6379
```

```yaml title="config.yaml"
modules:
  - class: modules::state::StateModule
    config:
      adapter:
        class: modules::state::adapters::RedisAdapter
        config:
          redis_url: ${REDIS_URL:redis://localhost:6379}

  - class: modules::queue::QueueModule
    config:
      adapter:
        class: modules::queue::RedisAdapter
        config:
          redis_url: ${REDIS_URL:redis://localhost:6379}

  - class: modules::stream::StreamModule
    config:
      adapter:
        class: modules::stream::adapters::RedisAdapter
        config:
          redis_url: ${REDIS_URL:redis://localhost:6379}

  - class: modules::pubsub::PubSubModule
    config:
      adapter:
        class: modules::pubsub::RedisAdapter
        config:
          redis_url: ${REDIS_URL:redis://localhost:6379}
```

The `${REDIS_URL:redis://localhost:6379}` syntax uses environment variable interpolation with a default value. See the [Configuration](/docs/development-guide/motia-config) and [Deployment Guide](/docs/deployment-guide) for complete examples.

## Deployment

When you deploy your app, set environment variables through your hosting platform:

### Motia Cloud
```bash
motia env set OPENAI_API_KEY=sk-your-production-key
motia env set NODE_ENV=production
```

## Important Security Tips

<Callout type="warning">
**Keep Your Keys Safe**

- Never commit `.env` files to git
- Use different API keys for development and production
- Don't share API keys in code or messages
</Callout>

That's it! Environment variables are simple - just put them in `.env` and use `process.env.VARIABLE_NAME` in your code.


-   [flows](/docs/development-guide/flows): Documentation for flows.
---
title: Flows
description: Group multiple steps to be visible in diagrams in the iii development console
---

Flows group related Steps together so you can see them as connected workflows in the [iii development console](https://iii.dev/docs). Add `flows` to your Step config - it's an array of flow names.

## How It Works

Add `flows` to any Step config. Each string is a flow name.

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript
import { type Handlers, type StepConfig } from 'motia'

export const config = {
  name: 'CreateResource',
  description: 'Create a new resource',
  triggers: [
    { type: 'http', path: '/resources', method: 'POST' },
  ],
  enqueues: [],
  flows: ['resource-management'],
} as const satisfies StepConfig
```

</Tab>
<Tab value='Python'>

```python
config = {
    "name": "CreateResource",
    "description": "Create a new resource",
    "triggers": [
        {"type": "http", "path": "/resources", "method": "POST"}
    ],
    "enqueues": [],
    "flows": ["resource-management"]
}
```

</Tab>
<Tab value='JavaScript'>

```javascript
export const config = {
  name: 'CreateResource',
  description: 'Create a new resource',
  triggers: [
    { type: 'http', path: '/resources', method: 'POST' },
  ],
  enqueues: [],
  flows: ['resource-management']
}
```

</Tab>
</Tabs>

---

## Example

Two Steps working together in one flow.

![HTTP and Queue Steps connected in a flow](../img/flows-api-event.png)

**HTTP Step - Create resource:**

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript title="src/create-resource.step.ts"
import { type Handlers, type StepConfig } from 'motia'

export const config = {
  name: 'CreateResource',
  description: 'Create a new resource and trigger email',
  triggers: [
    { type: 'http', path: '/resources', method: 'POST' },
  ],
  enqueues: ['send-email'],
  flows: ['resource-management'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (req, { enqueue, logger }) => {
  logger.info('Creating resource', { title: req.body.title })

  await enqueue({
    topic: 'send-email',
    data: { email: req.body.email }
  })

  return { status: 201, body: { id: '123' } }
}
```

</Tab>
<Tab value='Python'>

```python title="src/create_resource_step.py"
config = {
    "name": "CreateResource",
    "description": "Create a new resource and trigger email",
    "triggers": [
        {"type": "http", "path": "/resources", "method": "POST"}
    ],
    "enqueues": ["send-email"],
    "flows": ["resource-management"]
}

async def handler(req, ctx):
    ctx.logger.info("Creating resource", {"title": req["body"]["title"]})

    await ctx.enqueue({
        "topic": "send-email",
        "data": {"email": req["body"]["email"]}
    })

    return {"status": 201, "body": {"id": "123"}}
```

</Tab>
<Tab value='JavaScript'>

```javascript title="src/create-resource.step.js"
export const config = {
  name: 'CreateResource',
  description: 'Create a new resource and trigger email',
  triggers: [
    { type: 'http', path: '/resources', method: 'POST' },
  ],
  enqueues: ['send-email'],
  flows: ['resource-management']
}

export const handler = async (req, { enqueue, logger }) => {
  logger.info('Creating resource', { title: req.body.title })

  await enqueue({
    topic: 'send-email',
    data: { email: req.body.email }
  })

  return { status: 201, body: { id: '123' } }
}
```

</Tab>
</Tabs>

**Queue Step - Send email:**

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript title="src/send-email.step.ts"
import { type Handlers, type StepConfig } from 'motia'

export const config = {
  name: 'SendEmail',
  description: 'Send an email notification',
  triggers: [
    { type: 'queue', topic: 'send-email' },
  ],
  enqueues: [],
  flows: ['resource-management'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (input, { logger }) => {
  logger.info('Sending email', { email: input.email })
}
```

</Tab>
<Tab value='Python'>

```python title="src/send_email_step.py"
config = {
    "name": "SendEmail",
    "description": "Send an email notification",
    "triggers": [
        {"type": "queue", "topic": "send-email"}
    ],
    "enqueues": [],
    "flows": ["resource-management"]
}

async def handler(input, ctx):
    ctx.logger.info("Sending email", {"email": input["email"]})
```

</Tab>
<Tab value='JavaScript'>

```javascript title="src/send-email.step.js"
export const config = {
  name: 'SendEmail',
  description: 'Send an email notification',
  triggers: [
    { type: 'queue', topic: 'send-email' },
  ],
  enqueues: [],
  flows: ['resource-management']
}

export const handler = async (input, { logger }) => {
  logger.info('Sending email', { email: input.email })
}
```

</Tab>
</Tabs>

Both Steps have `flows: ['resource-management']`. In the iii development console, they appear connected.

---

## Multiple Flows

A Step can belong to multiple flows.

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript
import { type Handlers, type StepConfig } from 'motia'

export const config = {
  name: 'SendEmail',
  description: 'Send an email notification',
  triggers: [
    { type: 'queue', topic: 'send-email' },
  ],
  enqueues: [],
  flows: ['resource-management', 'user-onboarding'],
} as const satisfies StepConfig
```

</Tab>
<Tab value='Python'>

```python
config = {
    "name": "SendEmail",
    "description": "Send an email notification",
    "triggers": [
        {"type": "queue", "topic": "send-email"}
    ],
    "enqueues": [],
    "flows": ["resource-management", "user-onboarding"]
}
```

</Tab>
<Tab value='JavaScript'>

```javascript
export const config = {
  name: 'SendEmail',
  description: 'Send an email notification',
  triggers: [
    { type: 'queue', topic: 'send-email' },
  ],
  enqueues: [],
  flows: ['resource-management', 'user-onboarding']
}
```

</Tab>
</Tabs>

This Step appears in both flows in the iii development console.

## Steps Without Flows

Steps work fine without flows.

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript
import { type Handlers, type StepConfig } from 'motia'

export const config = {
  name: 'HealthCheck',
  description: 'Health check endpoint',
  triggers: [
    { type: 'http', path: '/health', method: 'GET' },
  ],
  enqueues: [],
} as const satisfies StepConfig
```

</Tab>
<Tab value='Python'>

```python
config = {
    "name": "HealthCheck",
    "description": "Health check endpoint",
    "triggers": [
        {"type": "http", "path": "/health", "method": "GET"}
    ],
    "enqueues": []
}
```

</Tab>
<Tab value='JavaScript'>

```javascript
export const config = {
  name: 'HealthCheck',
  description: 'Health check endpoint',
  triggers: [
    { type: 'http', path: '/health', method: 'GET' },
  ],
  enqueues: [],
}
```

</Tab>
</Tabs>

---

## Flows in the iii Development Console

The iii development console has a dropdown to filter by flow. Select a flow to see only the Steps that belong to it.

![Flow dropdown in iii development console](../img/drop-down-flow.png)

![Flow view in the iii Console](/console/flow-view.png)

### Virtual Connections

Use `virtualEnqueues` and `virtualSubscribes` for visualization without actual events:

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript
import { type StepConfig } from 'motia'

export const config = {
  name: 'CreateResource',
  description: 'Create a resource requiring approval',
  triggers: [
    { type: 'http', path: '/resources', method: 'POST' },
  ],
  enqueues: [],
  virtualEnqueues: ['approval.required'],
  flows: ['resource-management'],
} as const satisfies StepConfig
```

</Tab>
<Tab value='Python'>

```python
config = {
    "name": "CreateResource",
    "description": "Create a resource requiring approval",
    "triggers": [
        {"type": "http", "path": "/resources", "method": "POST"}
    ],
    "enqueues": [],
    "virtualEnqueues": ["approval.required"],
    "flows": ["resource-management"]
}
```

</Tab>
<Tab value='JavaScript'>

```javascript
export const config = {
  name: 'CreateResource',
  description: 'Create a resource requiring approval',
  triggers: [
    { type: 'http', path: '/resources', method: 'POST' },
  ],
  enqueues: [],
  virtualEnqueues: ['approval.required'],
  flows: ['resource-management']
}
```

</Tab>
</Tabs>

Virtual connections show as gray/dashed lines in the iii development console. Real connections (from `enqueues` and queue triggers) show as dark solid lines.

![Virtual connections with labels in iii development console](../img/virtual-emit-subscribe.png)

### Labels

Add labels to connections in the iii development console:

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript
import { type StepConfig } from 'motia'

export const config = {
  name: 'SendEmail',
  description: 'Send email notifications',
  triggers: [
    { type: 'http', path: '/send', method: 'POST' },
  ],
  enqueues: [],
  virtualEnqueues: [
    { topic: 'email-sent', label: 'Email delivered' },
    { topic: 'email-failed', label: 'Failed to send', conditional: true },
  ],
  flows: ['notifications'],
} as const satisfies StepConfig
```

</Tab>
<Tab value='Python'>

```python
config = {
    "name": "SendEmail",
    "description": "Send email notifications",
    "triggers": [
        {"type": "http", "path": "/send", "method": "POST"}
    ],
    "enqueues": [],
    "virtualEnqueues": [
        {"topic": "email-sent", "label": "Email delivered"},
        {"topic": "email-failed", "label": "Failed to send", "conditional": True}
    ],
    "flows": ["notifications"]
}
```

</Tab>
<Tab value='JavaScript'>

```javascript
export const config = {
  name: 'SendEmail',
  description: 'Send email notifications',
  triggers: [
    { type: 'http', path: '/send', method: 'POST' },
  ],
  enqueues: [],
  virtualEnqueues: [
    { topic: 'email-sent', label: 'Email delivered' },
    { topic: 'email-failed', label: 'Failed to send', conditional: true }
  ],
  flows: ['notifications']
}
```

</Tab>
</Tabs>

### NOOP Steps

NOOP Steps don't run code. They're for visualization only:

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript
import { NoopConfig } from 'motia'

export const config: NoopConfig = {
  type: 'noop',
  name: 'ApprovalGate',
  virtualEnqueues: ['approved'],
  virtualSubscribes: ['approval.required'],
  flows: ['resource-management']
}
```

</Tab>
<Tab value='Python'>

```python
config = {
    "type": "noop",
    "name": "ApprovalGate",
    "virtualEnqueues": ["approved"],
    "virtualSubscribes": ["approval.required"],
    "flows": ["resource-management"]
}
```

</Tab>
<Tab value='JavaScript'>

```javascript
export const config = {
  type: 'noop',
  name: 'ApprovalGate',
  virtualEnqueues: ['approved'],
  virtualSubscribes: ['approval.required'],
  flows: ['resource-management']
}
```

</Tab>
</Tabs>

[Learn more about Steps and Triggers](/docs/concepts/steps)

---


-   [infrastructure](/docs/development-guide/infrastructure): Documentation for infrastructure.
---
title: Infrastructure
description: Configure queue behavior, retries, and timeouts for Queue Steps
---

Infrastructure settings let you control how Queue Steps handle queues, retries, and timeouts. Motia provides sensible defaults, so you only configure what you need.

## How It Works

Add `infrastructure` to your Step config that uses a queue trigger:

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript
import { type Handlers, type StepConfig } from 'motia'

export const config = {
  name: 'SendEmail',
  description: 'Send email with retry support',
  triggers: [
    { 
      type: 'queue', 
      topic: 'email.requested',
      infrastructure: {
        handler: { timeout: 10 },
        queue: { maxRetries: 5, visibilityTimeout: 60 }
      }
    },
  ],
  flows: ['notifications'],
} as const satisfies StepConfig
```

</Tab>
<Tab value='Python'>

```python
config = {
    "name": "SendEmail",
    "description": "Send email with retry support",
    "triggers": [
        {
            "type": "queue",
            "topic": "email.requested",
            "infrastructure": {
                "handler": {"timeout": 10},
                "queue": {"maxRetries": 5, "visibilityTimeout": 60}
            }
        }
    ],
    "flows": ["notifications"]
}
```

</Tab>
<Tab value='JavaScript'>

```javascript
export const config = {
  name: 'SendEmail',
  description: 'Send email with retry support',
  triggers: [
    {
      type: 'queue',
      topic: 'email.requested',
      infrastructure: {
        handler: { timeout: 10 },
        queue: { maxRetries: 5, visibilityTimeout: 60 }
      }
    },
  ],
  flows: ['notifications']
}
```

</Tab>
</Tabs>

---

## Configuration Options

### Handler Settings

| Property | Type | Default | Description |
|----------|------|---------|-------------|
| `timeout` | `number` | 30 | Handler timeout in seconds |

### Queue Settings

| Property | Type | Default | Description |
|----------|------|---------|-------------|
| `type` | `string` | `standard` | Queue type: `standard` or `fifo` |
| `maxRetries` | `number` | 3 | Number of retry attempts on failure |
| `visibilityTimeout` | `number` | 900 | Seconds before message becomes visible again |
| `delaySeconds` | `number` | 0 | Delay before processing (0-900 seconds) |

---

## FIFO Queues

FIFO queues guarantee exactly-once processing and maintain message order within a group.

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript
import { type Handlers, type StepConfig } from 'motia'

export const config = {
  name: 'ProcessOrder',
  description: 'Process orders in FIFO order',
  triggers: [
    {
      type: 'queue',
      topic: 'order.created',
      infrastructure: {
        queue: { type: 'fifo' }
      }
    },
  ],
  flows: ['orders'],
} as const satisfies StepConfig
```

</Tab>
<Tab value='Python'>

```python
config = {
    "name": "ProcessOrder",
    "description": "Process orders in FIFO order",
    "triggers": [
        {
            "type": "queue",
            "topic": "order.created",
            "infrastructure": {
                "queue": {"type": "fifo"}
            }
        }
    ],
    "flows": ["orders"]
}
```

</Tab>
<Tab value='JavaScript'>

```javascript
export const config = {
  name: 'ProcessOrder',
  description: 'Process orders in FIFO order',
  triggers: [
    {
      type: 'queue',
      topic: 'order.created',
      infrastructure: {
        queue: { type: 'fifo' }
      }
    },
  ],
  flows: ['orders']
}
```

</Tab>
</Tabs>

### Message Group ID

When enqueuing to FIFO queues, pass a `messageGroupId`:

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript
export const handler: Handlers<typeof config> = async (req, { enqueue }) => {
  const { orderId, customerId } = req.body

  await enqueue({
    topic: 'order.created',
    data: { orderId, customerId },
    messageGroupId: customerId
  })
}
```

</Tab>
<Tab value='Python'>

```python
async def handler(req, ctx):
    order_id = req.body["orderId"]
    customer_id = req.body["customerId"]

    await ctx.enqueue({
        "topic": "order.created",
        "data": {"orderId": order_id, "customerId": customer_id},
        "messageGroupId": customer_id
    })
```

</Tab>
<Tab value='JavaScript'>

```javascript
export const handler = async (req, { enqueue }) => {
  const { orderId, customerId } = req.body

  await enqueue({
    topic: 'order.created',
    data: { orderId, customerId },
    messageGroupId: customerId
  })
}
```

</Tab>
</Tabs>

The `messageGroupId` ensures events are processed in order within that group.

---

## Default Values

If you don't specify `infrastructure` on a queue trigger, Motia uses these defaults:

```typescript
{
  handler: {
    timeout: 30
  },
  queue: {
    type: 'standard',
    maxRetries: 3,
    visibilityTimeout: 900,
    delaySeconds: 0
  }
}
```

---


-   [middleware](/docs/development-guide/middleware): Documentation for middleware.
---
title: Middleware
description: Run code before and after your HTTP handlers
---

## What is Middleware?

Middleware runs before your HTTP handler. Use it for authentication, logging, error handling, or any logic that applies to multiple endpoints.

---

## How It Works

A middleware is a function that receives three arguments:

```typescript
middleware(req, ctx, next)
```

- **req** - The incoming request (same as handler)
- **ctx** - The context object (same as handler)
- **next()** - Call this to continue to the handler

If you don't call `next()`, the request stops. The handler never runs.

---

## Simple Example

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
  <Tab value="TypeScript">
    ```typescript
    import { ApiMiddleware, type Handlers, type StepConfig } from 'motia'

    const authMiddleware: ApiMiddleware = async (req, ctx, next) => {
      if (!req.headers.authorization) {
        return { status: 401, body: { error: 'Unauthorized' } }
      }
      return next()
    }

    export const config = {
      name: 'ProtectedEndpoint',
      description: 'A protected API endpoint',
      triggers: [
        { type: 'http', path: '/protected', method: 'GET' },
      ],
      enqueues: [],
      middleware: [authMiddleware],
    } as const satisfies StepConfig

    export const handler: Handlers<typeof config> = async (req, ctx) => {
      return { status: 200, body: { message: 'Success' } }
    }
    ```
  </Tab>
  <Tab value="JavaScript">
    ```javascript
    const authMiddleware = async (req, ctx, next) => {
      if (!req.headers.authorization) {
        return { status: 401, body: { error: 'Unauthorized' } }
      }
      return next()
    }

    export const config = {
      name: 'ProtectedEndpoint',
      description: 'A protected API endpoint',
      triggers: [
        { type: 'http', path: '/protected', method: 'GET' },
      ],
      enqueues: [],
      middleware: [authMiddleware]
    }

    export const handler = async (req, ctx) => {
      return { status: 200, body: { message: 'Success' } }
    }
    ```
  </Tab>
  <Tab value="Python">
    ```python
    async def auth_middleware(req, context, next_fn):
        if not req.get("headers", {}).get("authorization"):
            return {"status": 401, "body": {"error": "Unauthorized"}}
        return await next_fn()

    config = {
        "name": "ProtectedEndpoint",
        "description": "A protected API endpoint",
        "triggers": [
            {"type": "http", "path": "/protected", "method": "GET"}
        ],
        "enqueues": [],
        "middleware": [auth_middleware]
    }

    async def handler(req, context):
        return {"status": 200, "body": {"message": "Success"}}
    ```
  </Tab>
</Tabs>

---

## Execution Order

Middleware runs in the order you list them:

```typescript
export const config = {
  name: 'MyEndpoint',
  description: 'Endpoint with multiple middleware',
  triggers: [
    { type: 'http', path: '/endpoint', method: 'POST' },
  ],
  enqueues: [],
  middleware: [
    loggingMiddleware,
    authMiddleware,
    errorMiddleware
  ]
} as const satisfies StepConfig
```

---

## Modifying Responses

Await `next()` to get the response, then modify it:

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
  <Tab value="TypeScript">
    ```typescript
    const addHeadersMiddleware = async (req, ctx, next) => {
      const response = await next()

      return {
        ...response,
        headers: {
          ...response.headers,
          'X-Request-Id': ctx.traceId
        }
      }
    }
    ```
  </Tab>
  <Tab value="JavaScript">
    ```javascript
    const addHeadersMiddleware = async (req, ctx, next) => {
      const response = await next()

      return {
        ...response,
        headers: {
          ...response.headers,
          'X-Request-Id': ctx.traceId
        }
      }
    }
    ```
  </Tab>
  <Tab value="Python">
    ```python
    async def add_headers_middleware(req, context, next_fn):
        response = await next_fn()

        headers = response.get("headers", {})
        headers["X-Request-Id"] = context.trace_id

        return {**response, "headers": headers}
    ```
  </Tab>
</Tabs>

---

## Passing Data to Handlers

Middleware can attach data to the `req` object, making it available to your handler. This is perfect for authentication - verify the user once in middleware, then use their details in the handler.

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
  <Tab value="TypeScript">
    First, extend the request type in `api.d.ts`:

    ```typescript
    import 'motia'

    declare module 'motia' {
      interface ApiRequest {
        user?: { id: string; role: string }
      }
    }
    ```

    Then attach the data in your middleware:

    ```typescript
    const authMiddleware: ApiMiddleware = async (req, ctx, next) => {
      req.user = { id: '123', role: 'admin' }
      return next()
    }
    ```

    Now use it in your handler:

    ```typescript
    export const handler: Handlers<typeof config> = async (req, ctx) => {
      if (req.user?.role === 'admin') {
        return { status: 200, body: { message: 'Welcome Admin' } }
      }
      return { status: 403, body: { error: 'Forbidden' } }
    }
    ```
  </Tab>
  <Tab value="JavaScript">
    Attach data to `req` in middleware:

    ```javascript
    const authMiddleware = async (req, ctx, next) => {
      req.user = { id: '123', role: 'admin' }
      return next()
    }
    ```

    Access it in your handler:

    ```javascript
    export const handler = async (req, ctx) => {
      const { user } = req
      return { status: 200, body: { user } }
    }
    ```
  </Tab>
  <Tab value="Python">
    Add data to the `req` dictionary:

    ```python
    async def auth_middleware(req, context, next_fn):
        req["user"] = {"id": "123", "role": "admin"}
        return await next_fn()

    async def handler(req, context):
        user = req.get("user")
        return {"status": 200, "body": {"user": user}}
    ```
  </Tab>
</Tabs>

> **Learn more:** Check out the [Middleware Auth Handler Example](https://github.com/MotiaDev/motia-examples/tree/main/examples/middleware-auth-handler-example) to see a complete project with JWT validation and type safety.

---

## Error Handling

Catch errors from handlers:

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
  <Tab value="TypeScript">
    ```typescript
    import { ZodError } from 'zod'

    const errorMiddleware = async (req, ctx, next) => {
      try {
        return await next()
      } catch (error: any) {
        if (error instanceof ZodError) {
          ctx.logger.error('Validation error', { errors: error.errors })
          return { status: 400, body: { error: 'Validation failed' } }
        }

        ctx.logger.error('Unexpected error', { error: error.message })
        return { status: 500, body: { error: 'Internal server error' } }
      }
    }
    ```
  </Tab>
  <Tab value="JavaScript">
    ```javascript
    import { ZodError } from 'zod'

    const errorMiddleware = async (req, ctx, next) => {
      try {
        return await next()
      } catch (error) {
        if (error instanceof ZodError) {
          ctx.logger.error('Validation error', { errors: error.errors })
          return { status: 400, body: { error: 'Validation failed' } }
        }

        ctx.logger.error('Unexpected error', { error: error.message })
        return { status: 500, body: { error: 'Internal server error' } }
      }
    }
    ```
  </Tab>
  <Tab value="Python">
    ```python
    async def error_middleware(req, context, next_fn):
        try:
            return await next_fn()
        except ValidationError as e:
            context.logger.error("Validation error", {"errors": str(e)})
            return {"status": 400, "body": {"error": "Validation failed"}}
        except Exception as e:
            context.logger.error("Unexpected error", {"error": str(e)})
            return {"status": 500, "body": {"error": "Internal server error"}}
    ```
  </Tab>
</Tabs>

---

## Reusing Middleware

Create middleware files in a shared location:

```typescript title="middlewares/core.middleware.ts"
export const coreMiddleware = async (req, ctx, next) => {
  try {
    return await next()
  } catch (error) {
    ctx.logger.error('Error', { error })
    return { status: 500, body: { error: 'Internal server error' } }
  }
}
```

Import and use across steps:

```typescript title="src/user.step.ts"
import { coreMiddleware } from '../middlewares/core.middleware'
import { type Handlers, type StepConfig } from 'motia'

export const config = {
  name: 'GetUser',
  description: 'Get user by ID',
  triggers: [
    { type: 'http', path: '/users/:id', method: 'GET' },
  ],
  enqueues: [],
  middleware: [coreMiddleware],
} as const satisfies StepConfig
```

---

## What's Next?

<Cards>
  <Card href="/docs/concepts/steps#triggers" title="Triggers">
    Learn more about Triggers
  </Card>

  <Card href="/docs/examples" title="Examples">
    Explore real-world examples and patterns
  </Card>
</Cards>


-   [motia-config](/docs/development-guide/motia-config): Documentation for motia-config.
---
title: Configuration (config.yaml)
description: Configure your Motia project within the iii config.yaml file.
---

Motia projects run on [iii](https://iii.dev), which uses a `config.yaml` file for its modular runtime configuration. When you scaffold a project with `npx motia@latest create`, this file is generated for you with sensible defaults.

<Callout type="info">
The `config.yaml` is an iii configuration file. Most modules (API, queue, state, streams, cron, observability) are iii infrastructure concerns. Visit [iii.dev/docs](https://iii.dev/docs) for the full module reference.
</Callout>

## Project Setup

Your `package.json` must have `"type": "module"` and use `iii` as the dev command:

```json title="package.json"
{
  "name": "my-app",
  "type": "module",
  "scripts": {
    "dev": "iii",
    "build": "motia build"
  },
  "dependencies": {
    "motia": "next"
  }
}
```

Running `npm run dev` starts the iii runtime, which reads `config.yaml` and boots all configured modules -- including the Motia application via the Shell Exec module.

---

## Motia-Specific Configuration

The portion of `config.yaml` specific to Motia is the **Shell Exec module**, which tells iii how to build and run your Motia application:

```yaml title="config.yaml (Motia portion)"
  - class: modules::shell::ExecModule
    config:
      watch:
        - steps/**/*.ts
      exec:
        - npx motia dev
        - node dist/index-dev.js
```

- `watch` -- glob patterns for files to watch. When these change, the exec commands are re-run.
- `exec` -- commands to execute in order. `npx motia dev` builds your Steps, and `node dist/index-dev.js` runs the bundled output.

---

## Full Development Config

A complete `config.yaml` for local development. The iii infrastructure modules use file-based storage by default:

```yaml title="config.yaml"
modules:
  - class: modules::stream::StreamModule
    config:
      port: ${STREAM_PORT:3112}
      host: 127.0.0.1
      adapter:
        class: modules::stream::adapters::KvStore
        config:
          store_method: file_based
          file_path: ./data/stream_store

  - class: modules::kv_server::KvServer
    config:
      store_method: file_based
      file_path: ./data/kv_store
      save_interval_ms: 5000

  - class: modules::state::StateModule
    config:
      adapter:
        class: modules::state::adapters::KvStore
        config:
          store_method: file_based
          file_path: ./data/state_store.db

  - class: modules::api::RestApiModule
    config:
      port: 3111
      host: 127.0.0.1
      default_timeout: 30000
      concurrency_request_limit: 1024
      cors:
        allowed_origins:
          - http://localhost:3000
          - http://localhost:5173
          - http://localhost:3113
        allowed_methods:
          - GET
          - POST
          - PUT
          - DELETE
          - OPTIONS

  - class: modules::queue::QueueModule
    config:
      adapter:
        class: modules::queue::BuiltinQueueAdapter
        config:
          store_method: file_based
          file_path: ./data/queue_store

  - class: modules::pubsub::PubSubModule
    config:
      adapter:
        class: modules::pubsub::LocalAdapter

  - class: modules::cron::CronModule
    config:
      adapter:
        class: modules::cron::KvCronAdapter

  - class: modules::observability::OtelModule
    config:
      enabled: ${OTEL_ENABLED:true}
      service_name: ${OTEL_SERVICE_NAME:iii-engine}
      exporter: ${OTEL_EXPORTER_TYPE:memory}

  - class: modules::shell::ExecModule
    config:
      watch:
        - steps/**/*.ts
      exec:
        - npx motia dev
        - node dist/index-dev.js
```

<Callout type="info">
All config values support environment variable interpolation: `${VARIABLE_NAME:default_value}`. If the variable is not set, the default after `:` is used.
</Callout>

For production configuration with Redis adapters and OTLP exporters, see the [Deployment Guide](/docs/deployment-guide) and [iii.dev/docs](https://iii.dev/docs).


---

## What's Next?

<Cards>
  <Card href="/docs/development-guide/streams" title="Streams">
    Build real-time features
  </Card>

  <Card href="/docs/development-guide/state-management" title="State Management">
    Persistent storage across Steps
  </Card>
</Cards>


-   [observability](/docs/development-guide/observability): Documentation for observability.
---
title: Observability
description: See what's happening in your Motia app with logging, tracing, and debugging
---

<video controls className="mb-8 w-full rounded-xl" poster="https://assets.motia.dev/images/gifs/v1/5-motia-logging.gif">
  <source src="https://assets.motia.dev/videos/mp4/site/v1/5-motia-logging.mp4" type="video/mp4" />
</video>

Your app is running. But what's actually happening inside?
- Is that API getting hit?
- Did the message get enqueued?
- Why did that Step fail?
- Which user triggered this flow?

Motia gives you everything you need to answer these questions.

---

## Logging

Every Step has a `logger` in the context. Use it to see what's happening.

### Log Levels

| Level | When to use it |
| ----- | -------------- |
| `info` | Normal stuff - "User created", "Order processed" |
| `warn` | Something's weird but not broken - "High API usage", "Slow response" |
| `error` | Things broke - Failed API calls, exceptions, crashes |
| `debug` | Deep debugging - Raw data, internal state, timing info |

---

## How to Log

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
  <Tab value='TypeScript'>
    ```typescript
    export const handler: Handlers<typeof config> = async (input, { logger }) => {
      logger.info('Processing order')

      logger.info('Order created', {
        orderId: input.id,
        total: input.total
      })

      try {
        await chargeCard(input.paymentMethod)
      } catch (error) {
        logger.error('Payment failed', {
          error: error.message,
          orderId: input.id
        })
      }

      if (input.total > 1000) {
        logger.warn('Large order', {
          total: input.total,
          threshold: 1000
        })
      }

      logger.debug('Raw input', { input })
    }
    ```
  </Tab>
  <Tab value='Python'>
    ```python
    async def handler(input, context):
        context.logger.info('Processing order')

        context.logger.info('Order created', {
            'order_id': input.get("id"),
            'total': input.get("total")
        })

        try:
            await charge_card(input.get("payment_method"))
        except Exception as error:
            context.logger.error('Payment failed', {
                'error': str(error),
                'order_id': input.get("id")
            })

        if input.get("total", 0) > 1000:
            context.logger.warn('Large order', {
                'total': input.get("total"),
                'threshold': 1000
            })

        context.logger.debug('Raw input', {'input': input})
    ```
  </Tab>
  <Tab value='JavaScript'>
    ```javascript
    export const handler = async (input, { logger }) => {
      logger.info('Processing order')

      logger.info('Order created', {
        orderId: input.id,
        total: input.total
      })

      try {
        await chargeCard(input.paymentMethod)
      } catch (error) {
        logger.error('Payment failed', {
          error: error.message,
          orderId: input.id
        })
      }

      if (input.total > 1000) {
        logger.warn('Large order', {
          total: input.total,
          threshold: 1000
        })
      }

      logger.debug('Raw input', { input })
    }
    ```
  </Tab>
</Tabs>

Always add context data to your logs. `{ orderId: '123' }` is way more useful than just a message.

---

## Where to See Logs

Start your app:

```bash
npm run dev
```

Logs appear in **two places**:

### 1. Your Terminal

See logs right where you ran `npm run dev`:

```
[INFO] Processing order { orderId: '123', total: 99.99 }
[INFO] Order created { orderId: '123' }
[INFO] Payment successful
```

### 2. The iii Development Console

Open the [iii development console](https://iii.dev/docs) and click on your flow. Logs show up in real-time with:
- Timestamps
- Which Step logged it
- The trace ID (to follow a request through the entire flow)
- Full context data

![Real-time logs in the iii Console](/console/logs-detail.png)

---

## Tracing

Every request gets a unique `traceId`. This lets you follow a single request through your entire flow.

```typescript
export const handler: Handlers<typeof config> = async (req, { logger, traceId, enqueue }) => {
  logger.info('Order started', { traceId })

  await enqueue({
    topic: 'process.payment',
    data: { orderId: '123' }
  })

  return { status: 200, body: { traceId } }
}
```

**In the iii development console:**
- Click any log entry
- See all logs with the same `traceId`
- Follow the request from start to finish

![Traces waterfall view in the iii Console](/console/traces-detail.png)

---

## Debug Mode

Want more detailed logs?

```bash
npm run dev -- --debug
```

This enables `debug` level logs. You'll see everything - raw inputs, internal state, timing info.

**In production:** Don't use debug mode (it's slow and logs everything).

---

## Tips for Better Logs

### Use Objects, Not Strings

**Good:**
```typescript
logger.info('Payment processed', {
  paymentId: '123',
  amount: 100,
  status: 'success'
})
```

**Bad:**
```typescript
logger.info(`Payment 123 processed: amount=100`)
```

Why? Objects are searchable, filterable, and easier to parse.

### Track Performance

```typescript
export const handler: Handlers<typeof config> = async (input, { logger }) => {
  const start = performance.now()

  await processOrder(input)

  logger.info('Order processed', {
    duration: performance.now() - start,
    orderId: input.id
  })
}
```

### Log Errors Properly

```typescript
try {
  await riskyOperation()
} catch (error) {
  logger.error('Operation failed', {
    error: error.message,
    stack: error.stack,
    input: input.id
  })
  throw error
}
```

---

## Debugging Workflows

**Problem:** Something's not working, but where?

**Steps to debug:**

1. **Check terminal logs** - See which Steps ran
2. **Open the iii development console** at [http://localhost:3113](http://localhost:3113)
3. **Click your flow** - See the visual diagram
4. **Expand logs panel** - See all logs in chronological order
5. **Click a log** - Filter by that `traceId` to follow the request
6. **Check each Step** - See where it failed

![Traces waterfall in the iii Console](/console/traces-waterfall.png)

### Common Issues

**API not responding?**
- Check if the Step ran: Look for logs with your Step's name
- Check the response: Look for `status: 200` in logs

**Message not being processed?**
- Check if `enqueue()` was called: Search logs for "enqueue"
- Check the topic name: Make sure it matches the queue trigger topic

**Step not running?**
- Check if it's discovered: Look for `[CREATED] Step` in startup logs
- Check the file name: Must contain `.step.` or `_step`

---

## Remember

- **Log everything important** - But not everything (no sensitive data!)
- **Use `traceId`** - Follow requests through your entire flow
- **Check the iii development console** - Visual debugging is easier
- **Use objects** - Don't log strings, log objects
- **Debug mode** - Only for development, never in production

---


-   [plugins](/docs/development-guide/plugins): Documentation for plugins.
---
title: Plugins (Removed)
description: Plugins have been removed from motia and the workbench
---

import { Callout } from 'fumadocs-ui/components/callout';

<Callout type="error">
**Plugins have been removed from motia and the workbench.** The plugin system that was previously available for extending the workbench UI and adding custom functionality is no longer supported.
</Callout>

## What Changed

In previous versions, you could create and install plugins to extend motia's workbench with custom tabs, visualizations, and service integrations. This plugin system has been removed.

The following are no longer available:
- `MotiaPlugin` type and plugin architecture
- `WorkbenchPlugin` configuration for custom tabs
- `MotiaPluginContext` for accessing internal APIs
- Plugin CLI generation (`pnpm dlx npx motia@latest create --plugin`)
- Local plugins with `~/` package resolution
- Plugin registration in `motia.config.ts`

## Migration

If you were previously using plugins, you will need to find alternative approaches for the functionality they provided. Custom API endpoints can be created as regular Steps instead.

---


-   [project-structure](/docs/development-guide/project-structure): Documentation for project-structure.
---
title: Project Structure
description: Learn about Motia's project structure, file organization, and automatic step discovery system for building scalable workflow applications.
---

# Project Structure

Understanding how to organize your Motia project is crucial for building maintainable and scalable workflow applications. This guide covers the directory structure, file naming conventions, and Motia's automatic step discovery system.

## Basic Project Structure

Here's what a typical Motia project looks like:

<Folder name="my-motia-project" defaultOpen>
  <Folder name="src" defaultOpen>
    <File name="api-gateway.step.ts" />
    <File name="data-processor_step.py" />
    <File name="send-notification.step.js" />
    <File name="send-notification.tsx" />
  </Folder>
  <File name="package.json" />
  <File name="requirements.txt" />
  <File name="tsconfig.json" />
  <File name="types.d.ts" />
  <File name="config.yaml" />
</Folder>

### File Descriptions

| File | Purpose | Type | Auto-Generated |
|------|---------|------|----------------|
| `api-gateway.step.ts` | TypeScript API endpoint | User Code | - |
| `data-processor_step.py` | Python data processing | User Code | - |
| `send-notification.step.js` | JavaScript automation | User Code | - |
| `send-notification.tsx` | Optional UI override component | User Code | - |
| `package.json` | Node.js dependencies (if using JS/TS) | Config | - |
| `requirements.txt` | Python dependencies (if using Python) | Config | - |
| `tsconfig.json` | TypeScript config (if using TypeScript) | Config | - |
| `types.d.ts` | **Type definitions for your project** | **Generated** | **By TypeScript** |
| `config.yaml` | iii configuration | Config | - |

<Callout type="info">
**Flexible Step Discovery**

Motia automatically discovers and registers steps from your `src/` directory. You're **not required** to use a specific directory structure - organize your code however makes sense for your project!
</Callout>

<Callout type="success">
<strong>Directory flexibility and organization</strong>

- **Recursive discovery** - nest steps in subfolders as deeply as you need (e.g., `src/api/v1/users.step.ts`, `src/services/email/send_step.py`)
- **Organize freely** - structure by feature, language, team, or any pattern that works for you
</Callout>

## Automatic Step Discovery

<Callout type="default">
**Key Concept: Automatic Discovery**

Motia automatically discovers and registers **any file** that follows the `.step.` naming pattern as a workflow step, **regardless of where it's located** in your `src/` directory. No manual registration required - just create a file with the right naming pattern and Motia will find it.
</Callout>

### Discovery Rules

Motia scans your project and automatically registers files as steps based on these simple rules:

1. **File must contain `.step.` or `_step.` in the filename** (e.g., `my-task.step.ts`, `my_task_step.py`)
2. **File must export a `config` object** defining the step configuration
3. **File must export a `handler` function** containing the step logic
4. **File extension determines the runtime** (`.ts` = TypeScript, `.py` = Python, `.js` = JavaScript)

When you start the dev server, Motia will:
- **Recursively scan** the `src/` directory
- **Find all files** matching `*.step.*` or `*_step.*` patterns in the `src/` directory
- Parse their `config` exports to understand step types and connections
- Register them in the workflow engine

<Callout type="success">
**No directory requirement** - Steps are discoverable from anywhere within `src/`, regardless of folder depth or organization pattern.
</Callout>

## File Naming Convention

Motia uses this specific pattern for automatic step discovery:

```
descriptive-name.step.[extension]
```

<Callout type="warning">
The `.step.` part in the filename is **required** - this is how Motia identifies which files are workflow steps during automatic discovery.
</Callout>

### Supported Languages & Extensions

| Language | Extension | Example Step File | Runtime |
|----------|-----------|-------------------|---------|
| **TypeScript** | `.ts` | `user-registration.step.ts` | Node.js with TypeScript |
| **Python** | `.py` | `data-analysis_step.py` | Python interpreter |
| **JavaScript** | `.js` | `send-notification.step.js` | Node.js |

### Naming Examples by Step Type

| Step Type | TypeScript | Python | JavaScript |
|-----------|------------|---------|-----------|
| **API Endpoint** | `auth-api.step.ts` | `auth-api_step.py` or `auth_api_step.py` | `auth-api.step.js` |
| **Queue Handler** | `process-order.step.ts` | `process-order_step.py` or `process_order_step.py` | `process-order.step.js` |
| **Cron Job** | `daily-report.step.ts` | `daily-report_step.py` or `daily_report_step.py` | `daily-report.step.js` |
| **Data Processing** | `transform-data.step.ts` | `ml-analysis_step.py` or `ml_analysis_step.py` | `data-cleanup.step.js` |

## Step Organization Patterns

<Callout type="info">
All examples below use `src/` as the root directory.
</Callout>

<Tabs items={["Sequential", "Feature-Based", "Language-Specific", "Mixed Directories"]}>
<Tab value="Sequential">

### Sequential Flow Organization
Perfect for linear workflows where order matters:

<Folder name="src" defaultOpen>
  <File name="api-start.step.ts" />
  <File name="validate-data_step.py" />
  <File name="process-payment.step.js" />
  <File name="send-confirmation.step.ts" />
  <File name="cleanup_step.py" />
</Folder>

| Step | Language | Purpose |
|------|----------|---------|
| `api-start.step.ts` | TypeScript | API endpoint |
| `validate-data_step.py` | Python | Data validation |
| `process-payment.step.js` | JavaScript | Payment processing |
| `send-confirmation.step.ts` | TypeScript | Email service |
| `cleanup_step.py` | Python | Cleanup tasks |

</Tab>
<Tab value="Feature-Based">

### Feature-Based Organization
Organize by business domains for complex applications:

<Folder name="src" defaultOpen>
  <Folder name="authentication" defaultOpen>
    <File name="login.step.ts" />
    <File name="verify-token_step.py" />
    <File name="logout.step.js" />
  </Folder>
  <Folder name="payment" defaultOpen>
    <File name="process-payment.step.ts" />
    <File name="fraud-detection_step.py" />
    <File name="webhook.step.js" />
  </Folder>
  <Folder name="notification" defaultOpen>
    <File name="email_step.py" />
    <File name="sms.step.js" />
    <File name="push.step.ts" />
  </Folder>
</Folder>

**Benefits:**
- Logical grouping by business domain
- Easy to locate related functionality
- Team ownership by feature area
- Independent scaling and deployment

</Tab>
<Tab value="Language-Specific">

### Language-Specific Organization
Group by programming language for team specialization:

<Folder name="src" defaultOpen>
  <Folder name="typescript" defaultOpen>
    <File name="api-gateway.step.ts" />
    <File name="user-management.step.ts" />
    <File name="data-validation.step.ts" />
  </Folder>
  <Folder name="python" defaultOpen>
    <File name="ml-processing_step.py" />
    <File name="data-analysis_step.py" />
    <File name="image-processing_step.py" />
  </Folder>
  <Folder name="javascript" defaultOpen>
    <File name="automation.step.js" />
    <File name="webhook-handlers.step.js" />
    <File name="integrations.step.js" />
  </Folder>
</Folder>

**Benefits:**
- Team specialization by language
- Consistent tooling and patterns
- Easy onboarding for language experts
- Shared libraries and utilities

</Tab>
<Tab value="Mixed Directories">

### Mixed Directory Organization
Organize by different concerns within `src/`:

<Folder name="project-root" defaultOpen>
  <Folder name="src" defaultOpen>
    <Folder name="api" defaultOpen>
      <File name="users.step.ts" />
      <File name="products.step.ts" />
    </Folder>
    <Folder name="services" defaultOpen>
      <File name="email-service_step.py" />
      <File name="payment-service.step.js" />
    </Folder>
    <Folder name="workflows" defaultOpen>
      <File name="onboarding.step.ts" />
      <File name="analytics_step.py" />
    </Folder>
  </Folder>
</Folder>

**Benefits:**
- Combine organizational patterns
- Separate concerns (e.g., APIs, services, workflows)
- Team autonomy in different parts of the codebase

</Tab>
</Tabs>

## Language-Specific Configuration

### TypeScript/JavaScript Projects

For Node.js-based steps, you'll need:

```json title="package.json"
{
  "name": "my-motia-app",
  "version": "1.0.0",
  "scripts": {
    "dev": "iii",
    "build": "motia build",
    "start": "motia start"
  },
  "dependencies": {
    "motia": "^0.5.12-beta.121",
    "zod": "^3.24.4"
  },
  "devDependencies": {
    "typescript": "^5.7.3",
    "@types/node": "^20.0.0"
  }
}
```

```json title="tsconfig.json (for TypeScript)"
{
  "compilerOptions": {
    "target": "ES2020",
    "module": "ESNext",
    "moduleResolution": "Node",
    "esModuleInterop": true,
    "strict": true,
    "skipLibCheck": true
  },
  "include": ["**/*.ts", "**/*.tsx"],
  "exclude": ["node_modules", "dist"]
}
```

### Python Projects

For Python-based steps:

```text title="requirements.txt"
# Core Motia dependency (install via pip install motia-python)
motia>=0.5.12

# Common dependencies
requests>=2.28.0
pydantic>=1.10.0

# Data processing (if needed)
pandas>=1.5.0
numpy>=1.21.0
```

## Step Discovery Examples

Let's see how Motia discovers different step types:

### Example 1: TypeScript API Step

```typescript title="src/user-api.step.ts"
import { type Handlers, type StepConfig } from 'motia'

export const config = {
  name: 'user-api',
  description: 'Fetch users and enqueue event',
  triggers: [
    { type: 'http', path: '/users', method: 'GET' },
  ],
  enqueues: ['users.fetched'],
  flows: ['user-management'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (req, { enqueue }) => {
  await enqueue({
    topic: 'users.fetched',
    data: { users: [] }
  })

  return {
    status: 200,
    body: { message: 'Users retrieved' }
  }
}
```

### Example 2: Python Queue Step

```python title="src/data-processor_step.py"
config = {
    "name": "data-processor",
    "description": "Process incoming data with Python",
    "triggers": [
        {"type": "queue", "topic": "users.fetched"}
    ],
    "enqueues": ["data.processed"],
    "flows": ["user-management"]
}

async def handler(input_data, ctx):
    processed_data = {
        "original": input_data,
        "processed_at": ctx.utils.dates.now().isoformat(),
        "count": len(input_data.get("users", []))
    }

    await ctx.enqueue({
        "topic": "data.processed",
        "data": processed_data
    })
```

### Example 3: JavaScript Automation Step

```javascript title="src/send-notifications.step.js"
export const config = {
  name: 'send-notifications',
  description: 'Send notifications via multiple channels',
  triggers: [
    { type: 'queue', topic: 'data.processed' },
  ],
  enqueues: ['notifications.sent'],
  flows: ['user-management']
}

export const handler = async (input, { enqueue, logger }) => {
  logger.info('Sending notifications', { data: input })

  const results = await Promise.all([
    sendEmail(input),
    sendSMS(input),
    sendPush(input)
  ])

  await enqueue({
    topic: 'notifications.sent',
    data: {
      results,
      sent_at: new Date().toISOString()
    }
  })
}

async function sendEmail(data) { /* implementation */ }
async function sendSMS(data) { /* implementation */ }
async function sendPush(data) { /* implementation */ }
```

## Auto-Generated Files

Some files in your Motia project are automatically generated:

- `types.d.ts` - TypeScript generates this for type definitions

## Discovery Troubleshooting

If Motia isn't discovering your steps:

### Common Issues

<Tabs items={["Filename Issues", "Export Issues", "Location Issues"]}>
<Tab value="Filename Issues">

**Missing `.step.` (or `_step` for Python) in filename**

<div className="grid grid-cols-1 md:grid-cols-2 gap-4">
<div>
Won't be discovered:
<Folder name="src" defaultOpen>
  <File name="user-handler.ts" />
  <File name="data-processor.py" />
  <File name="webhook.js" />
</Folder>
</div>
<div>
Will be discovered:
<Folder name="src" defaultOpen>
  <File name="user-handler.step.ts" />
  <File name="data-processor_step.py" />
  <File name="webhook.step.js" />
</Folder>
</div>
</div>

</Tab>
<Tab value="Export Issues">

**Missing config export**

```typescript title="Won't be discovered"
export const handler = async () => {
  console.log('This won't be found by Motia')
}
```

```typescript title="Will be discovered"
import { type Handlers, type StepConfig } from 'motia'

export const config = {
  name: 'my-step',
  description: 'A queue handler step',
  triggers: [
    { type: 'queue', topic: 'my-topic' },
  ],
  enqueues: ['my-output'],
  flows: ['my-flow'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (input, ctx) => {
  // Motia will discover and register this step
}
```

</Tab>
<Tab value="Location Issues">

**File outside src/ directory**

<div className="grid grid-cols-1 md:grid-cols-2 gap-4">
<div>
Won't be discovered:
<Folder name="project-root" defaultOpen>
  <Folder name="lib">
    <File name="user-handler.step.ts" />
  </Folder>
  <Folder name="utils">
    <File name="processor_step.py" />
  </Folder>
  <File name="helper.step.js" />
</Folder>
</div>
<div>
Will be discovered:
<Folder name="project-root" defaultOpen>
  <Folder name="src" defaultOpen>
    <File name="user-handler.step.ts" />
    <Folder name="services">
      <File name="processor_step.py" />
    </Folder>
  </Folder>
</Folder>
</div>
</div>

**Note:** Steps must be located within the `src/` directory to be discovered. Files can be nested at any depth within the `src/` directory.

</Tab>
</Tabs>

### Discovery Verification

Check if your steps are discovered:

```bash
npm run dev

# Look for step creation in your console:
# [CREATED] Step (Cron) src/petstore/state-audit-cron.step.ts created
# [CREATED] Step (Queue) src/petstore/process-food-order.step.ts created
# [CREATED] Step (Queue) src/petstore/notification.step.ts created
# [CREATED] Step (HTTP) src/petstore/api.step.ts created
```

## Next Steps

Now that you understand how Motia discovers and organizes steps:

- Learn about [Core Concepts](/docs/concepts) to understand how steps work together
- Explore [Defining Steps](/docs/concepts/steps) for detailed step creation
- Check out [Triggers](/docs/concepts/steps#triggers) for API, Queue, and Cron steps


-   [state-management](/docs/development-guide/state-management): Documentation for state-management.
---
title: State Management
description: Persistent Key-Value storage that works across Triggers, Steps, and Functions
---

<video controls className="mb-8 w-full rounded-xl" poster="https://assets.motia.dev/images/gifs/v1/6-motia-state.gif">
  <source src="https://assets.motia.dev/videos/mp4/site/v1/6-motia-state.mp4" type="video/mp4" />
</video>

State is persistent key-value storage that works across all your Triggers, Steps, and Functions. Set data in one Trigger, read it in another. Works across TypeScript, Python, and JavaScript.

## How It Works

State organizes data into **groups**. Each group can hold multiple items with unique keys.

Think of it like folders and files:
- **groupId** = A folder name (like `orders`, `users`, `cache`)
- **key** = A file name inside that folder
- **value** = The actual data

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript
import { type Handlers, type StepConfig } from 'motia'

export const config = {
  name: 'MyStep',
  description: 'Demonstrates state usage',
  triggers: [
    { type: 'queue', topic: 'my-topic' },
  ],
  flows: ['my-flow'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (input, { state }) => {
  // Store an item in a group (returns { new_value, old_value })
  const result = await state.set('orders', 'order-123', {
    id: 'order-123',
    status: 'pending',
    total: 99.99
  })

  // Get a specific item
  const order = await state.get('orders', 'order-123')

  // Get all items in a group
  const allOrders = await state.list('orders')

  // Delete a specific item
  await state.delete('orders', 'order-123')

  // Clear entire group
  await state.clear('orders')
}
```

</Tab>
<Tab value='Python'>

```python
async def handler(input, context):
    # Store an item in a group (returns { new_value, old_value })
    result = await context.state.set("orders", "order-123", {
        "id": "order-123",
        "status": "pending",
        "total": 99.99
    })

    # Get a specific item
    order = await context.state.get("orders", "order-123")

    # Get all items in a group
    all_orders = await context.state.list("orders")

    # Delete a specific item
    await context.state.delete("orders", "order-123")

    # Clear entire group
    await context.state.clear("orders")
  ```

  </Tab>
<Tab value='JavaScript'>

  ```javascript
import { type Handlers, type StepConfig } from 'motia'

export const config = {
  name: 'MyStep',
  description: 'Demonstrates state usage',
  triggers: [
    { type: 'queue', topic: 'my-topic' },
  ],
  flows: ['my-flow'],
}

export const handler = async (input, { state }) => {
  // Store an item in a group (returns { new_value, old_value })
  const result = await state.set('orders', 'order-123', {
    id: 'order-123',
    status: 'pending',
    total: 99.99
  })

  // Get a specific item
  const order = await state.get('orders', 'order-123')

  // Get all items in a group
  const allOrders = await state.list('orders')

  // Delete a specific item
  await state.delete('orders', 'order-123')

  // Clear entire group
  await state.clear('orders')
  }
  ```

  </Tab>
</Tabs>

---

## State Methods

| Method | What it does |
|--------|--------------|
| `state.set(groupId, key, value)` | Store an item in a group. Returns `StreamSetResult` with `new_value` and `old_value` |
| `state.get(groupId, key)` | Get a specific item (returns `null` if not found) |
| `state.list(groupId)` | Get all items in a group as an array |
| `state.delete(groupId, key)` | Remove a specific item |
| `state.clear(groupId)` | Remove all items in a group |
| `state.update(groupId, key, ops)` | Atomic update with `UpdateOp[]` |

---

## Atomic Updates

The `update()` method performs atomic operations on state data, eliminating race conditions from manual get-then-set patterns.

<Callout type="info">
  Use `update()` instead of getting a value, modifying it, and setting it back. Atomic updates prevent data loss when multiple Steps modify the same state concurrently.
</Callout>

### TypeScript/JavaScript

```typescript
await ctx.state.update('orders', orderId, [
  { type: 'increment', path: 'completedSteps', by: 1 },
  { type: 'set', path: 'status', value: 'shipped' },
  { type: 'decrement', path: 'retries', by: 1 },
])
```

### Python

```python
await context.state.update("orders", order_id, [
    {"type": "increment", "path": "completedSteps", "by": 1},
    {"type": "set", "path": "status", "value": "shipped"},
    {"type": "decrement", "path": "retries", "by": 1},
])
```

### UpdateOp Types

| Type | Fields | Description |
|---|---|---|
| `set` | `path`, `value` | Set a field to a value (overwrite) |
| `merge` | `path` (optional), `value` | Merge an object into the existing value |
| `increment` | `path`, `by` | Increment a numeric field |
| `decrement` | `path`, `by` | Decrement a numeric field |
| `remove` | `path` | Remove a field entirely |

`update()` returns `{ new_value, old_value }` just like `set()`.

[Learn more about Atomic Updates](/docs/advanced-features/atomic-updates)

---

## Real-World Example

Let's build an order processing workflow that uses state across multiple Steps.

**Step 1 - API receives order:**

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript
import { type Handlers, type StepConfig } from 'motia'

export const config = {
  name: 'CreateOrder',
  description: 'Receive and store a new order',
  triggers: [
    { type: 'http', path: '/orders', method: 'POST' },
  ],
  enqueues: ['order.created'],
  flows: ['order-processing'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (req, { state, enqueue, logger }) => {
  const orderId = crypto.randomUUID()

  const order = {
    id: orderId,
    items: req.body.items,
    total: req.body.total,
    status: 'pending',
    createdAt: new Date().toISOString()
  }

  // Store in state
  await state.set('orders', orderId, order)

  logger.info('Order created', { orderId })

  // Trigger processing
  await enqueue({
    topic: 'order.created',
    data: { orderId }
  })

  return { status: 201, body: order }
}
```

  </Tab>
<Tab value='Python'>

```python
import uuid
from datetime import datetime

async def handler(req, context):
    order_id = str(uuid.uuid4())

    order = {
        "id": order_id,
        "items": req.get("body", {}).get("items"),
        "total": req.get("body", {}).get("total"),
        "status": "pending",
        "created_at": datetime.now().isoformat()
    }

    # Store in state
    await context.state.set("orders", order_id, order)

    context.logger.info("Order created", {"orderId": order_id})

    # Trigger processing
    await context.enqueue({
        "topic": "order.created",
        "data": {"orderId": order_id}
    })

    return {"status": 201, "body": order}
  ```

  </Tab>
<Tab value='JavaScript'>

  ```javascript
export const handler = async (req, { state, enqueue, logger }) => {
  const orderId = crypto.randomUUID()

  const order = {
    id: orderId,
    items: req.body.items,
    total: req.body.total,
    status: 'pending',
    createdAt: new Date().toISOString()
  }

  // Store in state
  await state.set('orders', orderId, order)

  logger.info('Order created', { orderId })

  // Trigger processing
  await enqueue({
    topic: 'order.created',
    data: { orderId }
  })

  return { status: 201, body: order }
}
  ```

  </Tab>
</Tabs>

**Step 2 - Process payment:**

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

  ```typescript
import { type Handlers, type StepConfig } from 'motia'

export const config = {
  name: 'ProcessPayment',
  description: 'Process payment for an order',
  triggers: [
    { type: 'queue', topic: 'order.created' },
  ],
  enqueues: ['payment.completed'],
  flows: ['order-processing'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (input, { state, enqueue, logger }) => {
  const { orderId } = input

  // Get order from state
  const order = await state.get('orders', orderId)

  if (!order) {
    throw new Error(`Order ${orderId} not found`)
  }

  // Update status
  order.status = 'paid'
  await state.set('orders', orderId, order)

  logger.info('Payment processed', { orderId })

  await enqueue({
    topic: 'payment.completed',
    data: { orderId }
  })
}
  ```

  </Tab>
<Tab value='Python'>

```python
async def handler(input, context):
    order_id = input.get("orderId")

    # Get order from state
    order = await context.state.get("orders", order_id)

    if not order:
        raise Exception(f"Order {order_id} not found")

    # Update status
    order["status"] = "paid"
    await context.state.set("orders", order_id, order)

    context.logger.info("Payment processed", {"orderId": order_id})

    await context.enqueue({
        "topic": "payment.completed",
        "data": {"orderId": order_id}
    })
```

</Tab>
<Tab value='JavaScript'>

```javascript
export const handler = async (input, { state, enqueue, logger }) => {
  const { orderId } = input

  // Get order from state
  const order = await state.get('orders', orderId)

  if (!order) {
    throw new Error(`Order ${orderId} not found`)
  }

  // Update status
  order.status = 'paid'
  await state.set('orders', orderId, order)

  logger.info('Payment processed', { orderId })

  await enqueue({
    topic: 'payment.completed',
    data: { orderId }
  })
}
  ```

  </Tab>
</Tabs>

**Step 3 - View all orders (Cron job):**

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

  ```typescript
import { type Handlers, type StepConfig, cron } from 'motia'

export const config = {
  name: 'DailyReport',
  description: 'Generate daily order report',
  triggers: [
    cron('0 0 * * *'),
  ],
  enqueues: [],
  flows: ['order-processing'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (input, { state, logger }) => {
  // Get all orders
  const allOrders = await state.list<Order>('orders')

  const pending = allOrders.filter(o => o.status === 'pending')
  const paid = allOrders.filter(o => o.status === 'paid')

  logger.info('Daily order report', {
    total: allOrders.length,
    pending: pending.length,
    paid: paid.length
  })
}
```

  </Tab>
<Tab value='Python'>

```python
async def handler(context):
    # Get all orders
    all_orders = await context.state.list("orders")

    pending = [o for o in all_orders if o.get("status") == "pending"]
    paid = [o for o in all_orders if o.get("status") == "paid"]

    context.logger.info("Daily order report", {
        "total": len(all_orders),
        "pending": len(pending),
        "paid": len(paid)
    })
```

</Tab>
<Tab value='JavaScript'>

  ```javascript
export const handler = async (input, { state, logger }) => {
  // Get all orders
  const allOrders = await state.list('orders')

  const pending = allOrders.filter(o => o.status === 'pending')
  const paid = allOrders.filter(o => o.status === 'paid')

  logger.info('Daily order report', {
    total: allOrders.length,
    pending: pending.length,
    paid: paid.length
  })
}
```

  </Tab>
</Tabs>

---

## When to Use State

**Good use cases:**
- **Temporary workflow data** - Data that's only needed during a flow execution
- **API response caching** - Cache expensive API calls that don't change often
- **Sharing data between Steps** - Pass data between Steps without enqueuing it in events
- **Building up results** - Accumulate data across multiple Steps

**Better alternatives:**
- **Persistent user data** - Use a database like Postgres or MongoDB
- **File storage** - Use S3 or similar for images, PDFs, documents
- **Real-time updates** - Use Motia Streams for live data to clients
- **Large datasets** - Use a proper database, not state

---

## Inspecting State in the iii Console

The iii development console lets you browse, inspect, and manage state groups and individual entries in real-time:

![State inspector in the iii Console](/console/states-detail.png)

---

## Remember

- Organize data using **groupId** (like `orders`, `users`, `cache`)
- Each item needs a unique **key** within its groupId
- Use `list(groupId)` to retrieve all items in a group
- `state.set()` returns `{ new_value, old_value }` (StreamSetResult)
- Use `state.update()` for atomic operations like increment/decrement
- State works the same across TypeScript, Python, and JavaScript
- Clean up state when you're done with it
- Use databases for permanent data, state for temporary workflow data

---

## State Triggers

Steps can react to state changes automatically using state triggers. This enables powerful reactive patterns — for example, triggering a step when a parallel merge completes, without polling or manual coordination.

```typescript
export const config = {
  name: 'OnTaskComplete',
  triggers: [
    {
      type: 'state',
      condition: (input) => {
        if (!input.new_value) return false
        return input.group_id === 'tasks' && input.new_value.completedSteps === input.new_value.totalSteps
      },
    },
  ],
  flows: ['task-flow'],
} as const satisfies StepConfig
```

[Learn more about State Triggers](/docs/advanced-features/reactive-triggers)


-   [streams](/docs/development-guide/streams): Documentation for streams.
---
title: Real-time Streams
description: Push live updates from your backend to connected clients without polling. Perfect for AI responses, chat apps, and long-running tasks.
---

<video controls className="mb-8 w-full rounded-xl" poster="https://assets.motia.dev/images/gifs/v1/7-motia-streaming.gif">
  <source src="https://assets.motia.dev/videos/mp4/site/v1/7-motia-streaming.mp4" type="video/mp4" />
</video>

## Why Streams?

Building modern apps means dealing with long-running tasks - AI responses that stream in word by word, file processing that takes time, or chat messages that need to appear instantly.

Without Streams, you'd need to:
- Build polling logic on the frontend
- Set up WebSocket infrastructure manually
- Manage connection states and reconnection
- Handle data synchronization yourself

With Motia Streams, you get all of this out of the box. Just define what data you want to stream, and Motia handles the rest.

## Some Use Cases for Streams

- **AI/LLM responses** - Stream ChatGPT responses as they generate
- **Chat applications** - Real-time messaging and typing indicators
- **Long processes** - Video processing, data exports, batch operations
- **Live dashboards** - Real-time metrics and notifications
- **Collaborative tools** - Real-time updates across multiple users

---

## Creating a Stream

Streams are just files. Create a `.stream.ts` file in your `src/` folder and export a config.

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript title="src/chat-messages.stream.ts"
import { StreamConfig } from 'motia'
import { z } from 'zod'

export const config: StreamConfig = {
  name: 'chatMessage',
  schema: z.object({
    id: z.string(),
    userId: z.string(),
    message: z.string(),
    timestamp: z.string()
  }),
  baseConfig: {
    storageType: 'default'
  }
}
```

</Tab>
<Tab value='Python'>

```python title="src/chat_messages_stream.py"
from pydantic import BaseModel

class ChatMessage(BaseModel):
    id: str
    user_id: str
    message: str
    timestamp: str

config = {
    "name": "chatMessage",
    "schema": ChatMessage.model_json_schema(),
    "baseConfig": {"storageType": "default"}
}
```

</Tab>
<Tab value='JavaScript'>

```javascript title="src/chat-messages.stream.js"
export const config = {
  name: 'chatMessage',
  schema: {
    type: 'object',
    properties: {
      id: { type: 'string' },
      userId: { type: 'string' },
      message: { type: 'string' },
      timestamp: { type: 'string' }
    },
    required: ['id', 'userId', 'message', 'timestamp']
  },
  baseConfig: {
    storageType: 'default'
  }
}
```

</Tab>
</Tabs>

That's it. Motia auto-discovers the stream and makes it available as `context.streams.chatMessage` in all your handlers.

---

## Subscription Hooks

Stream configs support `onJoin` and `onLeave` hooks for controlling client subscriptions:

```typescript
import type { StreamConfig } from 'motia'
import { z } from 'zod'

export const config: StreamConfig = {
  name: 'deployment',
  baseConfig: { storageType: 'default' },
  schema: z.object({
    id: z.string(),
    status: z.enum(['pending', 'progress', 'completed', 'failed']),
    message: z.string().optional(),
  }),
  onJoin: async (subscription, context, authContext) => {
    context.logger.info('Client joined stream', { subscription, authContext })
    if (!authContext?.userId) {
      return { unauthorized: true }
    }
    return { unauthorized: false }
  },
  onLeave: async (subscription, context, authContext) => {
    context.logger.info('Client left stream', { subscription, authContext })
  },
}
```

- **`onJoin`** — Called when a client subscribes. Return `{ unauthorized: true }` to reject the subscription.
- **`onLeave`** — Called when a client unsubscribes.

---

## Using Streams in Steps

Once you've defined a stream, you can use it in any Step through `context.streams`.

### Stream Methods

Every stream has these methods:

| Method | What it does |
|--------|-------------|
| `set(groupId, id, data)` | Create or update an item. Returns `StreamSetResult` with `new_value` and `old_value` |
| `get(groupId, id)` | Get a single item |
| `delete(groupId, id)` | Remove an item |
| `getGroup(groupId)` | Get all items in a group |
| `update(groupId, id, ops)` | Atomic update with `UpdateOp[]`. Returns `{ new_value, old_value }` |
| `send(channel, event)` | Send ephemeral events (typing, reactions, etc.) |

**Think of it like this:**
- `groupId` = Which room/conversation/user
- `id` = Which specific item in that room
- `data` = The actual data matching your schema

### Atomic Updates with `update()`

Use the `update()` method to perform atomic operations on stream items without reading and rewriting the entire object:

```typescript
await streams.deployment.update('data', deploymentId, [
  { type: 'increment', path: 'completedSteps', by: 1 },
  { type: 'set', path: 'status', value: 'progress' },
  { type: 'decrement', path: 'retries', by: 1 },
])
```

This uses the same `UpdateOp` types as state updates: `set`, `merge`, `increment`, `decrement`, `remove`.

[Learn more about Atomic Updates](/docs/advanced-features/atomic-updates)

---

## Real Example: Todo App with Real-Time Sync

Let's build a todo app where all connected clients see updates instantly.

<Callout type="info">
  This is a real, working example from the [Motia Examples Repository](https://github.com/MotiaDev/motia-examples/tree/main/examples/realtime-todo-app). You can clone it and run it locally!
</Callout>

**Step 1:** Create the stream definition

```typescript title="src/todo.stream.ts"
import { StreamConfig } from 'motia'
import { z } from 'zod'

const todoSchema = z.object({
  id: z.string(),
  description: z.string(),
  createdAt: z.string(),
  dueDate: z.string().optional(),
  completedAt: z.string().optional()
})

export const config: StreamConfig = {
  name: 'todo',
  schema: todoSchema,
  baseConfig: { storageType: 'default' }
}

export type Todo = z.infer<typeof todoSchema>
```

**Step 2:** Create an API endpoint that uses streams

```typescript title="src/create-todo.step.ts"
import { type Handlers, type StepConfig } from 'motia'
import { z } from 'zod'
import { Todo } from './todo.stream'

export const config = {
  name: 'CreateTodo',
  description: 'Create a new todo item',
  triggers: [
    { type: 'http', path: '/todo', method: 'POST' },
  ],
  enqueues: [],
  flows: ['todo-app'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (req, { logger, streams }) => {
  logger.info('Creating new todo', { body: req.body })

  const { description, dueDate } = req.body
  const todoId = `todo-${Date.now()}-${Math.random().toString(36).substring(2, 9)}`

  if (!description) {
    return { status: 400, body: { error: 'Description is required' } }
  }

  const newTodo: Todo = {
    id: todoId,
    description,
    createdAt: new Date().toISOString(),
    dueDate,
    completedAt: undefined
  }

  // Store in the 'inbox' group - all clients watching this group see the update!
  const todo = await streams.todo.set('inbox', todoId, newTodo)

  logger.info('Todo created successfully', { todoId })

  return { status: 200, body: todo }
}
```

**What happens here:**
1. Client calls `POST /todo` with a description
2. Server creates the todo and calls `streams.todo.set('inbox', todoId, newTodo)`
3. **Instantly**, all clients subscribed to the `inbox` group receive the new todo
4. No polling, no refresh needed

Every time you call `streams.todo.set()`, connected clients receive the update instantly. No polling needed.

---

## Restricting Stream Access

Streams can enforce authentication and authorization rules so that only approved clients can subscribe.

### 1. Configure `streamAuth`

```typescript title="stream-auth.ts"
import type { StreamAuthRequest } from 'motia'
import { z } from 'zod'

const streamAuthContextSchema = z.object({
  userId: z.string(),
  plan: z.enum(['free', 'pro']),
  projectIds: z.array(z.string()),
})

const extractAuthToken = (request: StreamAuthRequest): string | undefined => {
  const protocolHeader = request.headers['sec-websocket-protocol']
  if (protocolHeader?.includes('Authorization')) {
    const [, token] = protocolHeader.split(',')
    if (token) {
      return token.trim()
    }
  }

  if (!request.url) return undefined

  try {
    const url = new URL(request.url, 'http://localhost')
    return url.searchParams.get('authToken') ?? undefined
  } catch {
    return undefined
  }
}
```

### 2. Apply fine-grained rules with `canAccess`

Each stream can expose an optional `canAccess` function that receives the subscription info plus the `StreamAuthContext` value returned by your `authenticate` function.

```typescript title="src/chat-messages.stream.ts"
export const config: StreamConfig = {
  name: 'chatMessage',
  schema: chatMessageSchema,
  baseConfig: { storageType: 'default' },
  canAccess: ({ groupId, id }, authContext) => {
    if (!authContext) return false
    return authContext.projectIds.includes(groupId)
  },
}
```

`canAccess` can be synchronous or async. If it's not defined, Motia allows every client (even anonymous ones) to subscribe.

### 3. Send tokens from the client

Provide an auth token when creating the stream client by embedding it in the WebSocket URL.

```tsx title="App.tsx"
import { useMemo } from 'react'
import { MotiaStreamProvider } from 'motia/stream-client-react'

function AppShell({ session }: { session?: { streamToken?: string } }) {
  const streamAddress = useMemo(() => new URL('ws://localhost:3000').toString(), [])
  const protocols = useMemo(() => {
    return session?.streamToken ? ['Authorization', session.streamToken] : undefined
  }, [session?.streamToken])

  return (
    <MotiaStreamProvider address={streamAddress} protocols={protocols}>
      <App />
    </MotiaStreamProvider>
  )
}
```

Using the browser/node clients directly:

```ts
import { Stream } from 'motia/stream-client-node'

const url = new URL('wss://api.example.com/streams')
if (process.env.STREAM_TOKEN) {
  url.searchParams.set('authToken', process.env.STREAM_TOKEN)
}

const stream = new Stream(url.toString())
```

---

## Viewing Streams in the iii Development Console

The [iii development console](https://iii.dev/docs) can display stream updates in real-time:

1. Make sure your API Step returns the stream object:

```typescript
return { status: 200, body: todo }
```

2. Open the iii development console
3. Watch the stream update in real-time

The console automatically detects stream responses and subscribes to them for you.

![Streams WebSocket monitor in the iii Console](/console/streams-detail.png)

---

## Using Streams in Your Frontend

Once you have streams working on the backend, connect them to your React app.

### Install

```bash
npm install motia
```

### Setup Provider

Wrap your app with the provider:

```tsx title="App.tsx"
import { MotiaStreamProvider } from 'motia/stream-client-react'

function App() {
  const authToken = useAuthToken()

  return (
    <MotiaStreamProvider address="ws://localhost:3000" authToken={authToken}>
      {/* Your app */}
    </MotiaStreamProvider>
  )
}
```

### Subscribe to Stream Updates

```tsx title="App.tsx"
import { useStreamGroup } from 'motia/stream-client-react'
import { useTodoEndpoints, type Todo } from './hook/useTodoEndpoints'

function App() {
  const { createTodo, updateTodo, deleteTodo } = useTodoEndpoints()

  const { data: todos } = useStreamGroup<Todo>({
    groupId: 'inbox',
    streamName: 'todo'
  })

  const handleAddTodo = async (description: string) => {
    await createTodo(description)
  }

  return (
    <div>
      <h1>Inbox</h1>
      {todos.map((todo) => (
        <div key={todo.id}>{todo.description}</div>
      ))}
    </div>
  )
}
```

**How it works:**
1. `useStreamGroup()` subscribes to all items in the `inbox` group
2. When server calls `streams.todo.set('inbox', todoId, newTodo)`, the `todos` array updates automatically
3. React re-renders with the new data
4. Works across all connected clients!

![Todo App in React](./../img/todo-react.png)

Every time you call `createTodo()`, connected clients receive the update instantly. No polling needed.

---

## Ephemeral Events

Sometimes you need to send temporary events that don't need to be stored - like typing indicators, reactions, or online status.

Use `streams.<name>.send()` for this:

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript
await streams.chatMessage.send(
  { groupId: channelId },
  { type: 'typing', data: { userId: 'user-123', isTyping: true } }
)

await streams.chatMessage.send(
  { groupId: channelId, id: messageId },
  { type: 'reaction', data: { emoji: '👍', userId: 'user-123' } }
)
```

</Tab>
<Tab value='Python'>

```python
await context.streams.chatMessage.send(
    {"groupId": channel_id},
    {"type": "typing", "data": {"userId": "user-123", "isTyping": True}}
)

await context.streams.chatMessage.send(
    {"groupId": channel_id, "id": message_id},
    {"type": "reaction", "data": {"emoji": "👍", "userId": "user-123"}}
)
```

</Tab>
<Tab value='JavaScript'>

```javascript
await streams.chatMessage.send(
  { groupId: channelId },
  { type: 'typing', data: { userId: 'user-123', isTyping: true } }
)

await streams.chatMessage.send(
  { groupId: channelId, id: messageId },
  { type: 'reaction', data: { emoji: '👍', userId: 'user-123' } }
)
```

</Tab>
</Tabs>

**Difference from `set()`:**
- `set()` - Stores data, clients sync to it. Returns `{ new_value, old_value }`
- `send()` - Fire-and-forget events, not stored

---

## Remember

- **Streams = Real-time state** that clients subscribe to
- **Every `set()` call** pushes updates to connected clients instantly and returns `{ new_value, old_value }`
- **Use `update()`** for atomic operations (increment, decrement, set fields)
- **Use `send()`** for temporary events like typing indicators
- **View in the iii development console** before building your frontend
- **No polling needed** - WebSocket connection handles everything

---

## Stream Triggers

Steps can react to stream changes (create, update, delete) using stream triggers:

```typescript
export const config = {
  name: 'OnDeploymentUpdate',
  triggers: [
    {
      type: 'stream',
      streamName: 'deployment',
      groupId: 'data',
      condition: (input) => input.event.type === 'update',
    },
  ],
  flows: ['deployments'],
} as const satisfies StepConfig
```

[Learn more about Stream Triggers](/docs/advanced-features/reactive-triggers)

---

## What's Next?

<Cards>
  <Card href="/docs/development-guide/state-management" title="State Management">
    Learn about persistent storage across Steps
  </Card>

  <Card href="/docs/concepts/steps" title="Steps">
    Deep dive into building with Steps
  </Card>
</Cards>


-   [adapter-configuration](/docs/examples/adapter-configuration): Documentation for adapter-configuration.
---
title: 'Adapter Configuration'
description: 'Configure distributed adapters for horizontal scaling in production'
---

<Callout type="warn">
**Deprecated** - The `@motiadev/adapter-*` packages and `motia.config.ts` adapter configuration have been removed. Adapters are now configured through `config.yaml` modules.
</Callout>

## Migration

Adapter configuration is now handled in `config.yaml`, where each iii module declares its own adapter. See [Adapters (Removed)](/docs/development-guide/adapters) for migration details.

### Example: Redis Adapters in config.yaml

```yaml title="config.yaml"
modules:
  - class: modules::state::StateModule
    config:
      adapter:
        class: modules::state::adapters::RedisAdapter
        config:
          redis_url: ${REDIS_URL:redis://localhost:6379}

  - class: modules::queue::QueueModule
    config:
      adapter:
        class: modules::queue::RedisAdapter
        config:
          redis_url: ${REDIS_URL:redis://localhost:6379}

  - class: modules::stream::StreamModule
    config:
      adapter:
        class: modules::stream::adapters::RedisAdapter
        config:
          redis_url: ${REDIS_URL:redis://localhost:6379}

  - class: modules::pubsub::PubSubModule
    config:
      adapter:
        class: modules::pubsub::RedisAdapter
        config:
          redis_url: ${REDIS_URL:redis://localhost:6379}
```

See [Configuration](/docs/development-guide/motia-config) for the full reference, and the [Deployment Guide](/docs/deployment-guide) for production examples.



## Examples
[adapter-configuration](/docs/examples/adapter-configuration): Code example
---
title: 'Adapter Configuration'
description: 'Configure distributed adapters for horizontal scaling in production'
---

<Callout type="warn">
**Deprecated** - The `@motiadev/adapter-*` packages and `motia.config.ts` adapter configuration have been removed. Adapters are now configured through `config.yaml` modules.
</Callout>

## Migration

Adapter configuration is now handled in `config.yaml`, where each iii module declares its own adapter. See [Adapters (Removed)](/docs/development-guide/adapters) for migration details.

### Example: Redis Adapters in config.yaml

```yaml title="config.yaml"
modules:
  - class: modules::state::StateModule
    config:
      adapter:
        class: modules::state::adapters::RedisAdapter
        config:
          redis_url: ${REDIS_URL:redis://localhost:6379}

  - class: modules::queue::QueueModule
    config:
      adapter:
        class: modules::queue::RedisAdapter
        config:
          redis_url: ${REDIS_URL:redis://localhost:6379}

  - class: modules::stream::StreamModule
    config:
      adapter:
        class: modules::stream::adapters::RedisAdapter
        config:
          redis_url: ${REDIS_URL:redis://localhost:6379}

  - class: modules::pubsub::PubSubModule
    config:
      adapter:
        class: modules::pubsub::RedisAdapter
        config:
          redis_url: ${REDIS_URL:redis://localhost:6379}
```

See [Configuration](/docs/development-guide/motia-config) for the full reference, and the [Deployment Guide](/docs/deployment-guide) for production examples.


-   [ai-content-moderation](/docs/examples/ai-content-moderation): Documentation for ai-content-moderation.
---
title: 'AI Content Moderation'
description: 'Intelligent Content Moderation: Building Human-in-the-Loop Systems with Motia'
---

In today's digital landscape, content moderation is crucial for maintaining safe and appropriate user experiences. Whether you're building a social platform, forum, or any user-generated content system, you need intelligent moderation that can scale with your user base while maintaining human oversight for complex decisions.

This comprehensive guide explores how to build a production-ready content moderation system using Motia's event-driven architecture. We'll cover:

1. **AI-Powered Analysis**: Using OpenAI for text toxicity detection and image safety analysis
2. **Confidence-Based Routing**: Automatically handling clear cases while flagging uncertain content for human review
3. **Slack Integration**: Creating interactive moderation workflows within existing team communication tools
4. **Human-in-the-Loop**: Seamlessly integrating human decision-making into automated processes

Let's build a content moderation system that scales intelligently.

---

## Workflow Overview

<div className="my-8">![AI Content Moderation Workflow](./../img/ai-content-moderation-workflow.png)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/ai-agents/specialized-agents/ai-content-moderation)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## The Power of Intelligent Content Moderation

At its core, our content moderation system solves a fundamental challenge: how do you efficiently moderate user-generated content at scale while maintaining human oversight for complex decisions? Traditional approaches often involve either fully manual processes that don't scale or fully automated systems that lack nuance.

Our Motia-powered solution combines the best of both worlds through intelligent routing:

- **[OpenAI Integration](https://openai.com/)**: Advanced AI analysis for text toxicity and image safety detection
- **[Confidence-Based Routing](https://en.wikipedia.org/wiki/Confidence_interval)**: Automatic handling of clear cases, human review for uncertain content
- **[Slack Integration](https://api.slack.com/)**: Interactive moderation workflows within existing team communication tools
- **[Motia Framework](https://motia.dev)**: Event-driven orchestration with built-in state management and error handling

Instead of a monolithic moderation system, we get a flexible architecture where each component can be scaled, modified, or replaced independently.

---

## The Anatomy of Our Content Moderation System

Our application consists of six specialized steps, each handling a specific part of the moderation workflow. Let's explore the complete architecture.

<Folder name="steps" defaultOpen>
  <File name="01-content-submit.step.ts" />
  <File name="02-content-analyzer.step.ts" />
  <File name="03-content-router.step.ts" />
  <File name="04-slack-notifier.step.ts" />
  <File name="05-slack-webhook.step.ts" />
  <File name="06-action-executor.step.ts" />
</Folder>

<Tabs items={['content-submit', 'content-analyzer', 'content-router', 'slack-notifier', 'slack-webhook', 'action-executor']}>
  <Tab value="content-submit">
    The entry point for content moderation. This API endpoint receives user-generated content (text and/or images) and initiates the moderation workflow.

    ```typescript
    import { z } from "zod";
    import { type Handlers, type StepConfig } from "motia";

    const ContentSubmitInputSchema = z.object({
      text: z.string().optional(),
      imageUrl: z.string().optional(),
      userId: z.string(),
      platform: z.string(),
    });

    export const config = {
      name: "ContentSubmitAPI",
      description: "Receives user-generated content for moderation",
      triggers: [
        { type: "http", path: "/content/submit", method: "POST", bodySchema: ContentSubmitInputSchema },
      ],
      enqueues: ["content.submitted"],
      flows: ["content-moderation"],
    } as const satisfies StepConfig;

    export const handler: Handlers<typeof config> = async (
      req,
      { logger, enqueue }
    ) => {
      const { text, imageUrl, userId, platform } = req.body;
      const submissionId = `sub_${Date.now()}_${Math.random()
        .toString(36)
        .slice(2, 11)}`;

      logger.info(`Content submitted for moderation`, {
        submissionId,
        hasText: !!text,
        hasImage: !!imageUrl,
        userId,
        platform,
      });

      await enqueue({
        topic: "content.submitted",
        data: {
          submissionId,
          text,
          imageUrl,
          userId,
          platform,
          timestamp: new Date().toISOString(),
        },
      });

      return {
        status: 200,
        body: {
          message: "Content submitted for moderation",
          submissionId,
        },
      };
    };
    ```

  </Tab>
  <Tab value="content-analyzer">
    The AI analysis engine that processes both text and image content using OpenAI's advanced models to determine content safety and risk levels.

    ```typescript
    import { z } from "zod";
    import { type Handlers, type StepConfig } from "motia";
    import OpenAI from "openai";

    const openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
    });

    export const config = {
      name: "ContentAnalyzer",
      description: "Analyzes content using OpenAI for toxicity and safety",
      triggers: [
        { type: "queue", topic: "content.submitted", input: z.object({
          submissionId: z.string(),
          text: z.string().optional(),
          imageUrl: z.string().optional(),
          userId: z.string(),
          platform: z.string(),
          timestamp: z.string(),
        }) },
      ],
      enqueues: ["content.analyzed"],
      flows: ["content-moderation"],
    } as const satisfies StepConfig;

    export const handler: Handlers<typeof config> = async (
      input,
      { logger, enqueue }
    ) => {
      const { submissionId, text, imageUrl, userId } = input;
      
      logger.info("Starting content analysis", { submissionId, hasText: !!text, hasImage: !!imageUrl });

      let textScore = 0;
      let imageScore = 0;
      let textAnalysis = "";
      let imageAnalysis = "";

      // Analyze text content if present
      if (text) {
        try {
          const textResponse = await openai.chat.completions.create({
            model: "gpt-4",
            messages: [
              {
                role: "system",
                content: `You are a content moderation AI. Analyze the following text for toxicity, hate speech, violence, harassment, or inappropriate content. 
                Respond with a JSON object containing:
                - "score": a number between 0-1 where 0 is completely safe and 1 is extremely harmful
                - "analysis": a brief explanation of your assessment
                - "categories": array of detected issues (e.g., ["hate_speech", "violence"])`
              },
              {
                role: "user",
                content: text
              }
            ],
            temperature: 0.1,
          });

          const textResult = JSON.parse(textResponse.choices[0]?.message?.content || "{}");
          textScore = textResult.score || 0;
          textAnalysis = textResult.analysis || "";
        } catch (error) {
          logger.error("Text analysis failed", { error, submissionId });
        }
      }

      // Analyze image content if present
      if (imageUrl) {
        try {
          const imageResponse = await openai.chat.completions.create({
            model: "gpt-4o",
            messages: [
              {
                role: "system",
                content: `You are a content moderation AI. Analyze the following image for inappropriate content, violence, nudity, or harmful material.
                Respond with a JSON object containing:
                - "score": a number between 0-1 where 0 is completely safe and 1 is extremely harmful
                - "analysis": a brief explanation of your assessment
                - "categories": array of detected issues (e.g., ["violence", "inappropriate"])`
              },
              {
                role: "user",
                content: [
                  {
                    type: "text",
                    text: "Analyze this image for content moderation:"
                  },
                  {
                    type: "image_url",
                    image_url: { url: imageUrl }
                  }
                ]
              }
            ],
            temperature: 0.1,
          });

          const imageResult = JSON.parse(imageResponse.choices[0]?.message?.content || "{}");
          imageScore = imageResult.score || 0;
          imageAnalysis = imageResult.analysis || "";
        } catch (error) {
          logger.error("Image analysis failed", { error, submissionId });
        }
      }

      // Calculate overall risk score
      const overallScore = Math.max(textScore, imageScore);
      
      const analysisResult = {
        submissionId,
        userId,
        textScore,
        imageScore,
        overallScore,
        textAnalysis,
        imageAnalysis,
        analyzedAt: new Date().toISOString(),
      };

      logger.info("Content analysis completed", {
        submissionId,
        overallScore,
        textScore,
        imageScore,
      });

      await enqueue({
        topic: "content.analyzed",
        data: analysisResult,
      });
    };
    ```

  </Tab>
  <Tab value="content-router">
    The intelligent routing system that determines whether content should be automatically approved/rejected or sent for human review based on confidence scores.

    ```typescript
    import { z } from "zod";
    import { type Handlers, type StepConfig } from "motia";

    export const config = {
      name: "ContentRouter",
      description: "Routes content based on AI analysis confidence scores",
      triggers: [
        { type: "queue", topic: "content.analyzed", input: z.object({
          submissionId: z.string(),
          userId: z.string(),
          textScore: z.number(),
          imageScore: z.number(),
          overallScore: z.number(),
          textAnalysis: z.string(),
          imageAnalysis: z.string(),
          analyzedAt: z.string(),
        }) },
      ],
      enqueues: ["content.auto.approved", "content.auto.rejected", "content.needs.review"],
      flows: ["content-moderation"],
    } as const satisfies StepConfig;

    export const handler: Handlers<typeof config> = async (
      input,
      { logger, enqueue }
    ) => {
      const { submissionId, userId, overallScore, textAnalysis, imageAnalysis } = input;
      
      logger.info("Routing content based on analysis", { 
        submissionId, 
        overallScore,
        userId 
      });

      let decision: string;
      let routingData = {
        submissionId,
        userId,
        overallScore,
        textAnalysis,
        imageAnalysis,
        routedAt: new Date().toISOString(),
      };

      // Decision logic based on confidence scores
      if (overallScore <= 0.05) {
        // Very low risk - auto approve
        decision = "approved";
        logger.info("Content auto-approved", { submissionId, overallScore });
        
        await enqueue({
          topic: "content.auto.approved",
          data: {
            ...routingData,
            decision,
            reason: "Low risk score - automatically approved",
          },
        });
        
      } else if (overallScore >= 0.95) {
        // Very high risk - auto reject
        decision = "rejected";
        logger.info("Content auto-rejected", { submissionId, overallScore });
        
        await enqueue({
          topic: "content.auto.rejected",
          data: {
            ...routingData,
            decision,
            reason: "High risk score - automatically rejected",
          },
        });
        
      } else {
        // Medium risk - needs human review
        decision = "review";
        logger.info("Content needs human review", { submissionId, overallScore });
        
        await enqueue({
          topic: "content.needs.review",
          data: {
            ...routingData,
            decision,
            reason: "Medium risk score - requires human review",
            priority: overallScore >= 0.7 ? "high" : overallScore >= 0.5 ? "medium" : "low",
          },
        });
      }
    };
    ```

  </Tab>
  <Tab value="slack-notifier">
    Creates interactive Slack messages for human moderators with approve/reject/escalate buttons and contextual information.

    ```typescript
    import { z } from "zod";
    import { type Handlers, type StepConfig } from "motia";
    import { WebClient } from "@slack/web-api";

    const slack = new WebClient(process.env.SLACK_BOT_TOKEN);

    export const config = {
      name: "SlackNotifier",
      description: "Sends interactive Slack messages for human review",
      triggers: [
        { type: "queue", topic: "content.needs.review", input: z.object({
          submissionId: z.string(),
          userId: z.string(),
          overallScore: z.number(),
          textAnalysis: z.string(),
          imageAnalysis: z.string(),
          decision: z.string(),
          reason: z.string(),
          priority: z.enum(["low", "medium", "high"]),
          routedAt: z.string(),
        }) },
      ],
      enqueues: ["slack.notification.sent"],
      flows: ["content-moderation"],
    } as const satisfies StepConfig;

    export const handler: Handlers<typeof config> = async (
      input,
      { logger, enqueue }
    ) => {
      const { submissionId, userId, overallScore, textAnalysis, imageAnalysis, priority } = input;
      
      logger.info("Sending Slack notification for review", { 
        submissionId, 
        priority,
        userId 
      });

      // Determine channel based on priority
      let channel: string;
      switch (priority) {
        case "high":
          channel = process.env.SLACK_CHANNEL_URGENT!;
          break;
        case "medium":
          channel = process.env.SLACK_CHANNEL_ESCALATED!;
          break;
        default:
          channel = process.env.SLACK_CHANNEL_MODERATION!;
      }

      // Create interactive message with buttons
      const message = {
        channel,
        text: `Content Moderation Review Required`,
        blocks: [
          {
            type: "header",
            text: {
              type: "plain_text",
              text: `🚨 Content Review - ${priority.toUpperCase()} Priority`,
            },
          },
          {
            type: "section",
            fields: [
              {
                type: "mrkdwn",
                text: `*Submission ID:*\n${submissionId}`,
              },
              {
                type: "mrkdwn",
                text: `*User ID:*\n${userId}`,
              },
              {
                type: "mrkdwn",
                text: `*Risk Score:*\n${(overallScore * 100).toFixed(1)}%`,
              },
              {
                type: "mrkdwn",
                text: `*Priority:*\n${priority.toUpperCase()}`,
              },
            ],
          },
          {
            type: "section",
            text: {
              type: "mrkdwn",
              text: `*AI Analysis:*\n${textAnalysis || imageAnalysis || "No analysis available"}`,
            },
          },
          {
            type: "actions",
            elements: [
              {
                type: "button",
                text: {
                  type: "plain_text",
                  text: "✅ Approve",
                },
                style: "primary",
                action_id: "approve_content",
                value: submissionId,
              },
              {
                type: "button",
                text: {
                  type: "plain_text",
                  text: "❌ Reject",
                },
                style: "danger",
                action_id: "reject_content",
                value: submissionId,
              },
              {
                type: "button",
                text: {
                  type: "plain_text",
                  text: "⚠️ Escalate",
                },
                action_id: "escalate_content",
                value: submissionId,
              },
            ],
          },
        ],
      };

      try {
        const result = await slack.chat.postMessage(message);
        
        logger.info("Slack notification sent successfully", {
          submissionId,
          channel,
          messageTs: result.ts,
        });

        await enqueue({
          topic: "slack.notification.sent",
          data: {
            submissionId,
            userId,
            channel,
            messageTs: result.ts,
            priority,
            sentAt: new Date().toISOString(),
          },
        });

      } catch (error) {
        logger.error("Failed to send Slack notification", {
          error,
          submissionId,
          channel,
        });
        throw error;
      }
    };
    ```

  </Tab>
  <Tab value="slack-webhook">
    Handles interactive button responses from Slack, processing approve/reject/escalate decisions from human moderators.

    ```typescript
    import { z } from "zod";
    import { type Handlers, type StepConfig } from "motia";
    import { createHmac } from "crypto";

    export const config = {
      name: "SlackWebhook",
      description: "Handles Slack interactive button responses",
      triggers: [
        { type: "http", path: "/slack/webhook", method: "POST" },
      ],
      enqueues: ["slack.decision.received"],
      flows: ["content-moderation"],
    } as const satisfies StepConfig;

    export const handler: Handlers<typeof config> = async (
      req,
      { logger, enqueue }
    ) => {
      // Verify Slack signature
      const signature = req.headers["x-slack-signature"] as string;
      const timestamp = req.headers["x-slack-request-timestamp"] as string;
      const body = req.body;

      if (!verifySlackSignature(signature, timestamp, body)) {
        logger.error("Invalid Slack signature");
        return { status: 401, body: { error: "Unauthorized" } };
      }

      const payload = JSON.parse(body.payload);
      const { actions, user, message } = payload;

      if (!actions || actions.length === 0) {
        return { status: 200, body: { text: "No action received" } };
      }

      const action = actions[0];
      const submissionId = action.value;
      const decision = action.action_id.replace("_content", "");
      const moderatorId = user.id;
      const moderatorName = user.name;

      logger.info("Slack decision received", {
        submissionId,
        decision,
        moderatorId,
        moderatorName,
      });

      await enqueue({
        topic: "slack.decision.received",
        data: {
          submissionId,
          decision,
          moderatorId,
          moderatorName,
          messageTs: message.ts,
          decidedAt: new Date().toISOString(),
        },
      });

      // Update the original message to show decision
      const responseMessage = `✅ Decision recorded: ${decision.toUpperCase()} by ${moderatorName}`;
      
      return {
        status: 200,
        body: {
          text: responseMessage,
          replace_original: false,
        },
      };
    };

    function verifySlackSignature(signature: string, timestamp: string, body: string): boolean {
      const requestAge = Math.abs(Date.now() / 1000 - Number(timestamp))
      if (requestAge > 300) return false

      const signingSecret = process.env.SLACK_SIGNING_SECRET!;
      const baseString = `v0:${timestamp}:${body}`;
      const expectedSignature = `v0=${createHmac("sha256", signingSecret)
        .update(baseString)
        .digest("hex")}`;
      
      return crypto.timingSafeEqual(
        Buffer.from(signature),
        Buffer.from(expectedSignature)
      );
    }
    ```

  </Tab>
  <Tab value="action-executor">
    Executes the final moderation decisions, handling both automated and human-reviewed content with comprehensive logging and state management.

    ```typescript
    import { z } from "zod";
    import { type Handlers, type StepConfig } from "motia";

    export const config = {
      name: "ActionExecutor",
      description: "Executes final moderation decisions",
      triggers: [
        { type: "queue", topic: "content.auto.approved" },
        { type: "queue", topic: "content.auto.rejected" },
        { type: "queue", topic: "slack.decision.received", input: z.object({
          submissionId: z.string(),
          decision: z.enum(["approved", "rejected", "escalated"]),
          reason: z.string(),
          moderatorId: z.string().optional(),
          moderatorName: z.string().optional(),
          decidedAt: z.string(),
        }) },
      ],
      enqueues: ["content.moderation.completed"],
      flows: ["content-moderation"],
    } as const satisfies StepConfig;

    export const handler: Handlers<typeof config> = async (
      input,
      { logger, enqueue, state }
    ) => {
      const { submissionId, decision, reason, moderatorId, moderatorName, decidedAt } = input;
      
      logger.info("Executing moderation decision", {
        submissionId,
        decision,
        moderatorId,
        moderatorName,
      });

      // Store the final decision in state
      const moderationRecord = {
        submissionId,
        decision,
        reason,
        moderatorId,
        moderatorName,
        decidedAt,
        executedAt: new Date().toISOString(),
      };

      await state.set("moderation", submissionId, moderationRecord);

      // Execute the appropriate action based on decision
      switch (decision) {
        case "approved":
          logger.info("Content approved", { submissionId });
          // Here you would typically:
          // - Make content visible to users
          // - Send approval notification to user
          // - Update content status in database
          break;

        case "rejected":
          logger.info("Content rejected", { submissionId });
          // Here you would typically:
          // - Hide or remove content
          // - Send rejection notification to user
          // - Log for potential user action
          break;

        case "escalated":
          logger.info("Content escalated", { submissionId });
          // Here you would typically:
          // - Send to higher-level moderators
          // - Create support ticket
          // - Flag for additional review
          break;
      }

      await enqueue({
        topic: "content.moderation.completed",
        data: moderationRecord,
      });

      logger.info("Moderation decision executed successfully", {
        submissionId,
        decision,
        moderatorId,
      });
    };
    ```

  </Tab>
</Tabs>

---

## Explore the Workflow

The [iii development console](https://iii.dev/docs) provides a visual representation of your content moderation pipeline, making it easy to understand the flow and monitor moderation decisions in real-time.

<div className="my-8">![AI Content Moderation Workflow](./../img/ai-content-moderation-workflow.png)</div>

You can monitor real-time content analysis, view Slack notifications, and trace the execution of each moderation decision directly in the iii development console. This makes development and debugging significantly easier compared to traditional monolithic moderation systems.

## Human-in-the-Loop Workflow Demo

Let's see the complete human-in-the-loop process in action using a real example. We'll submit problematic content and watch it flow through the moderation pipeline.

### Step 1: Submit Content for Moderation

Submit the sample content that should trigger human review:

```shell
curl -X POST http://localhost:3111/content/submit \
  -H "Content-Type: application/json" \
  -d '{
    "text": "I hate this stupid garbage, it\'s complete trash and makes me want to hurt someone",
    "userId": "user456",
    "platform": "web"
  }'
```

### Step 2: AI Analysis & Routing

The system will:
1. **Analyze the content** using OpenAI's GPT-4 for toxicity detection
2. **Calculate risk scores** based on detected harmful content
3. **Route for human review** since the content contains hate speech and violence references

You'll see logs like:
```
Content submitted for moderation: submissionId=sub_123, hasText=true, userId=user456
Starting content analysis: submissionId=sub_123, hasText=true
Content analysis completed: submissionId=sub_123, overallScore=0.87, textScore=0.87
Content needs human review: submissionId=sub_123, overallScore=0.87
```

### Step 3: Slack Notification for Human Review

The system automatically sends an interactive message to your moderation team in Slack:

<div className="my-8">![AI Content Moderation Slack Output](./../img/ai-content-moderation-slack-output.png)</div>

The Slack message includes:
- **Risk score**: 87% confidence of harmful content
- **Priority level**: HIGH (since score ≥ 70%)
- **AI analysis**: Detailed breakdown of detected issues
- **Interactive buttons**: Approve, Reject, or Escalate options

### Step 4: Human Decision & Execution

When a moderator clicks a button in Slack:
1. **Decision is recorded** with moderator attribution
2. **Content is processed** according to the decision
3. **User is notified** of the moderation outcome
4. **Audit trail is maintained** for compliance

The complete workflow demonstrates how AI handles the initial analysis while humans provide the final judgment for nuanced decisions.

---

## Key Features & Benefits

### 🤖 **AI-Powered Analysis**
Advanced OpenAI integration for both text toxicity detection and image safety analysis with confidence scoring.

### 🎯 **Intelligent Routing**
Confidence-based decision making that automatically handles clear cases while flagging uncertain content for human review.

### 💬 **Slack Integration**
Interactive moderation workflows within existing team communication tools - no custom dashboard required.

### 👥 **Human-in-the-Loop**
Seamless integration of human decision-making with approve/reject/escalate buttons and contextual information.

### 📊 **Priority-Based Routing**
Content is routed to different Slack channels based on risk level and urgency.

### 🔒 **Security & Compliance**
Built-in signature verification, audit trails, and comprehensive logging for compliance requirements.

---

## Getting Started

Ready to build your own intelligent content moderation system? Here's how to set it up and run it.

<Steps>

### 1. Install Dependencies

Install the necessary npm packages and set up the development environment.

```shell
npm install
```

### 2. Configure Environment Variables

Create a `.env` file with your API keys and Slack configuration:

```shell
# Required: OpenAI API key for content analysis
OPENAI_API_KEY="sk-..."

# Required: Slack bot configuration
SLACK_BOT_TOKEN="xoxb-your-bot-token"
SLACK_SIGNING_SECRET="your-signing-secret"

# Required: Slack channels for different priority levels
SLACK_CHANNEL_MODERATION="C1234567890"  # Normal priority
SLACK_CHANNEL_URGENT="C0987654321"      # High priority
SLACK_CHANNEL_ESCALATED="C1122334455"   # Escalated content
```

### 3. Set Up Slack Integration

1. Create a Slack app with the following permissions:
   - `chat:write` - Send messages to channels
   - `channels:read` - Access channel information
2. Enable Interactive Components and set webhook URL to: `https://your-domain.com/slack/webhook`
3. Install the app to your workspace
4. Copy the bot token and signing secret to your `.env` file

### 4. Run the Moderation System

Start the Motia development server to begin processing content.

```shell
npm run dev
```

</Steps>

---

## Advanced Configuration

### Adjusting Confidence Thresholds

Modify the decision thresholds in the content router step:

```typescript
// In 03-content-router.step.ts
if (overallScore <= 0.05) {
  decision = "approved"; // Auto-approve threshold (5%)
} else if (overallScore >= 0.95) {
  decision = "rejected"; // Auto-reject threshold (95%)
} else {
  decision = "review"; // Human review range (5-95%)
}
```

### Custom Channel Routing

Implement custom routing logic based on content type or user behavior:

```typescript
// Route based on user history or content type
const channel = getChannelForContent(contentType, userHistory, riskScore);
```

### Integration with External Systems

Extend the action executor to integrate with your existing systems:

```typescript
// In 06-action-executor.step.ts
case "approved":
  await publishContent(submissionId);
  await notifyUser(userId, "Your content has been approved");
  break;
```

---

## 💻 Dive into the Code

Want to explore the complete content moderation implementation? Check out the full source code, including all steps, Slack integration, and production-ready configuration:

<div className="not-prose">
  <div className="bg-gradient-to-r from-purple-50 to-pink-50 border border-purple-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-purple-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Complete Content Moderation System</h3>
        <p className="text-gray-600 mb-4">Access the full implementation with AI analysis, Slack integration, and human-in-the-loop workflows.</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/ai-agents/specialized-agents/ai-content-moderation" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-purple-600 hover:bg-purple-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.30.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            View Content Moderation Example
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            More Examples →
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Conclusion: Intelligent Content Moderation at Scale

This content moderation system demonstrates the power of combining AI analysis with human oversight in an event-driven architecture. By breaking down moderation into discrete, specialized components, we've created a system that's not only intelligent but also flexible and maintainable.

The human-in-the-loop approach means you can:
- **Scale efficiently**: Automatically handle 80-90% of content while maintaining quality
- **Adapt quickly**: Adjust thresholds and routing logic without system changes
- **Maintain oversight**: Human moderators focus on complex cases that require judgment
- **Integrate seamlessly**: Use existing team communication tools like Slack

Key architectural benefits:
- **Intelligent routing**: Confidence-based decisions reduce human workload
- **Flexible integration**: Works with any team communication platform
- **Audit compliance**: Complete decision trails and moderator attribution
- **Scalable architecture**: Each component can be scaled independently

From here, you can extend the system by:
- Adding support for video content moderation
- Implementing custom AI models for specific content types
- Building analytics dashboards for moderation insights
- Integrating with user management and content management systems
- Adding escalation policies and moderator workflows

The event-driven architecture makes all of these extensions straightforward to implement without disrupting the existing moderation pipeline.

Ready to build content moderation that scales with your platform? Start building with Motia today!



## Examples
[ai-content-moderation](/docs/examples/ai-content-moderation): Code example
---
title: 'AI Content Moderation'
description: 'Intelligent Content Moderation: Building Human-in-the-Loop Systems with Motia'
---

In today's digital landscape, content moderation is crucial for maintaining safe and appropriate user experiences. Whether you're building a social platform, forum, or any user-generated content system, you need intelligent moderation that can scale with your user base while maintaining human oversight for complex decisions.

This comprehensive guide explores how to build a production-ready content moderation system using Motia's event-driven architecture. We'll cover:

1. **AI-Powered Analysis**: Using OpenAI for text toxicity detection and image safety analysis
2. **Confidence-Based Routing**: Automatically handling clear cases while flagging uncertain content for human review
3. **Slack Integration**: Creating interactive moderation workflows within existing team communication tools
4. **Human-in-the-Loop**: Seamlessly integrating human decision-making into automated processes

Let's build a content moderation system that scales intelligently.

---

## Workflow Overview

<div className="my-8">![AI Content Moderation Workflow](./../img/ai-content-moderation-workflow.png)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/ai-agents/specialized-agents/ai-content-moderation)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## The Power of Intelligent Content Moderation

At its core, our content moderation system solves a fundamental challenge: how do you efficiently moderate user-generated content at scale while maintaining human oversight for complex decisions? Traditional approaches often involve either fully manual processes that don't scale or fully automated systems that lack nuance.

Our Motia-powered solution combines the best of both worlds through intelligent routing:

- **[OpenAI Integration](https://openai.com/)**: Advanced AI analysis for text toxicity and image safety detection
- **[Confidence-Based Routing](https://en.wikipedia.org/wiki/Confidence_interval)**: Automatic handling of clear cases, human review for uncertain content
- **[Slack Integration](https://api.slack.com/)**: Interactive moderation workflows within existing team communication tools
- **[Motia Framework](https://motia.dev)**: Event-driven orchestration with built-in state management and error handling

Instead of a monolithic moderation system, we get a flexible architecture where each component can be scaled, modified, or replaced independently.

---

## The Anatomy of Our Content Moderation System

Our application consists of six specialized steps, each handling a specific part of the moderation workflow. Let's explore the complete architecture.

<Folder name="steps" defaultOpen>
  <File name="01-content-submit.step.ts" />
  <File name="02-content-analyzer.step.ts" />
  <File name="03-content-router.step.ts" />
  <File name="04-slack-notifier.step.ts" />
  <File name="05-slack-webhook.step.ts" />
  <File name="06-action-executor.step.ts" />
</Folder>

<Tabs items={['content-submit', 'content-analyzer', 'content-router', 'slack-notifier', 'slack-webhook', 'action-executor']}>
  <Tab value="content-submit">
    The entry point for content moderation. This API endpoint receives user-generated content (text and/or images) and initiates the moderation workflow.

    ```typescript
    import { z } from "zod";
    import { type Handlers, type StepConfig } from "motia";

    const ContentSubmitInputSchema = z.object({
      text: z.string().optional(),
      imageUrl: z.string().optional(),
      userId: z.string(),
      platform: z.string(),
    });

    export const config = {
      name: "ContentSubmitAPI",
      description: "Receives user-generated content for moderation",
      triggers: [
        { type: "http", path: "/content/submit", method: "POST", bodySchema: ContentSubmitInputSchema },
      ],
      enqueues: ["content.submitted"],
      flows: ["content-moderation"],
    } as const satisfies StepConfig;

    export const handler: Handlers<typeof config> = async (
      req,
      { logger, enqueue }
    ) => {
      const { text, imageUrl, userId, platform } = req.body;
      const submissionId = `sub_${Date.now()}_${Math.random()
        .toString(36)
        .slice(2, 11)}`;

      logger.info(`Content submitted for moderation`, {
        submissionId,
        hasText: !!text,
        hasImage: !!imageUrl,
        userId,
        platform,
      });

      await enqueue({
        topic: "content.submitted",
        data: {
          submissionId,
          text,
          imageUrl,
          userId,
          platform,
          timestamp: new Date().toISOString(),
        },
      });

      return {
        status: 200,
        body: {
          message: "Content submitted for moderation",
          submissionId,
        },
      };
    };
    ```

  </Tab>
  <Tab value="content-analyzer">
    The AI analysis engine that processes both text and image content using OpenAI's advanced models to determine content safety and risk levels.

    ```typescript
    import { z } from "zod";
    import { type Handlers, type StepConfig } from "motia";
    import OpenAI from "openai";

    const openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
    });

    export const config = {
      name: "ContentAnalyzer",
      description: "Analyzes content using OpenAI for toxicity and safety",
      triggers: [
        { type: "queue", topic: "content.submitted", input: z.object({
          submissionId: z.string(),
          text: z.string().optional(),
          imageUrl: z.string().optional(),
          userId: z.string(),
          platform: z.string(),
          timestamp: z.string(),
        }) },
      ],
      enqueues: ["content.analyzed"],
      flows: ["content-moderation"],
    } as const satisfies StepConfig;

    export const handler: Handlers<typeof config> = async (
      input,
      { logger, enqueue }
    ) => {
      const { submissionId, text, imageUrl, userId } = input;
      
      logger.info("Starting content analysis", { submissionId, hasText: !!text, hasImage: !!imageUrl });

      let textScore = 0;
      let imageScore = 0;
      let textAnalysis = "";
      let imageAnalysis = "";

      // Analyze text content if present
      if (text) {
        try {
          const textResponse = await openai.chat.completions.create({
            model: "gpt-4",
            messages: [
              {
                role: "system",
                content: `You are a content moderation AI. Analyze the following text for toxicity, hate speech, violence, harassment, or inappropriate content. 
                Respond with a JSON object containing:
                - "score": a number between 0-1 where 0 is completely safe and 1 is extremely harmful
                - "analysis": a brief explanation of your assessment
                - "categories": array of detected issues (e.g., ["hate_speech", "violence"])`
              },
              {
                role: "user",
                content: text
              }
            ],
            temperature: 0.1,
          });

          const textResult = JSON.parse(textResponse.choices[0]?.message?.content || "{}");
          textScore = textResult.score || 0;
          textAnalysis = textResult.analysis || "";
        } catch (error) {
          logger.error("Text analysis failed", { error, submissionId });
        }
      }

      // Analyze image content if present
      if (imageUrl) {
        try {
          const imageResponse = await openai.chat.completions.create({
            model: "gpt-4o",
            messages: [
              {
                role: "system",
                content: `You are a content moderation AI. Analyze the following image for inappropriate content, violence, nudity, or harmful material.
                Respond with a JSON object containing:
                - "score": a number between 0-1 where 0 is completely safe and 1 is extremely harmful
                - "analysis": a brief explanation of your assessment
                - "categories": array of detected issues (e.g., ["violence", "inappropriate"])`
              },
              {
                role: "user",
                content: [
                  {
                    type: "text",
                    text: "Analyze this image for content moderation:"
                  },
                  {
                    type: "image_url",
                    image_url: { url: imageUrl }
                  }
                ]
              }
            ],
            temperature: 0.1,
          });

          const imageResult = JSON.parse(imageResponse.choices[0]?.message?.content || "{}");
          imageScore = imageResult.score || 0;
          imageAnalysis = imageResult.analysis || "";
        } catch (error) {
          logger.error("Image analysis failed", { error, submissionId });
        }
      }

      // Calculate overall risk score
      const overallScore = Math.max(textScore, imageScore);
      
      const analysisResult = {
        submissionId,
        userId,
        textScore,
        imageScore,
        overallScore,
        textAnalysis,
        imageAnalysis,
        analyzedAt: new Date().toISOString(),
      };

      logger.info("Content analysis completed", {
        submissionId,
        overallScore,
        textScore,
        imageScore,
      });

      await enqueue({
        topic: "content.analyzed",
        data: analysisResult,
      });
    };
    ```

  </Tab>
  <Tab value="content-router">
    The intelligent routing system that determines whether content should be automatically approved/rejected or sent for human review based on confidence scores.

    ```typescript
    import { z } from "zod";
    import { type Handlers, type StepConfig } from "motia";

    export const config = {
      name: "ContentRouter",
      description: "Routes content based on AI analysis confidence scores",
      triggers: [
        { type: "queue", topic: "content.analyzed", input: z.object({
          submissionId: z.string(),
          userId: z.string(),
          textScore: z.number(),
          imageScore: z.number(),
          overallScore: z.number(),
          textAnalysis: z.string(),
          imageAnalysis: z.string(),
          analyzedAt: z.string(),
        }) },
      ],
      enqueues: ["content.auto.approved", "content.auto.rejected", "content.needs.review"],
      flows: ["content-moderation"],
    } as const satisfies StepConfig;

    export const handler: Handlers<typeof config> = async (
      input,
      { logger, enqueue }
    ) => {
      const { submissionId, userId, overallScore, textAnalysis, imageAnalysis } = input;
      
      logger.info("Routing content based on analysis", { 
        submissionId, 
        overallScore,
        userId 
      });

      let decision: string;
      let routingData = {
        submissionId,
        userId,
        overallScore,
        textAnalysis,
        imageAnalysis,
        routedAt: new Date().toISOString(),
      };

      // Decision logic based on confidence scores
      if (overallScore <= 0.05) {
        // Very low risk - auto approve
        decision = "approved";
        logger.info("Content auto-approved", { submissionId, overallScore });
        
        await enqueue({
          topic: "content.auto.approved",
          data: {
            ...routingData,
            decision,
            reason: "Low risk score - automatically approved",
          },
        });
        
      } else if (overallScore >= 0.95) {
        // Very high risk - auto reject
        decision = "rejected";
        logger.info("Content auto-rejected", { submissionId, overallScore });
        
        await enqueue({
          topic: "content.auto.rejected",
          data: {
            ...routingData,
            decision,
            reason: "High risk score - automatically rejected",
          },
        });
        
      } else {
        // Medium risk - needs human review
        decision = "review";
        logger.info("Content needs human review", { submissionId, overallScore });
        
        await enqueue({
          topic: "content.needs.review",
          data: {
            ...routingData,
            decision,
            reason: "Medium risk score - requires human review",
            priority: overallScore >= 0.7 ? "high" : overallScore >= 0.5 ? "medium" : "low",
          },
        });
      }
    };
    ```

  </Tab>
  <Tab value="slack-notifier">
    Creates interactive Slack messages for human moderators with approve/reject/escalate buttons and contextual information.

    ```typescript
    import { z } from "zod";
    import { type Handlers, type StepConfig } from "motia";
    import { WebClient } from "@slack/web-api";

    const slack = new WebClient(process.env.SLACK_BOT_TOKEN);

    export const config = {
      name: "SlackNotifier",
      description: "Sends interactive Slack messages for human review",
      triggers: [
        { type: "queue", topic: "content.needs.review", input: z.object({
          submissionId: z.string(),
          userId: z.string(),
          overallScore: z.number(),
          textAnalysis: z.string(),
          imageAnalysis: z.string(),
          decision: z.string(),
          reason: z.string(),
          priority: z.enum(["low", "medium", "high"]),
          routedAt: z.string(),
        }) },
      ],
      enqueues: ["slack.notification.sent"],
      flows: ["content-moderation"],
    } as const satisfies StepConfig;

    export const handler: Handlers<typeof config> = async (
      input,
      { logger, enqueue }
    ) => {
      const { submissionId, userId, overallScore, textAnalysis, imageAnalysis, priority } = input;
      
      logger.info("Sending Slack notification for review", { 
        submissionId, 
        priority,
        userId 
      });

      // Determine channel based on priority
      let channel: string;
      switch (priority) {
        case "high":
          channel = process.env.SLACK_CHANNEL_URGENT!;
          break;
        case "medium":
          channel = process.env.SLACK_CHANNEL_ESCALATED!;
          break;
        default:
          channel = process.env.SLACK_CHANNEL_MODERATION!;
      }

      // Create interactive message with buttons
      const message = {
        channel,
        text: `Content Moderation Review Required`,
        blocks: [
          {
            type: "header",
            text: {
              type: "plain_text",
              text: `🚨 Content Review - ${priority.toUpperCase()} Priority`,
            },
          },
          {
            type: "section",
            fields: [
              {
                type: "mrkdwn",
                text: `*Submission ID:*\n${submissionId}`,
              },
              {
                type: "mrkdwn",
                text: `*User ID:*\n${userId}`,
              },
              {
                type: "mrkdwn",
                text: `*Risk Score:*\n${(overallScore * 100).toFixed(1)}%`,
              },
              {
                type: "mrkdwn",
                text: `*Priority:*\n${priority.toUpperCase()}`,
              },
            ],
          },
          {
            type: "section",
            text: {
              type: "mrkdwn",
              text: `*AI Analysis:*\n${textAnalysis || imageAnalysis || "No analysis available"}`,
            },
          },
          {
            type: "actions",
            elements: [
              {
                type: "button",
                text: {
                  type: "plain_text",
                  text: "✅ Approve",
                },
                style: "primary",
                action_id: "approve_content",
                value: submissionId,
              },
              {
                type: "button",
                text: {
                  type: "plain_text",
                  text: "❌ Reject",
                },
                style: "danger",
                action_id: "reject_content",
                value: submissionId,
              },
              {
                type: "button",
                text: {
                  type: "plain_text",
                  text: "⚠️ Escalate",
                },
                action_id: "escalate_content",
                value: submissionId,
              },
            ],
          },
        ],
      };

      try {
        const result = await slack.chat.postMessage(message);
        
        logger.info("Slack notification sent successfully", {
          submissionId,
          channel,
          messageTs: result.ts,
        });

        await enqueue({
          topic: "slack.notification.sent",
          data: {
            submissionId,
            userId,
            channel,
            messageTs: result.ts,
            priority,
            sentAt: new Date().toISOString(),
          },
        });

      } catch (error) {
        logger.error("Failed to send Slack notification", {
          error,
          submissionId,
          channel,
        });
        throw error;
      }
    };
    ```

  </Tab>
  <Tab value="slack-webhook">
    Handles interactive button responses from Slack, processing approve/reject/escalate decisions from human moderators.

    ```typescript
    import { z } from "zod";
    import { type Handlers, type StepConfig } from "motia";
    import { createHmac } from "crypto";

    export const config = {
      name: "SlackWebhook",
      description: "Handles Slack interactive button responses",
      triggers: [
        { type: "http", path: "/slack/webhook", method: "POST" },
      ],
      enqueues: ["slack.decision.received"],
      flows: ["content-moderation"],
    } as const satisfies StepConfig;

    export const handler: Handlers<typeof config> = async (
      req,
      { logger, enqueue }
    ) => {
      // Verify Slack signature
      const signature = req.headers["x-slack-signature"] as string;
      const timestamp = req.headers["x-slack-request-timestamp"] as string;
      const body = req.body;

      if (!verifySlackSignature(signature, timestamp, body)) {
        logger.error("Invalid Slack signature");
        return { status: 401, body: { error: "Unauthorized" } };
      }

      const payload = JSON.parse(body.payload);
      const { actions, user, message } = payload;

      if (!actions || actions.length === 0) {
        return { status: 200, body: { text: "No action received" } };
      }

      const action = actions[0];
      const submissionId = action.value;
      const decision = action.action_id.replace("_content", "");
      const moderatorId = user.id;
      const moderatorName = user.name;

      logger.info("Slack decision received", {
        submissionId,
        decision,
        moderatorId,
        moderatorName,
      });

      await enqueue({
        topic: "slack.decision.received",
        data: {
          submissionId,
          decision,
          moderatorId,
          moderatorName,
          messageTs: message.ts,
          decidedAt: new Date().toISOString(),
        },
      });

      // Update the original message to show decision
      const responseMessage = `✅ Decision recorded: ${decision.toUpperCase()} by ${moderatorName}`;
      
      return {
        status: 200,
        body: {
          text: responseMessage,
          replace_original: false,
        },
      };
    };

    function verifySlackSignature(signature: string, timestamp: string, body: string): boolean {
      const requestAge = Math.abs(Date.now() / 1000 - Number(timestamp))
      if (requestAge > 300) return false

      const signingSecret = process.env.SLACK_SIGNING_SECRET!;
      const baseString = `v0:${timestamp}:${body}`;
      const expectedSignature = `v0=${createHmac("sha256", signingSecret)
        .update(baseString)
        .digest("hex")}`;
      
      return crypto.timingSafeEqual(
        Buffer.from(signature),
        Buffer.from(expectedSignature)
      );
    }
    ```

  </Tab>
  <Tab value="action-executor">
    Executes the final moderation decisions, handling both automated and human-reviewed content with comprehensive logging and state management.

    ```typescript
    import { z } from "zod";
    import { type Handlers, type StepConfig } from "motia";

    export const config = {
      name: "ActionExecutor",
      description: "Executes final moderation decisions",
      triggers: [
        { type: "queue", topic: "content.auto.approved" },
        { type: "queue", topic: "content.auto.rejected" },
        { type: "queue", topic: "slack.decision.received", input: z.object({
          submissionId: z.string(),
          decision: z.enum(["approved", "rejected", "escalated"]),
          reason: z.string(),
          moderatorId: z.string().optional(),
          moderatorName: z.string().optional(),
          decidedAt: z.string(),
        }) },
      ],
      enqueues: ["content.moderation.completed"],
      flows: ["content-moderation"],
    } as const satisfies StepConfig;

    export const handler: Handlers<typeof config> = async (
      input,
      { logger, enqueue, state }
    ) => {
      const { submissionId, decision, reason, moderatorId, moderatorName, decidedAt } = input;
      
      logger.info("Executing moderation decision", {
        submissionId,
        decision,
        moderatorId,
        moderatorName,
      });

      // Store the final decision in state
      const moderationRecord = {
        submissionId,
        decision,
        reason,
        moderatorId,
        moderatorName,
        decidedAt,
        executedAt: new Date().toISOString(),
      };

      await state.set("moderation", submissionId, moderationRecord);

      // Execute the appropriate action based on decision
      switch (decision) {
        case "approved":
          logger.info("Content approved", { submissionId });
          // Here you would typically:
          // - Make content visible to users
          // - Send approval notification to user
          // - Update content status in database
          break;

        case "rejected":
          logger.info("Content rejected", { submissionId });
          // Here you would typically:
          // - Hide or remove content
          // - Send rejection notification to user
          // - Log for potential user action
          break;

        case "escalated":
          logger.info("Content escalated", { submissionId });
          // Here you would typically:
          // - Send to higher-level moderators
          // - Create support ticket
          // - Flag for additional review
          break;
      }

      await enqueue({
        topic: "content.moderation.completed",
        data: moderationRecord,
      });

      logger.info("Moderation decision executed successfully", {
        submissionId,
        decision,
        moderatorId,
      });
    };
    ```

  </Tab>
</Tabs>

---

## Explore the Workflow

The [iii development console](https://iii.dev/docs) provides a visual representation of your content moderation pipeline, making it easy to understand the flow and monitor moderation decisions in real-time.

<div className="my-8">![AI Content Moderation Workflow](./../img/ai-content-moderation-workflow.png)</div>

You can monitor real-time content analysis, view Slack notifications, and trace the execution of each moderation decision directly in the iii development console. This makes development and debugging significantly easier compared to traditional monolithic moderation systems.

## Human-in-the-Loop Workflow Demo

Let's see the complete human-in-the-loop process in action using a real example. We'll submit problematic content and watch it flow through the moderation pipeline.

### Step 1: Submit Content for Moderation

Submit the sample content that should trigger human review:

```shell
curl -X POST http://localhost:3111/content/submit \
  -H "Content-Type: application/json" \
  -d '{
    "text": "I hate this stupid garbage, it\'s complete trash and makes me want to hurt someone",
    "userId": "user456",
    "platform": "web"
  }'
```

### Step 2: AI Analysis & Routing

The system will:
1. **Analyze the content** using OpenAI's GPT-4 for toxicity detection
2. **Calculate risk scores** based on detected harmful content
3. **Route for human review** since the content contains hate speech and violence references

You'll see logs like:
```
Content submitted for moderation: submissionId=sub_123, hasText=true, userId=user456
Starting content analysis: submissionId=sub_123, hasText=true
Content analysis completed: submissionId=sub_123, overallScore=0.87, textScore=0.87
Content needs human review: submissionId=sub_123, overallScore=0.87
```

### Step 3: Slack Notification for Human Review

The system automatically sends an interactive message to your moderation team in Slack:

<div className="my-8">![AI Content Moderation Slack Output](./../img/ai-content-moderation-slack-output.png)</div>

The Slack message includes:
- **Risk score**: 87% confidence of harmful content
- **Priority level**: HIGH (since score ≥ 70%)
- **AI analysis**: Detailed breakdown of detected issues
- **Interactive buttons**: Approve, Reject, or Escalate options

### Step 4: Human Decision & Execution

When a moderator clicks a button in Slack:
1. **Decision is recorded** with moderator attribution
2. **Content is processed** according to the decision
3. **User is notified** of the moderation outcome
4. **Audit trail is maintained** for compliance

The complete workflow demonstrates how AI handles the initial analysis while humans provide the final judgment for nuanced decisions.

---

## Key Features & Benefits

### 🤖 **AI-Powered Analysis**
Advanced OpenAI integration for both text toxicity detection and image safety analysis with confidence scoring.

### 🎯 **Intelligent Routing**
Confidence-based decision making that automatically handles clear cases while flagging uncertain content for human review.

### 💬 **Slack Integration**
Interactive moderation workflows within existing team communication tools - no custom dashboard required.

### 👥 **Human-in-the-Loop**
Seamless integration of human decision-making with approve/reject/escalate buttons and contextual information.

### 📊 **Priority-Based Routing**
Content is routed to different Slack channels based on risk level and urgency.

### 🔒 **Security & Compliance**
Built-in signature verification, audit trails, and comprehensive logging for compliance requirements.

---

## Getting Started

Ready to build your own intelligent content moderation system? Here's how to set it up and run it.

<Steps>

### 1. Install Dependencies

Install the necessary npm packages and set up the development environment.

```shell
npm install
```

### 2. Configure Environment Variables

Create a `.env` file with your API keys and Slack configuration:

```shell
# Required: OpenAI API key for content analysis
OPENAI_API_KEY="sk-..."

# Required: Slack bot configuration
SLACK_BOT_TOKEN="xoxb-your-bot-token"
SLACK_SIGNING_SECRET="your-signing-secret"

# Required: Slack channels for different priority levels
SLACK_CHANNEL_MODERATION="C1234567890"  # Normal priority
SLACK_CHANNEL_URGENT="C0987654321"      # High priority
SLACK_CHANNEL_ESCALATED="C1122334455"   # Escalated content
```

### 3. Set Up Slack Integration

1. Create a Slack app with the following permissions:
   - `chat:write` - Send messages to channels
   - `channels:read` - Access channel information
2. Enable Interactive Components and set webhook URL to: `https://your-domain.com/slack/webhook`
3. Install the app to your workspace
4. Copy the bot token and signing secret to your `.env` file

### 4. Run the Moderation System

Start the Motia development server to begin processing content.

```shell
npm run dev
```

</Steps>

---

## Advanced Configuration

### Adjusting Confidence Thresholds

Modify the decision thresholds in the content router step:

```typescript
// In 03-content-router.step.ts
if (overallScore <= 0.05) {
  decision = "approved"; // Auto-approve threshold (5%)
} else if (overallScore >= 0.95) {
  decision = "rejected"; // Auto-reject threshold (95%)
} else {
  decision = "review"; // Human review range (5-95%)
}
```

### Custom Channel Routing

Implement custom routing logic based on content type or user behavior:

```typescript
// Route based on user history or content type
const channel = getChannelForContent(contentType, userHistory, riskScore);
```

### Integration with External Systems

Extend the action executor to integrate with your existing systems:

```typescript
// In 06-action-executor.step.ts
case "approved":
  await publishContent(submissionId);
  await notifyUser(userId, "Your content has been approved");
  break;
```

---

## 💻 Dive into the Code

Want to explore the complete content moderation implementation? Check out the full source code, including all steps, Slack integration, and production-ready configuration:

<div className="not-prose">
  <div className="bg-gradient-to-r from-purple-50 to-pink-50 border border-purple-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-purple-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Complete Content Moderation System</h3>
        <p className="text-gray-600 mb-4">Access the full implementation with AI analysis, Slack integration, and human-in-the-loop workflows.</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/ai-agents/specialized-agents/ai-content-moderation" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-purple-600 hover:bg-purple-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.30.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            View Content Moderation Example
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            More Examples →
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Conclusion: Intelligent Content Moderation at Scale

This content moderation system demonstrates the power of combining AI analysis with human oversight in an event-driven architecture. By breaking down moderation into discrete, specialized components, we've created a system that's not only intelligent but also flexible and maintainable.

The human-in-the-loop approach means you can:
- **Scale efficiently**: Automatically handle 80-90% of content while maintaining quality
- **Adapt quickly**: Adjust thresholds and routing logic without system changes
- **Maintain oversight**: Human moderators focus on complex cases that require judgment
- **Integrate seamlessly**: Use existing team communication tools like Slack

Key architectural benefits:
- **Intelligent routing**: Confidence-based decisions reduce human workload
- **Flexible integration**: Works with any team communication platform
- **Audit compliance**: Complete decision trails and moderator attribution
- **Scalable architecture**: Each component can be scaled independently

From here, you can extend the system by:
- Adding support for video content moderation
- Implementing custom AI models for specific content types
- Building analytics dashboards for moderation insights
- Integrating with user management and content management systems
- Adding escalation policies and moderator workflows

The event-driven architecture makes all of these extensions straightforward to implement without disrupting the existing moderation pipeline.

Ready to build content moderation that scales with your platform? Start building with Motia today!


-   [ai-deep-research-agent](/docs/examples/ai-deep-research-agent): Documentation for ai-deep-research-agent.
---
title: 'AI Research Agent'
description: A powerful research assistant that leverages the Motia Framework to perform comprehensive web research on any topic and any question.
---

---

## Workflow Overview

<div className="my-8">![AI Deep Research Agent](./../img/ai-deep-research-agent.png)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/ai-agents/specialized-agents/ai-deep-research-agent)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## The Steps

<Folder name="steps" defaultOpen>
  <File name="analyze-content.step.ts" />
  <File name="compile-report.step.ts" />
  <File name="extract-content.step.ts" />
  <File name="follow-up-research.step.ts" />
  <File name="generate-queries.step.ts" />
  <File name="report-api.step.ts" />
  <File name="research-api.step.ts" />
  <File name="search-web.step.ts" />
  <File name="status-api.step.ts" />
</Folder>

<Callout type="info">
This example uses the `steps/` directory, but you can also use `src/` or both. Motia discovers step files from either location automatically.
</Callout>

View the source code for each step in the [GitHub repository](https://github.com/MotiaDev/motia-examples/tree/main/examples/ai-agents/specialized-agents/ai-deep-research-agent).

## 🚀 Features

- **Deep Web Research**: Automatically searches the web, extracts content, and synthesizes findings
- **Iterative Research Process**: Supports multiple layers of research depth for comprehensive exploration
- **Event-Driven Architecture**: Built using Motia Framework's event system for robust workflow management
- **Parallel Processing**: Efficiently processes search results and content extraction
- **API Endpoints**: REST API access for initiating research and retrieving reports
- **Stateful Processing**: Maintains research state throughout the entire process

## 📋 Prerequisites

- Node.js v18 or later
- npm or pnpm
- API keys for:
  - [OpenAI](https://platform.openai.com/) (AI analysis)
  - [Firecrawl](https://www.firecrawl.dev/) (Web Crawler)

## 🛠️ Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/MotiaDev/motia-examples
   cd examples/ai-agents/specialized-agents/ai-deep-research-agent
   ```

2. Install dependencies:
   ```bash
   pnpm install
   # or
   npm install
   ```

3. Configure environment variables:
   ```bash
   cp .env.example .env
   ```

   Update `.env` with your API keys:
   ```bash
   # Required
   OPENAI_API_KEY=your-openai-api-key-here
   FIRECRAWL_API_KEY=your-firecrawl-api-key-here

   # Optional
   # OPENAI_MODEL=gpt-4o
   # FIRECRAWL_BASE_URL=http://your-firecrawl-instance-url
   ```

## 🏗️ Architecture

![AI Deep Research Agent](../img/ai-deep-research-agent.png)


## 🚦 API Endpoints

### Start Research

```
POST /research
Content-Type: application/json

{
  "query": "The research topic or question",
  "breadth": 4,  // Number of search queries to generate (1-10)
  "depth": 2     // Depth of research iterations (1-5)
}
```

Response:
```json
{
  "message": "Research process started",
  "requestId": "unique-trace-id"
}
```

### Check Research Status

```
GET /research/status?requestId=unique-trace-id
```

Response:
```json
{
  "message": "Research status retrieved successfully",
  "requestId": "unique-trace-id",
  "originalQuery": "The research topic or question",
  "status": "in-progress",
  "progress": {
    "currentDepth": 1,
    "totalDepth": 2,
    "percentComplete": 50
  },
  "reportAvailable": false
}
```

### Get Research Report

```
GET /research/report?requestId=unique-trace-id
```

Response:
```json
{
  "message": "Research report retrieved successfully",
  "report": {
    "title": "Research Report Title",
    "overview": "Executive summary...",
    "sections": [
      {
        "title": "Section Title",
        "content": "Section content..."
      }
    ],
    "keyTakeaways": [
      "Key takeaway 1",
      "Key takeaway 2"
    ],
    "sources": [
      {
        "title": "Source Title",
        "url": "Source URL"
      }
    ],
    "originalQuery": "The research topic or question",
    "metadata": {
      "depthUsed": 2,
      "completedAt": "2025-03-18T16:45:30Z"
    }
  },
  "requestId": "unique-trace-id"
}
```

## 🏃‍♂️ Running the Application

1. Start the development server:
   ```bash
   pnpm dev
   ```

2. Make a test request:
   ```bash
   curl --request POST \
   --url http://localhost:3111/research \
   --header 'Content-Type: application/json' \
   --data '{
      "query": "Advancements in renewable energy storage",
      "depth": 1,
      "breadth": 1
   }'
   ```
## 🙏 Acknowledgments

- [Motia Framework](https://motia.dev) for the event-driven workflow engine
- [OpenAI](https://platform.openai.com/) for AI analysis 
- [Firecrawl](https://www.firecrawl.dev/) for Web search and content extraction API


## Examples
[ai-deep-research-agent](/docs/examples/ai-deep-research-agent): Code example
---
title: 'AI Research Agent'
description: A powerful research assistant that leverages the Motia Framework to perform comprehensive web research on any topic and any question.
---

---

## Workflow Overview

<div className="my-8">![AI Deep Research Agent](./../img/ai-deep-research-agent.png)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/ai-agents/specialized-agents/ai-deep-research-agent)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## The Steps

<Folder name="steps" defaultOpen>
  <File name="analyze-content.step.ts" />
  <File name="compile-report.step.ts" />
  <File name="extract-content.step.ts" />
  <File name="follow-up-research.step.ts" />
  <File name="generate-queries.step.ts" />
  <File name="report-api.step.ts" />
  <File name="research-api.step.ts" />
  <File name="search-web.step.ts" />
  <File name="status-api.step.ts" />
</Folder>

<Callout type="info">
This example uses the `steps/` directory, but you can also use `src/` or both. Motia discovers step files from either location automatically.
</Callout>

View the source code for each step in the [GitHub repository](https://github.com/MotiaDev/motia-examples/tree/main/examples/ai-agents/specialized-agents/ai-deep-research-agent).

## 🚀 Features

- **Deep Web Research**: Automatically searches the web, extracts content, and synthesizes findings
- **Iterative Research Process**: Supports multiple layers of research depth for comprehensive exploration
- **Event-Driven Architecture**: Built using Motia Framework's event system for robust workflow management
- **Parallel Processing**: Efficiently processes search results and content extraction
- **API Endpoints**: REST API access for initiating research and retrieving reports
- **Stateful Processing**: Maintains research state throughout the entire process

## 📋 Prerequisites

- Node.js v18 or later
- npm or pnpm
- API keys for:
  - [OpenAI](https://platform.openai.com/) (AI analysis)
  - [Firecrawl](https://www.firecrawl.dev/) (Web Crawler)

## 🛠️ Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/MotiaDev/motia-examples
   cd examples/ai-agents/specialized-agents/ai-deep-research-agent
   ```

2. Install dependencies:
   ```bash
   pnpm install
   # or
   npm install
   ```

3. Configure environment variables:
   ```bash
   cp .env.example .env
   ```

   Update `.env` with your API keys:
   ```bash
   # Required
   OPENAI_API_KEY=your-openai-api-key-here
   FIRECRAWL_API_KEY=your-firecrawl-api-key-here

   # Optional
   # OPENAI_MODEL=gpt-4o
   # FIRECRAWL_BASE_URL=http://your-firecrawl-instance-url
   ```

## 🏗️ Architecture

![AI Deep Research Agent](../img/ai-deep-research-agent.png)


## 🚦 API Endpoints

### Start Research

```
POST /research
Content-Type: application/json

{
  "query": "The research topic or question",
  "breadth": 4,  // Number of search queries to generate (1-10)
  "depth": 2     // Depth of research iterations (1-5)
}
```

Response:
```json
{
  "message": "Research process started",
  "requestId": "unique-trace-id"
}
```

### Check Research Status

```
GET /research/status?requestId=unique-trace-id
```

Response:
```json
{
  "message": "Research status retrieved successfully",
  "requestId": "unique-trace-id",
  "originalQuery": "The research topic or question",
  "status": "in-progress",
  "progress": {
    "currentDepth": 1,
    "totalDepth": 2,
    "percentComplete": 50
  },
  "reportAvailable": false
}
```

### Get Research Report

```
GET /research/report?requestId=unique-trace-id
```

Response:
```json
{
  "message": "Research report retrieved successfully",
  "report": {
    "title": "Research Report Title",
    "overview": "Executive summary...",
    "sections": [
      {
        "title": "Section Title",
        "content": "Section content..."
      }
    ],
    "keyTakeaways": [
      "Key takeaway 1",
      "Key takeaway 2"
    ],
    "sources": [
      {
        "title": "Source Title",
        "url": "Source URL"
      }
    ],
    "originalQuery": "The research topic or question",
    "metadata": {
      "depthUsed": 2,
      "completedAt": "2025-03-18T16:45:30Z"
    }
  },
  "requestId": "unique-trace-id"
}
```

## 🏃‍♂️ Running the Application

1. Start the development server:
   ```bash
   pnpm dev
   ```

2. Make a test request:
   ```bash
   curl --request POST \
   --url http://localhost:3111/research \
   --header 'Content-Type: application/json' \
   --data '{
      "query": "Advancements in renewable energy storage",
      "depth": 1,
      "breadth": 1
   }'
   ```
## 🙏 Acknowledgments

- [Motia Framework](https://motia.dev) for the event-driven workflow engine
- [OpenAI](https://platform.openai.com/) for AI analysis 
- [Firecrawl](https://www.firecrawl.dev/) for Web search and content extraction API

-   [finance-agent](/docs/examples/finance-agent): Documentation for finance-agent.
---
title: 'Finance Agent'
description: A powerful event-driven financial analysis workflow that combines web search, financial data, and AI analysis to provide comprehensive investment insights.
---

---

## Workflow Overview

<div className="my-8">![Finance Agent](./../img/finance-agent.gif)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/ai-agents/specialized-agents/finance-agent)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## Let's build a finance agent that:

- Real-time Financial Analysis: Combines multiple data sources for comprehensive insights
- AI-Powered Insights: Leverages OpenAI GPT-4 for intelligent market analysis
- Web Search Integration: Aggregates latest market news and analysis
- Financial Data Integration: Real-time stock and company information

## The Steps

<Folder name="steps" defaultOpen>
  <File name="finance-data.step.ts" />
  <File name="openai-analysis.step.ts" />
  <File name="query-api.step.ts" />
  <File name="response-coordinator.step.ts" />
  <File name="result-api.step.ts" />
  <File name="save-result.step.ts" />
  <File name="web-search.step.ts" />
</Folder>

<Callout type="info">
This example uses the `steps/` directory, but you can also use `src/` or both. Motia discovers step files from either location automatically.
</Callout>

View the source code for each step in the [GitHub repository](https://github.com/MotiaDev/motia-examples/tree/main/examples/ai-agents/specialized-agents/finance-agent).

## 🚀 Features

- **Real-time Financial Analysis**: Combines multiple data sources for comprehensive insights
- **AI-Powered Insights**: Leverages OpenAI GPT-4 for intelligent market analysis
- **Event-Driven Architecture**: Built on Motia's robust event system for reliable processing
- **Web Search Integration**: Aggregates latest market news and analysis
- **Financial Data Integration**: Real-time stock and company information
- **Persistent Storage**: Stores analysis results for future reference
- **RESTful API**: Easy integration with existing systems

## 📋 Prerequisites

- Node.js v16+
- npm or pnpm
- API keys for:
  - [Alpha Vantage](https://www.alphavantage.co/) (financial data)
  - [SerperDev](https://serper.dev/) (web search)
  - [OpenAI](https://platform.openai.com/) (AI analysis)

## 🛠️ Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/MotiaDev/motia-examples
   cd examples/ai-agents/specialized-agents/finance-agent
   ```

2. Install dependencies:
   ```bash
   pnpm install
   # or
   npm install
   ```

3. Configure environment variables:
   ```bash
   cp .env.example .env
   ```

   Update `.env` with your API keys:
   ```bash
   ALPHA_VANTAGE_API_KEY=your_alpha_vantage_api_key_here
   SERPER_API_KEY=your_serper_api_key_here
   OPENAI_API_KEY=your_openai_api_key_here
   ```

## 🏗️ Architecture

The workflow consists of several specialized steps that work together to provide comprehensive financial analysis:

![Finance Agent](../img/finance-agent.gif)


## 🚦 API Endpoints

### Query Endpoint

```http
POST /finance-query
Content-Type: application/json

{
  "query": "Latest information about AAPL and MSFT"
}
```

Response:
```json
{
  "message": "Query received and processing started",
  "traceId": "abc123def456"
}
```

### Results Endpoint

```http
GET /finance-result/:traceId
```

Response:
```json
{
  "query": "Latest information about AAPL and MSFT",
  "timestamp": "2023-06-15T12:34:56.789Z",
  "response": {
    "summary": "Results for \"Latest information about AAPL and MSFT\"",
    "webResources": [...],
    "financialData": [...],
    "aiAnalysis": {...}
  },
  "status": "success"
}
```

## 🏃‍♂️ Running the Application

1. Start the development server:
   ```bash
   pnpm dev
   ```

2. Make a test request:
   ```bash
   curl -X POST http://localhost:3111/finance-query \
     -H "Content-Type: application/json" \
     -d '{"query": "Latest information about AAPL and MSFT"}'
   ```
## 🙏 Acknowledgments

- [Motia Framework](https://motia.dev) for the event-driven workflow engine
- [Alpha Vantage](https://www.alphavantage.co/) for financial data
- [SerperDev](https://serper.dev/) for web search capabilities
- [OpenAI](https://platform.openai.com/) for AI analysis 


## Examples
[finance-agent](/docs/examples/finance-agent): Code example
---
title: 'Finance Agent'
description: A powerful event-driven financial analysis workflow that combines web search, financial data, and AI analysis to provide comprehensive investment insights.
---

---

## Workflow Overview

<div className="my-8">![Finance Agent](./../img/finance-agent.gif)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/ai-agents/specialized-agents/finance-agent)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## Let's build a finance agent that:

- Real-time Financial Analysis: Combines multiple data sources for comprehensive insights
- AI-Powered Insights: Leverages OpenAI GPT-4 for intelligent market analysis
- Web Search Integration: Aggregates latest market news and analysis
- Financial Data Integration: Real-time stock and company information

## The Steps

<Folder name="steps" defaultOpen>
  <File name="finance-data.step.ts" />
  <File name="openai-analysis.step.ts" />
  <File name="query-api.step.ts" />
  <File name="response-coordinator.step.ts" />
  <File name="result-api.step.ts" />
  <File name="save-result.step.ts" />
  <File name="web-search.step.ts" />
</Folder>

<Callout type="info">
This example uses the `steps/` directory, but you can also use `src/` or both. Motia discovers step files from either location automatically.
</Callout>

View the source code for each step in the [GitHub repository](https://github.com/MotiaDev/motia-examples/tree/main/examples/ai-agents/specialized-agents/finance-agent).

## 🚀 Features

- **Real-time Financial Analysis**: Combines multiple data sources for comprehensive insights
- **AI-Powered Insights**: Leverages OpenAI GPT-4 for intelligent market analysis
- **Event-Driven Architecture**: Built on Motia's robust event system for reliable processing
- **Web Search Integration**: Aggregates latest market news and analysis
- **Financial Data Integration**: Real-time stock and company information
- **Persistent Storage**: Stores analysis results for future reference
- **RESTful API**: Easy integration with existing systems

## 📋 Prerequisites

- Node.js v16+
- npm or pnpm
- API keys for:
  - [Alpha Vantage](https://www.alphavantage.co/) (financial data)
  - [SerperDev](https://serper.dev/) (web search)
  - [OpenAI](https://platform.openai.com/) (AI analysis)

## 🛠️ Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/MotiaDev/motia-examples
   cd examples/ai-agents/specialized-agents/finance-agent
   ```

2. Install dependencies:
   ```bash
   pnpm install
   # or
   npm install
   ```

3. Configure environment variables:
   ```bash
   cp .env.example .env
   ```

   Update `.env` with your API keys:
   ```bash
   ALPHA_VANTAGE_API_KEY=your_alpha_vantage_api_key_here
   SERPER_API_KEY=your_serper_api_key_here
   OPENAI_API_KEY=your_openai_api_key_here
   ```

## 🏗️ Architecture

The workflow consists of several specialized steps that work together to provide comprehensive financial analysis:

![Finance Agent](../img/finance-agent.gif)


## 🚦 API Endpoints

### Query Endpoint

```http
POST /finance-query
Content-Type: application/json

{
  "query": "Latest information about AAPL and MSFT"
}
```

Response:
```json
{
  "message": "Query received and processing started",
  "traceId": "abc123def456"
}
```

### Results Endpoint

```http
GET /finance-result/:traceId
```

Response:
```json
{
  "query": "Latest information about AAPL and MSFT",
  "timestamp": "2023-06-15T12:34:56.789Z",
  "response": {
    "summary": "Results for \"Latest information about AAPL and MSFT\"",
    "webResources": [...],
    "financialData": [...],
    "aiAnalysis": {...}
  },
  "status": "success"
}
```

## 🏃‍♂️ Running the Application

1. Start the development server:
   ```bash
   pnpm dev
   ```

2. Make a test request:
   ```bash
   curl -X POST http://localhost:3111/finance-query \
     -H "Content-Type: application/json" \
     -d '{"query": "Latest information about AAPL and MSFT"}'
   ```
## 🙏 Acknowledgments

- [Motia Framework](https://motia.dev) for the event-driven workflow engine
- [Alpha Vantage](https://www.alphavantage.co/) for financial data
- [SerperDev](https://serper.dev/) for web search capabilities
- [OpenAI](https://platform.openai.com/) for AI analysis 

-   [github-integration-workflow](/docs/examples/github-integration-workflow): Documentation for github-integration-workflow.
---
title: 'GitHub Integration'
description: Build an automated GitHub issue and PR management system with AI-powered classification and routing
---

---

## Workflow Overview

<div className="my-8">![GitHub Issue Workflow](./../img/github-issue-workflow.png)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/integrations/github/github-integration-workflow)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## Let's build a GitHub automation system that:

1. Automatically triages and classifies new issues
2. Intelligently assigns labels based on content
3. Suggests appropriate assignees and reviewers
4. Monitors PR test status
5. Generates contextual comments

## Workflow Structure

The GitHub integration workflow is organized into two main components:

- **Issue Triage**: Handles the management of GitHub issues
- **PR Classifier**: Manages pull request workflows

## The Steps

<Folder name="steps" defaultOpen>
  <Folder name="issue-triage" defaultOpen>
    <File name="github-webhook.step.ts" />
    <File name="issue-classifier.step.ts" />
    <File name="label-assigner.step.ts" />
    <File name="assignee-selector.step.ts" />
    <File name="handle-new-issue.step.ts" />
    <File name="handle-issue-update.step.ts" />
    <File name="handle-issue-closure.step.ts" />
  </Folder>
  <Folder name="pr-classifier" defaultOpen>
    <File name="pr-webhook.step.ts" />
    <File name="pr-classifier.step.ts" />
    <File name="pr-label-assigner.step.ts" />
    <File name="pr-reviewer-assigner.step.ts" />
    <File name="pr-test-monitor.step.ts" />
  </Folder>
</Folder>

<Callout type="info">
This example uses the `steps/` directory, but you can also use `src/` or both. Motia discovers step files from either location automatically.
</Callout>

See the full source code on [GitHub](https://github.com/MotiaDev/motia/tree/main/examples/github-integration).

## Visual Overview

Here's how the automation flow works:

<div className="my-8">![Flow: GitHub Issue Workflow](../img/github-issue-workflow.png)</div>
<div className="my-8">![Flow: GitHub PR Workflow](../img/github-pr-workflow.png)</div>

1. **Webhook Reception** → Captures GitHub events
2. **Issue/PR Classification** → Analyzes content with AI
3. **Automated Labeling** → Applies appropriate labels
4. **Smart Assignment** → Suggests reviewers and assignees
5. **Status Monitoring** → Tracks PR test status

## Try It Out

<Steps>

### Prerequisites

Make sure you have:

- GitHub account with personal access token
- Node.js installed
- OpenAI API key (for AI classification)

### Clone the Repository

```bash
git clone git@github.com:MotiaDev/motia-examples.git
cd examples/github-integration-workflow
```

### Install Dependencies

```bash
npm install
```

### Configure Environment Variables

Create a `.env` file by copying the example:

```bash
cp .env.example .env
```

Update your `.env` with the following credentials:

```bash
GITHUB_TOKEN=your_github_token_here
OPENAI_API_KEY=your_openai_api_key
```

### Set Up GitHub Webhook

1. Go to your GitHub repository settings
2. Navigate to Webhooks and add a new webhook
3. Set the Payload URL to your Motia server endpoint
4. Select content type as `application/json`
5. Choose which events to trigger the webhook (Issues, Pull requests)
6. Save the webhook

### Run the Application

```bash
npm run dev
```

### Test the Flow

1. Create a new issue in your GitHub repository
2. Watch as it gets automatically classified and labeled
3. Create a new PR to see the reviewer assignment in action
4. Check the PR comments for test status updates

</Steps>

<Callout type="info">
  For more detailed setup instructions and configuration options, check out the [full
  documentation](https://github.com/MotiaDev/motia-examples/tree/main/examples/integrations/github/github-integration-workflow).
</Callout> 


## Examples
[github-integration-workflow](/docs/examples/github-integration-workflow): Code example
---
title: 'GitHub Integration'
description: Build an automated GitHub issue and PR management system with AI-powered classification and routing
---

---

## Workflow Overview

<div className="my-8">![GitHub Issue Workflow](./../img/github-issue-workflow.png)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/integrations/github/github-integration-workflow)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## Let's build a GitHub automation system that:

1. Automatically triages and classifies new issues
2. Intelligently assigns labels based on content
3. Suggests appropriate assignees and reviewers
4. Monitors PR test status
5. Generates contextual comments

## Workflow Structure

The GitHub integration workflow is organized into two main components:

- **Issue Triage**: Handles the management of GitHub issues
- **PR Classifier**: Manages pull request workflows

## The Steps

<Folder name="steps" defaultOpen>
  <Folder name="issue-triage" defaultOpen>
    <File name="github-webhook.step.ts" />
    <File name="issue-classifier.step.ts" />
    <File name="label-assigner.step.ts" />
    <File name="assignee-selector.step.ts" />
    <File name="handle-new-issue.step.ts" />
    <File name="handle-issue-update.step.ts" />
    <File name="handle-issue-closure.step.ts" />
  </Folder>
  <Folder name="pr-classifier" defaultOpen>
    <File name="pr-webhook.step.ts" />
    <File name="pr-classifier.step.ts" />
    <File name="pr-label-assigner.step.ts" />
    <File name="pr-reviewer-assigner.step.ts" />
    <File name="pr-test-monitor.step.ts" />
  </Folder>
</Folder>

<Callout type="info">
This example uses the `steps/` directory, but you can also use `src/` or both. Motia discovers step files from either location automatically.
</Callout>

See the full source code on [GitHub](https://github.com/MotiaDev/motia/tree/main/examples/github-integration).

## Visual Overview

Here's how the automation flow works:

<div className="my-8">![Flow: GitHub Issue Workflow](../img/github-issue-workflow.png)</div>
<div className="my-8">![Flow: GitHub PR Workflow](../img/github-pr-workflow.png)</div>

1. **Webhook Reception** → Captures GitHub events
2. **Issue/PR Classification** → Analyzes content with AI
3. **Automated Labeling** → Applies appropriate labels
4. **Smart Assignment** → Suggests reviewers and assignees
5. **Status Monitoring** → Tracks PR test status

## Try It Out

<Steps>

### Prerequisites

Make sure you have:

- GitHub account with personal access token
- Node.js installed
- OpenAI API key (for AI classification)

### Clone the Repository

```bash
git clone git@github.com:MotiaDev/motia-examples.git
cd examples/github-integration-workflow
```

### Install Dependencies

```bash
npm install
```

### Configure Environment Variables

Create a `.env` file by copying the example:

```bash
cp .env.example .env
```

Update your `.env` with the following credentials:

```bash
GITHUB_TOKEN=your_github_token_here
OPENAI_API_KEY=your_openai_api_key
```

### Set Up GitHub Webhook

1. Go to your GitHub repository settings
2. Navigate to Webhooks and add a new webhook
3. Set the Payload URL to your Motia server endpoint
4. Select content type as `application/json`
5. Choose which events to trigger the webhook (Issues, Pull requests)
6. Save the webhook

### Run the Application

```bash
npm run dev
```

### Test the Flow

1. Create a new issue in your GitHub repository
2. Watch as it gets automatically classified and labeled
3. Create a new PR to see the reviewer assignment in action
4. Check the PR comments for test status updates

</Steps>

<Callout type="info">
  For more detailed setup instructions and configuration options, check out the [full
  documentation](https://github.com/MotiaDev/motia-examples/tree/main/examples/integrations/github/github-integration-workflow).
</Callout> 

-   [github-stars-counter](/docs/examples/github-stars-counter): Documentation for github-stars-counter.
---
title: 'GitHub Stars Counter'
description: 'Real-Time GitHub Stars Counter: Building Live Updates with Motia Streams'
---

In today's social-driven development world, real-time metrics and live updates are essential for building engaging applications. Whether you're creating a portfolio site, an open-source project showcase, or a developer dashboard, you need systems that can display live data without complex infrastructure.

This comprehensive guide explores how to build a production-ready, real-time GitHub stars counter using Motia's event-driven architecture and streaming capabilities. We'll cover:

1. **Real-Time Streams**: How Motia's streams enable effortless live data synchronization
2. **Secure Webhooks**: Production-ready webhook signature verification and event handling
3. **Minimal Architecture**: Building powerful real-time features with just two components
4. **Live Integration**: How this exact counter powers the live star count on the Motia website

Let's build a stars counter that updates in real-time across all connected clients.

---

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/github-stars-counter)

---

## 🏭 Production-Grade Example

**This is not a tutorial project** - this is battle-tested, production-ready code that handles real traffic at scale. Every aspect has been designed for enterprise use:

- **🔐 Enterprise Security**: HMAC webhook verification, timing-safe comparisons, comprehensive input validation
- **⚡ High Performance**: Handles thousands of concurrent connections with automatic scaling
- **📊 Full Observability**: Structured logging, error tracking, and comprehensive monitoring
- **🛡️ Error Resilience**: Graceful degradation, retry logic, and fault tolerance
- **🌍 Global Scale**: Production deployment on Motia Cloud with worldwide CDN
- **💰 Cost Efficient**: Serverless architecture that scales to zero when not in use

---

## Live Proof: Powering Motia.dev Header

**This isn't just a demo** - this exact code powers the live GitHub star counter you can see right now in the header of [Motia.dev](https://motia.dev)! 

Look at the top-right corner of the Motia website and you'll see:
- **🏠 Motia** logo on the left
- **📑 Blog, Docs, Manifesto** navigation 
- **⭐ GitHub** icon with a **live star count** (currently showing 7953+ stars)
- **🚀 Vercel OSS 2025** badge

That live-updating number next to the GitHub icon? That's this exact implementation in production, processing real webhook events and streaming updates to thousands of visitors in real-time!

---

## The Power of Real-Time Simplicity

At its core, our GitHub stars counter solves a fundamental challenge: how do you display live, real-time metrics without complex WebSocket infrastructure or manual state management? Traditional approaches often involve intricate server-side event handling, client connection management, and complex state synchronization.

Our Motia-powered solution breaks this down into just two simple components:

- **[GitHub Webhooks](https://docs.github.com/en/webhooks)**: Instant notifications when repository stars change
- **[Motia Streams](https://motia.dev)**: Real-time data synchronization with automatic state management
- **[Production Security](https://docs.github.com/en/webhooks/securing)**: Built-in webhook signature verification

🎯 **Live in Action**: This exact implementation powers the real-time star counter visible in the header of [Motia.dev](https://motia.dev) (look for the GitHub icon with live count), updating instantly whenever developers star the repository!

Instead of complex infrastructure, we get a resilient real-time system where data flows effortlessly from GitHub events to live client updates.

---

## The Anatomy of Our Real-Time Counter

Our application consists of just two specialized components, each handling a specific part of the real-time data flow. Let's explore the complete architecture.

<Folder name="steps" defaultOpen>
  <File name="repository-stars.stream.ts" />
  <File name="github-webhook.step.ts" />
</Folder>

<Folder name="utils" defaultOpen>
  <File name="verify-webhook-signature.ts" />
  <File name="check-user-profile.ts" />
</Folder>

<Tabs items={['stream-config', 'webhook-handler', 'signature-verification', 'user-profile']}>
  <Tab value="stream-config">
    The real-time data stream that holds our repository star counts. This stream automatically synchronizes data to all connected clients with zero configuration.

    ```typescript
    import type { StreamConfig } from 'motia'
    import { z } from 'zod'

    const RepositoryStarsSchema = z.object({
      stars: z.number(),
      name: z.string(),
      fullName: z.string(),
      organization: z.string(),
      lastUpdated: z.string(),
    })

    export type RepositoryStars = z.infer<typeof RepositoryStarsSchema>

    export const config: StreamConfig = {
      name: 'stars',
      schema: RepositoryStarsSchema,
      baseConfig: { storageType: 'default' },
    }
    ```

  </Tab>
  <Tab value="webhook-handler">
    The secure webhook endpoint that receives GitHub star events, verifies their authenticity, and updates the real-time stream with new star counts.

    ```typescript
    import { type Handlers, type StepConfig } from 'motia'
    import { z } from 'zod'
    import { verifyWebhookSignature } from '../utils/verify-webhook-signature'
    import { checkUserProfile } from '../utils/check-user-profile'

    export const config = {
      name: 'GitHubStarWebhook',
      description: 'Process GitHub star webhook events with signature verification',
      triggers: [
        {
          type: 'http',
          method: 'POST',
          path: '/webhooks/github/star',
          bodySchema: z.object({
            action: z.enum(['created', 'deleted']),
            starred_at: z.string().optional(),
            repository: z.object({
              name: z.string(),
              full_name: z.string(),
              stargazers_count: z.number(),
              owner: z.object({ login: z.string() }),
            }),
            sender: z.object({
              login: z.string(),
              name: z.string().optional(),
              avatar_url: z.string().optional(),
              html_url: z.string(),
              url: z.string().describe('API URL'),
            }),
          }),
          responseSchema: {
            200: z.object({
              message: z.string(),
              event: z.string(),
              processed: z.boolean(),
            }),
            400: z.object({ error: z.string() }),
            401: z.object({ error: z.string() }),
            500: z.object({ error: z.string() }),
          },
        },
      ],
      enqueues: [],
      flows: ['github-star-processing'],
    } as const satisfies StepConfig

    export const handler: Handlers<typeof config> = async (
      req,
      { logger, streams, state, traceId }
    ) => {
      try {
        // Extract and validate GitHub headers
        const githubEvent = req.headers['x-github-event'] as string
        const githubDelivery = req.headers['x-github-delivery'] as string
        const githubSignature = req.headers['x-hub-signature-256'] as string
        const githubSignatureSha1 = req.headers['x-hub-signature'] as string

        // Only process star events
        if (githubEvent !== 'star') {
          logger.info('Ignoring non-star event', { githubEvent, githubDelivery })

          return {
            status: 200,
            body: {
              message: 'Event ignored - only processing star events',
              event: githubEvent,
              processed: false,
            },
          }
        }

        // Verify webhook signature if secret is configured
        const webhookSecret = process.env.GITHUB_WEBHOOK_SECRET

        if (webhookSecret) {
          logger.info('Verifying webhook signature', {
            delivery: githubDelivery,
            event: githubEvent,
          })

          const isValidSignature = verifyWebhookSignature({
            payload: JSON.stringify(req.body),
            signature: githubSignature || githubSignatureSha1,
            secret: webhookSecret,
            algorithm: githubSignature ? 'sha256' : 'sha1',
          })

          if (!isValidSignature) {
            logger.warn('Invalid webhook signature', {
              delivery: githubDelivery,
              event: githubEvent,
            })

            return {
              status: 401,
              body: { error: 'Invalid webhook signature' },
            }
          }
        }

        // Extract repository and user data
        const repository = {
          fullName: req.body.repository.full_name,
          name: req.body.repository.name,
          organization: req.body.repository.owner.login,
        }

        const sender = {
          name: req.body.sender.name,
          login: req.body.sender.login,
          avatarUrl: req.body.sender.avatar_url,
          url: req.body.sender.html_url,
          apiUrl: req.body.sender.url,
        }

        // Prepare star data for stream
        const webhookData = {
          fullName: repository.fullName,
          name: repository.name,
          organization: repository.organization,
          lastUpdated: req.body.starred_at || new Date().toISOString(),
          stars: req.body.repository.stargazers_count,
        }

        // Update real-time stream - this automatically propagates to all clients!
        await streams.stars.set(repository.organization, repository.name, webhookData)

        logger.info('GitHub star webhook processed successfully', { ...webhookData, sender })

        // Optional: Fetch additional user profile data
        if (sender.apiUrl) {
          try {
            logger.info('Getting GitHub user profile', { apiUrl: sender.apiUrl })
            const userProfile = await checkUserProfile(sender.apiUrl)
            await state.set(repository.fullName, traceId, userProfile)
            logger.info('GitHub user profile', { userProfile })
          } catch (error: any) {
            logger.error('Failed to get GitHub user profile', { error: error.message })
          }
        }

        return {
          status: 200,
          body: {
            message: 'Star webhook processed successfully',
            event: githubEvent,
            processed: true,
          },
        }
      } catch (error: any) {
        logger.error('GitHub star webhook processing failed', {
          error: error.message,
          stack: error.stack,
        })

        return {
          status: 500,
          body: { error: 'Star webhook processing failed' },
        }
      }
    }
    ```

  </Tab>
  <Tab value="signature-verification">
    Production-ready webhook security that verifies GitHub webhook signatures using HMAC cryptographic validation to ensure requests are authentic.

    ```typescript
    import crypto from 'crypto'

    type Args = {
      payload: string
      signature: string
      secret: string
      algorithm: 'sha1' | 'sha256'
    }

    export function verifyWebhookSignature(args: Args): boolean {
      const { payload, signature, secret, algorithm = 'sha256' } = args

      try {
        if (!signature) return false

        // Generate expected signature using HMAC
        const expectedSignature =
          algorithm === 'sha256'
            ? `sha256=${crypto.createHmac('sha256', secret).update(payload, 'utf8').digest('hex')}`
            : `sha1=${crypto.createHmac('sha1', secret).update(payload, 'utf8').digest('hex')}`

        // Use timing-safe comparison to prevent timing attacks
        return crypto.timingSafeEqual(Buffer.from(signature), Buffer.from(expectedSignature))
      } catch (error) {
        return false
      }
    }
    ```

  </Tab>
  <Tab value="user-profile">
    Optional GitHub user profile fetching that enriches webhook events with additional user information for analytics and user insights.

    ```typescript
    export interface GitHubUserProfile {
      login: string
      id: number
      node_id: string
      avatar_url: string
      gravatar_id: string
      url: string
      html_url: string
      followers_url: string
      following_url: string
      gists_url: string
      starred_url: string
      subscriptions_url: string
      organizations_url: string
      repos_url: string
      events_url: string
      received_events_url: string
      type: string
      user_view_type: string
      site_admin: boolean
      name: string | null
      company: string | null
      blog: string
      location: string | null
      email: string | null
      hireable: boolean | null
      bio: string | null
      twitter_username: string | null
      public_repos: number
      public_gists: number
      followers: number
      following: number
      created_at: string
      updated_at: string
    }

    export interface GitHubUserProfileResponse {
      followers: number
      bio: string | null
      email: string | null
      htmlUrl: string
      name: string | null
      login: string
      location: string | null
    }

    export const checkUserProfile = async (apiUrl: string): Promise<GitHubUserProfileResponse> => {
      const response = await fetch(apiUrl)
      const data = (await response.json()) as GitHubUserProfile

      return {
        followers: data.followers,
        bio: data.bio,
        email: data.email,
        htmlUrl: data.html_url,
        name: data.name,
        login: data.login,
        location: data.location,
      }
    }
    ```

  </Tab>
</Tabs>

---

## Real-Time Data Flow

The beauty of this architecture lies in its simplicity. Here's how real-time updates flow through the system:

1. **GitHub Event** → User stars/unstars your repository
2. **Webhook Delivery** → GitHub sends POST request to your endpoint  
3. **Security Validation** → Signature verification ensures request authenticity
4. **Stream Update** → Data is written to Motia stream with `streams.stars.set()`
5. **Live Propagation** → All connected clients automatically receive the update
6. **UI Updates** → Client applications re-render with new star count

**No manual WebSocket management, no connection handling, no state synchronization code required!**

---

## Key Features & Benefits

### ⚡ **Instant Real-Time Updates**
Stars update across all connected clients the moment GitHub sends the webhook - no polling, no delays.

### 🔐 **Production-Ready Security**  
HMAC signature verification with timing-safe comparison prevents unauthorized webhook requests.

### 🧩 **Minimal Architecture**
Just two components handle the complete real-time functionality - no complex infrastructure required.

### 📊 **Automatic State Management**
Motia streams handle data persistence, synchronization, and client updates automatically.

### 🎯 **Type-Safe Development**
Full TypeScript integration with Zod validation ensures zero runtime surprises.

### 🌐 **Live Production Usage**
This exact implementation powers the real-time counter visible in the Motia website header - go check it out now!

### 🚀 **Production-Grade Architecture**
Built for enterprise scale with proper error handling, security, monitoring, and deployment automation.

---

## Trying It Out

Ready to build your own real-time GitHub stars counter? Let's get it running.

<Steps>

### Clone and Install

Start by getting the project locally and installing dependencies.

```shell
git clone https://github.com/MotiaDev/github-stars-counter.git
cd github-stars-counter
npm install
```

### Configure GitHub Webhook (Optional)

Set up webhook security with a secret for production use. This is optional for testing but essential for production deployments.

```shell
# Generate a secure random secret
export GITHUB_WEBHOOK_SECRET=$(openssl rand -hex 32)
echo "GITHUB_WEBHOOK_SECRET=$GITHUB_WEBHOOK_SECRET" >> .env
```

### Start Development Server

Launch the Motia development server to begin receiving webhook events.

```shell
npm run dev
```

Your webhook endpoint will be available at: `http://localhost:3111/webhooks/github/star`

### Set Up GitHub Webhook

Configure GitHub to send star events to your endpoint:

1. Go to your GitHub repository settings
2. Navigate to **Settings** → **Webhooks**  
3. Click **Add webhook**
4. Set **Payload URL** to your endpoint (use ngrok for local testing)
5. Set **Content type** to `application/json`
6. Add your webhook secret if configured
7. Select **Individual events** → **Stars**
8. Click **Add webhook**

### Test the Real-Time Updates

Test your webhook by starring/unstarring your repository:

1. **Star your repository** on GitHub
2. **Check the logs** - you should see webhook processing
3. **Access the stream** - query `/api/streams/stars` to see current data
4. **Watch real-time updates** in the [iii development console](https://iii.dev/docs)

### Access Real-Time Data

Your star data is now available via the Motia streams API:

```shell
# Get all repository star counts
curl http://localhost:3111/api/streams/stars

# Get specific repository star count  
curl http://localhost:3111/api/streams/stars/{org}/{repo}
```

The response includes live star counts that update automatically whenever GitHub sends webhook events.

### Deploy to Production

Once your counter is working locally, deploy it to production with Motia Cloud:

**Option 1: CLI Deployment**
```shell
# Deploy with version and API key
motia cloud deploy --api-key your-api-key --version-name 1.0.0

# Deploy with environment variables
motia cloud deploy --api-key your-api-key \
  --version-name 1.0.0 \
  --env-file .env.production \
  --environment-id your-env-id
```

**Option 2: One-Click Web Deployment**
1. Ensure your local project is running (`npm run dev`)
2. Go to [Motia Cloud](https://motia.cloud) and import your project
3. Select your local project port
4. Choose project and environment name
5. Upload environment variables (optional)
6. Click **Deploy** and watch the magic happen! ✨

</Steps>

---

## 🚀 Production Deployment Guide

### Environment Variables

Configure these environment variables for production security and functionality:

```shell
# Required: GitHub webhook secret for security
GITHUB_WEBHOOK_SECRET="your-secure-random-secret"

# Optional: GitHub personal access token for enhanced API limits
GITHUB_TOKEN="ghp_your_github_token"
```

### Security Best Practices

For production deployments, ensure you:

1. **Generate secure webhook secrets**: 
   ```shell
   # Generate a cryptographically secure secret
   openssl rand -hex 32
   ```

2. **Store secrets securely**: Use environment variables, never commit to code

3. **Monitor webhook signatures**: The handler automatically verifies signatures when `GITHUB_WEBHOOK_SECRET` is set

4. **Enable logging**: Monitor for signature verification failures and unauthorized requests

### Scaling Considerations

This architecture scales automatically with your traffic:

- **Multiple repositories**: Each repo gets its own stream key (`org/repo`)
- **High concurrency**: Motia streams handle thousands of concurrent connections
- **Global distribution**: Deploy to multiple regions for worldwide performance
- **Cost optimization**: Pay only for actual usage with serverless scaling

---

## 💻 Dive into the Code

Want to explore the complete real-time implementation? Check out the full source code and see how simple real-time features can be with Motia:

<div className="not-prose">
  <div className="bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-blue-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Live GitHub Stars Counter</h3>
        <p className="text-gray-600 mb-4">Access the complete implementation with webhook security, real-time streams, and production deployment configurations. See exactly how the Motia website's live counter works!</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/github-stars-counter" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-blue-600 hover:bg-blue-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            View Stars Counter Code
          </a>
          <a 
            href="https://motia.dev" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            See It Live in Header →
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Conclusion: Real-Time Made Simple

This GitHub stars counter demonstrates how Motia transforms complex real-time development into simple, manageable components. With just two files and minimal configuration, we've built a production-ready system that handles webhook security, real-time synchronization, and live client updates.

The beauty of this approach is its scalability and extensibility:
- **Add more repositories**: Each gets its own stream automatically
- **Enhance with analytics**: Track starring patterns and user insights
- **Multiple notification channels**: Slack, Discord, email alerts for milestones
- **Rich frontend integrations**: React, Vue, vanilla JS - all work seamlessly

Key architectural benefits:
- **No WebSocket complexity**: Streams handle all real-time synchronization automatically
- **Built-in security**: Production-ready webhook verification out of the box
- **Type safety**: Full TypeScript support prevents runtime errors
- **Zero configuration**: Real-time features work with no additional setup

This exact implementation powers the live star counter you see in the header of [Motia.dev](https://motia.dev) - that 7953+ count updating in real-time? It's this code in action, proven at enterprise scale with thousands of daily visitors.

**Production Metrics:**
- Handles 10,000+ webhook events per day
- Sub-50ms response times globally  
- 99.9% uptime with automatic failover
- Zero maintenance serverless architecture

Ready to add enterprise-grade real-time features to your applications? Deploy production-ready code with Motia today!




## Examples
[github-stars-counter](/docs/examples/github-stars-counter): Code example
---
title: 'GitHub Stars Counter'
description: 'Real-Time GitHub Stars Counter: Building Live Updates with Motia Streams'
---

In today's social-driven development world, real-time metrics and live updates are essential for building engaging applications. Whether you're creating a portfolio site, an open-source project showcase, or a developer dashboard, you need systems that can display live data without complex infrastructure.

This comprehensive guide explores how to build a production-ready, real-time GitHub stars counter using Motia's event-driven architecture and streaming capabilities. We'll cover:

1. **Real-Time Streams**: How Motia's streams enable effortless live data synchronization
2. **Secure Webhooks**: Production-ready webhook signature verification and event handling
3. **Minimal Architecture**: Building powerful real-time features with just two components
4. **Live Integration**: How this exact counter powers the live star count on the Motia website

Let's build a stars counter that updates in real-time across all connected clients.

---

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/github-stars-counter)

---

## 🏭 Production-Grade Example

**This is not a tutorial project** - this is battle-tested, production-ready code that handles real traffic at scale. Every aspect has been designed for enterprise use:

- **🔐 Enterprise Security**: HMAC webhook verification, timing-safe comparisons, comprehensive input validation
- **⚡ High Performance**: Handles thousands of concurrent connections with automatic scaling
- **📊 Full Observability**: Structured logging, error tracking, and comprehensive monitoring
- **🛡️ Error Resilience**: Graceful degradation, retry logic, and fault tolerance
- **🌍 Global Scale**: Production deployment on Motia Cloud with worldwide CDN
- **💰 Cost Efficient**: Serverless architecture that scales to zero when not in use

---

## Live Proof: Powering Motia.dev Header

**This isn't just a demo** - this exact code powers the live GitHub star counter you can see right now in the header of [Motia.dev](https://motia.dev)! 

Look at the top-right corner of the Motia website and you'll see:
- **🏠 Motia** logo on the left
- **📑 Blog, Docs, Manifesto** navigation 
- **⭐ GitHub** icon with a **live star count** (currently showing 7953+ stars)
- **🚀 Vercel OSS 2025** badge

That live-updating number next to the GitHub icon? That's this exact implementation in production, processing real webhook events and streaming updates to thousands of visitors in real-time!

---

## The Power of Real-Time Simplicity

At its core, our GitHub stars counter solves a fundamental challenge: how do you display live, real-time metrics without complex WebSocket infrastructure or manual state management? Traditional approaches often involve intricate server-side event handling, client connection management, and complex state synchronization.

Our Motia-powered solution breaks this down into just two simple components:

- **[GitHub Webhooks](https://docs.github.com/en/webhooks)**: Instant notifications when repository stars change
- **[Motia Streams](https://motia.dev)**: Real-time data synchronization with automatic state management
- **[Production Security](https://docs.github.com/en/webhooks/securing)**: Built-in webhook signature verification

🎯 **Live in Action**: This exact implementation powers the real-time star counter visible in the header of [Motia.dev](https://motia.dev) (look for the GitHub icon with live count), updating instantly whenever developers star the repository!

Instead of complex infrastructure, we get a resilient real-time system where data flows effortlessly from GitHub events to live client updates.

---

## The Anatomy of Our Real-Time Counter

Our application consists of just two specialized components, each handling a specific part of the real-time data flow. Let's explore the complete architecture.

<Folder name="steps" defaultOpen>
  <File name="repository-stars.stream.ts" />
  <File name="github-webhook.step.ts" />
</Folder>

<Folder name="utils" defaultOpen>
  <File name="verify-webhook-signature.ts" />
  <File name="check-user-profile.ts" />
</Folder>

<Tabs items={['stream-config', 'webhook-handler', 'signature-verification', 'user-profile']}>
  <Tab value="stream-config">
    The real-time data stream that holds our repository star counts. This stream automatically synchronizes data to all connected clients with zero configuration.

    ```typescript
    import type { StreamConfig } from 'motia'
    import { z } from 'zod'

    const RepositoryStarsSchema = z.object({
      stars: z.number(),
      name: z.string(),
      fullName: z.string(),
      organization: z.string(),
      lastUpdated: z.string(),
    })

    export type RepositoryStars = z.infer<typeof RepositoryStarsSchema>

    export const config: StreamConfig = {
      name: 'stars',
      schema: RepositoryStarsSchema,
      baseConfig: { storageType: 'default' },
    }
    ```

  </Tab>
  <Tab value="webhook-handler">
    The secure webhook endpoint that receives GitHub star events, verifies their authenticity, and updates the real-time stream with new star counts.

    ```typescript
    import { type Handlers, type StepConfig } from 'motia'
    import { z } from 'zod'
    import { verifyWebhookSignature } from '../utils/verify-webhook-signature'
    import { checkUserProfile } from '../utils/check-user-profile'

    export const config = {
      name: 'GitHubStarWebhook',
      description: 'Process GitHub star webhook events with signature verification',
      triggers: [
        {
          type: 'http',
          method: 'POST',
          path: '/webhooks/github/star',
          bodySchema: z.object({
            action: z.enum(['created', 'deleted']),
            starred_at: z.string().optional(),
            repository: z.object({
              name: z.string(),
              full_name: z.string(),
              stargazers_count: z.number(),
              owner: z.object({ login: z.string() }),
            }),
            sender: z.object({
              login: z.string(),
              name: z.string().optional(),
              avatar_url: z.string().optional(),
              html_url: z.string(),
              url: z.string().describe('API URL'),
            }),
          }),
          responseSchema: {
            200: z.object({
              message: z.string(),
              event: z.string(),
              processed: z.boolean(),
            }),
            400: z.object({ error: z.string() }),
            401: z.object({ error: z.string() }),
            500: z.object({ error: z.string() }),
          },
        },
      ],
      enqueues: [],
      flows: ['github-star-processing'],
    } as const satisfies StepConfig

    export const handler: Handlers<typeof config> = async (
      req,
      { logger, streams, state, traceId }
    ) => {
      try {
        // Extract and validate GitHub headers
        const githubEvent = req.headers['x-github-event'] as string
        const githubDelivery = req.headers['x-github-delivery'] as string
        const githubSignature = req.headers['x-hub-signature-256'] as string
        const githubSignatureSha1 = req.headers['x-hub-signature'] as string

        // Only process star events
        if (githubEvent !== 'star') {
          logger.info('Ignoring non-star event', { githubEvent, githubDelivery })

          return {
            status: 200,
            body: {
              message: 'Event ignored - only processing star events',
              event: githubEvent,
              processed: false,
            },
          }
        }

        // Verify webhook signature if secret is configured
        const webhookSecret = process.env.GITHUB_WEBHOOK_SECRET

        if (webhookSecret) {
          logger.info('Verifying webhook signature', {
            delivery: githubDelivery,
            event: githubEvent,
          })

          const isValidSignature = verifyWebhookSignature({
            payload: JSON.stringify(req.body),
            signature: githubSignature || githubSignatureSha1,
            secret: webhookSecret,
            algorithm: githubSignature ? 'sha256' : 'sha1',
          })

          if (!isValidSignature) {
            logger.warn('Invalid webhook signature', {
              delivery: githubDelivery,
              event: githubEvent,
            })

            return {
              status: 401,
              body: { error: 'Invalid webhook signature' },
            }
          }
        }

        // Extract repository and user data
        const repository = {
          fullName: req.body.repository.full_name,
          name: req.body.repository.name,
          organization: req.body.repository.owner.login,
        }

        const sender = {
          name: req.body.sender.name,
          login: req.body.sender.login,
          avatarUrl: req.body.sender.avatar_url,
          url: req.body.sender.html_url,
          apiUrl: req.body.sender.url,
        }

        // Prepare star data for stream
        const webhookData = {
          fullName: repository.fullName,
          name: repository.name,
          organization: repository.organization,
          lastUpdated: req.body.starred_at || new Date().toISOString(),
          stars: req.body.repository.stargazers_count,
        }

        // Update real-time stream - this automatically propagates to all clients!
        await streams.stars.set(repository.organization, repository.name, webhookData)

        logger.info('GitHub star webhook processed successfully', { ...webhookData, sender })

        // Optional: Fetch additional user profile data
        if (sender.apiUrl) {
          try {
            logger.info('Getting GitHub user profile', { apiUrl: sender.apiUrl })
            const userProfile = await checkUserProfile(sender.apiUrl)
            await state.set(repository.fullName, traceId, userProfile)
            logger.info('GitHub user profile', { userProfile })
          } catch (error: any) {
            logger.error('Failed to get GitHub user profile', { error: error.message })
          }
        }

        return {
          status: 200,
          body: {
            message: 'Star webhook processed successfully',
            event: githubEvent,
            processed: true,
          },
        }
      } catch (error: any) {
        logger.error('GitHub star webhook processing failed', {
          error: error.message,
          stack: error.stack,
        })

        return {
          status: 500,
          body: { error: 'Star webhook processing failed' },
        }
      }
    }
    ```

  </Tab>
  <Tab value="signature-verification">
    Production-ready webhook security that verifies GitHub webhook signatures using HMAC cryptographic validation to ensure requests are authentic.

    ```typescript
    import crypto from 'crypto'

    type Args = {
      payload: string
      signature: string
      secret: string
      algorithm: 'sha1' | 'sha256'
    }

    export function verifyWebhookSignature(args: Args): boolean {
      const { payload, signature, secret, algorithm = 'sha256' } = args

      try {
        if (!signature) return false

        // Generate expected signature using HMAC
        const expectedSignature =
          algorithm === 'sha256'
            ? `sha256=${crypto.createHmac('sha256', secret).update(payload, 'utf8').digest('hex')}`
            : `sha1=${crypto.createHmac('sha1', secret).update(payload, 'utf8').digest('hex')}`

        // Use timing-safe comparison to prevent timing attacks
        return crypto.timingSafeEqual(Buffer.from(signature), Buffer.from(expectedSignature))
      } catch (error) {
        return false
      }
    }
    ```

  </Tab>
  <Tab value="user-profile">
    Optional GitHub user profile fetching that enriches webhook events with additional user information for analytics and user insights.

    ```typescript
    export interface GitHubUserProfile {
      login: string
      id: number
      node_id: string
      avatar_url: string
      gravatar_id: string
      url: string
      html_url: string
      followers_url: string
      following_url: string
      gists_url: string
      starred_url: string
      subscriptions_url: string
      organizations_url: string
      repos_url: string
      events_url: string
      received_events_url: string
      type: string
      user_view_type: string
      site_admin: boolean
      name: string | null
      company: string | null
      blog: string
      location: string | null
      email: string | null
      hireable: boolean | null
      bio: string | null
      twitter_username: string | null
      public_repos: number
      public_gists: number
      followers: number
      following: number
      created_at: string
      updated_at: string
    }

    export interface GitHubUserProfileResponse {
      followers: number
      bio: string | null
      email: string | null
      htmlUrl: string
      name: string | null
      login: string
      location: string | null
    }

    export const checkUserProfile = async (apiUrl: string): Promise<GitHubUserProfileResponse> => {
      const response = await fetch(apiUrl)
      const data = (await response.json()) as GitHubUserProfile

      return {
        followers: data.followers,
        bio: data.bio,
        email: data.email,
        htmlUrl: data.html_url,
        name: data.name,
        login: data.login,
        location: data.location,
      }
    }
    ```

  </Tab>
</Tabs>

---

## Real-Time Data Flow

The beauty of this architecture lies in its simplicity. Here's how real-time updates flow through the system:

1. **GitHub Event** → User stars/unstars your repository
2. **Webhook Delivery** → GitHub sends POST request to your endpoint  
3. **Security Validation** → Signature verification ensures request authenticity
4. **Stream Update** → Data is written to Motia stream with `streams.stars.set()`
5. **Live Propagation** → All connected clients automatically receive the update
6. **UI Updates** → Client applications re-render with new star count

**No manual WebSocket management, no connection handling, no state synchronization code required!**

---

## Key Features & Benefits

### ⚡ **Instant Real-Time Updates**
Stars update across all connected clients the moment GitHub sends the webhook - no polling, no delays.

### 🔐 **Production-Ready Security**  
HMAC signature verification with timing-safe comparison prevents unauthorized webhook requests.

### 🧩 **Minimal Architecture**
Just two components handle the complete real-time functionality - no complex infrastructure required.

### 📊 **Automatic State Management**
Motia streams handle data persistence, synchronization, and client updates automatically.

### 🎯 **Type-Safe Development**
Full TypeScript integration with Zod validation ensures zero runtime surprises.

### 🌐 **Live Production Usage**
This exact implementation powers the real-time counter visible in the Motia website header - go check it out now!

### 🚀 **Production-Grade Architecture**
Built for enterprise scale with proper error handling, security, monitoring, and deployment automation.

---

## Trying It Out

Ready to build your own real-time GitHub stars counter? Let's get it running.

<Steps>

### Clone and Install

Start by getting the project locally and installing dependencies.

```shell
git clone https://github.com/MotiaDev/github-stars-counter.git
cd github-stars-counter
npm install
```

### Configure GitHub Webhook (Optional)

Set up webhook security with a secret for production use. This is optional for testing but essential for production deployments.

```shell
# Generate a secure random secret
export GITHUB_WEBHOOK_SECRET=$(openssl rand -hex 32)
echo "GITHUB_WEBHOOK_SECRET=$GITHUB_WEBHOOK_SECRET" >> .env
```

### Start Development Server

Launch the Motia development server to begin receiving webhook events.

```shell
npm run dev
```

Your webhook endpoint will be available at: `http://localhost:3111/webhooks/github/star`

### Set Up GitHub Webhook

Configure GitHub to send star events to your endpoint:

1. Go to your GitHub repository settings
2. Navigate to **Settings** → **Webhooks**  
3. Click **Add webhook**
4. Set **Payload URL** to your endpoint (use ngrok for local testing)
5. Set **Content type** to `application/json`
6. Add your webhook secret if configured
7. Select **Individual events** → **Stars**
8. Click **Add webhook**

### Test the Real-Time Updates

Test your webhook by starring/unstarring your repository:

1. **Star your repository** on GitHub
2. **Check the logs** - you should see webhook processing
3. **Access the stream** - query `/api/streams/stars` to see current data
4. **Watch real-time updates** in the [iii development console](https://iii.dev/docs)

### Access Real-Time Data

Your star data is now available via the Motia streams API:

```shell
# Get all repository star counts
curl http://localhost:3111/api/streams/stars

# Get specific repository star count  
curl http://localhost:3111/api/streams/stars/{org}/{repo}
```

The response includes live star counts that update automatically whenever GitHub sends webhook events.

### Deploy to Production

Once your counter is working locally, deploy it to production with Motia Cloud:

**Option 1: CLI Deployment**
```shell
# Deploy with version and API key
motia cloud deploy --api-key your-api-key --version-name 1.0.0

# Deploy with environment variables
motia cloud deploy --api-key your-api-key \
  --version-name 1.0.0 \
  --env-file .env.production \
  --environment-id your-env-id
```

**Option 2: One-Click Web Deployment**
1. Ensure your local project is running (`npm run dev`)
2. Go to [Motia Cloud](https://motia.cloud) and import your project
3. Select your local project port
4. Choose project and environment name
5. Upload environment variables (optional)
6. Click **Deploy** and watch the magic happen! ✨

</Steps>

---

## 🚀 Production Deployment Guide

### Environment Variables

Configure these environment variables for production security and functionality:

```shell
# Required: GitHub webhook secret for security
GITHUB_WEBHOOK_SECRET="your-secure-random-secret"

# Optional: GitHub personal access token for enhanced API limits
GITHUB_TOKEN="ghp_your_github_token"
```

### Security Best Practices

For production deployments, ensure you:

1. **Generate secure webhook secrets**: 
   ```shell
   # Generate a cryptographically secure secret
   openssl rand -hex 32
   ```

2. **Store secrets securely**: Use environment variables, never commit to code

3. **Monitor webhook signatures**: The handler automatically verifies signatures when `GITHUB_WEBHOOK_SECRET` is set

4. **Enable logging**: Monitor for signature verification failures and unauthorized requests

### Scaling Considerations

This architecture scales automatically with your traffic:

- **Multiple repositories**: Each repo gets its own stream key (`org/repo`)
- **High concurrency**: Motia streams handle thousands of concurrent connections
- **Global distribution**: Deploy to multiple regions for worldwide performance
- **Cost optimization**: Pay only for actual usage with serverless scaling

---

## 💻 Dive into the Code

Want to explore the complete real-time implementation? Check out the full source code and see how simple real-time features can be with Motia:

<div className="not-prose">
  <div className="bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-blue-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Live GitHub Stars Counter</h3>
        <p className="text-gray-600 mb-4">Access the complete implementation with webhook security, real-time streams, and production deployment configurations. See exactly how the Motia website's live counter works!</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/github-stars-counter" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-blue-600 hover:bg-blue-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            View Stars Counter Code
          </a>
          <a 
            href="https://motia.dev" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            See It Live in Header →
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Conclusion: Real-Time Made Simple

This GitHub stars counter demonstrates how Motia transforms complex real-time development into simple, manageable components. With just two files and minimal configuration, we've built a production-ready system that handles webhook security, real-time synchronization, and live client updates.

The beauty of this approach is its scalability and extensibility:
- **Add more repositories**: Each gets its own stream automatically
- **Enhance with analytics**: Track starring patterns and user insights
- **Multiple notification channels**: Slack, Discord, email alerts for milestones
- **Rich frontend integrations**: React, Vue, vanilla JS - all work seamlessly

Key architectural benefits:
- **No WebSocket complexity**: Streams handle all real-time synchronization automatically
- **Built-in security**: Production-ready webhook verification out of the box
- **Type safety**: Full TypeScript support prevents runtime errors
- **Zero configuration**: Real-time features work with no additional setup

This exact implementation powers the live star counter you see in the header of [Motia.dev](https://motia.dev) - that 7953+ count updating in real-time? It's this code in action, proven at enterprise scale with thousands of daily visitors.

**Production Metrics:**
- Handles 10,000+ webhook events per day
- Sub-50ms response times globally  
- 99.9% uptime with automatic failover
- Zero maintenance serverless architecture

Ready to add enterprise-grade real-time features to your applications? Deploy production-ready code with Motia today!



-   [gmail-automation](/docs/examples/gmail-automation): Documentation for gmail-automation.
---
title: 'Gmail Automation'
description: Build an automated email system with smart labeling, auto-responses, and AI-powered filtering
---

---

## Workflow Overview

<div className="my-8">![Gmail Automation](./../img/gmail-automation.png)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/integrations/communication/gmail-workflow)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## Let's build a Gmail automation system that:

- 📊 Smart email classification by category (work, personal, social, promotion, spam, update)
- 🚨 Urgency detection (high, medium, low) with prioritization
- 💬 Intelligent automated responses based on email context
- 🏷️ Automatic email organization (labeling, archiving)
- 📈 Daily summary reports via Discord
- 🔒 Secure Gmail API integration with OAuth2 authentication flow
- ⚡ Real-time email monitoring with webhook notifications

## The Steps

<Folder name="steps" defaultOpen>
  <File name="analyze-email.step.py" />
  <File name="auto-responder.step.ts" />
  <File name="daily-summary.step.ts" />
  <File name="fetch-email.step.ts" />
  <File name="gmail-webhook.step.ts" />
  <File name="organize-email.step.ts" />
</Folder>

<Callout type="info">
This example uses the `steps/` directory, but you can also use `src/` or both. Motia discovers step files from either location automatically.
</Callout>

View the source code for each step in the [GitHub repository](https://github.com/MotiaDev/motia-examples/tree/main/examples/integrations/communication/gmail-workflow).

## Visual Overview

Here's how the automation flow works:

<div className="my-8">![Flow: Gmail Automation Steps](../img/gmail-automation.png)</div>

## 🌊 Workflow Architecture

The Gmail Account Manager workflow consists of the following steps:

### 1. Gmail Authentication (Multi-Step Flow)
- **Files**: 
  - `steps/gmail-get-auth-url.step.ts`: Generates OAuth2 authorization URL
  - `steps/gmail-auth.step.ts`: Handles authorization code exchange
  - `steps/gmail-token-status.step.ts`: Checks token validity and refreshes if needed

### 2. Gmail Webhook (HTTP Step)
- **File**: `steps/gmail-webhook.step.ts`
- **Purpose**: Receives notifications from Gmail when new emails arrive
- **Enqueues**: `gmail.new_email` event with message details
- **Endpoint**: `POST /api/gmail-webhook`

### 3. Gmail Watch (HTTP Step)
- **File**: `steps/gmail-watch.step.ts`
- **Purpose**: Sets up push notifications for the Gmail account
- **Endpoint**: `GET /api/watch`

### 4. Fetch Email (Queue Step)
- **File**: `steps/fetch-email.step.ts`
- **Purpose**: Retrieves the full email content from Gmail API
- **Queue trigger**: `gmail.email.received`
- **Enqueues**: `gmail.email.fetched` with complete email data
- **Key Functions**: Authenticates with Gmail API, fetches message content, parses attachments

### 5. Analyze Email (Queue Step)
- **File**: `steps/analyze-email.step.py`
- **Purpose**: Uses Hugging Face models to analyze email content
- **Queue trigger**: `gmail.email.fetched`
- **Enqueues**: `gmail.email.analyzed` with analysis results
- **Analysis Performed**: 
  - Category classification
  - Urgency detection
  - Sentiment analysis
  - Key information extraction

### 6. Organize Email (Queue Step)
- **File**: `steps/organize-email.step.ts`
- **Purpose**: Applies labels and organization based on analysis
- **Queue trigger**: `gmail.email.analyzed`
- **Enqueues**: `[gmail.email.organized, gmail.email.archived]`
- **Actions**: Creates/applies labels, archives certain emails, marks importance

### 7. Auto-Respond to Email (Queue Step)
- **File**: `steps/auto-responder.step.ts`
- **Purpose**: Generates and sends appropriate responses for certain emails
- **Queue trigger**: `gmail.email.analyzed`
- **Enqueues**: `gmail.email.responded`
- **Features**: 
  - Template selection based on email context
  - Personalization of responses
  - Auto-reply for urgent messages
  - Follow-up scheduling

### 8. Daily Summary (Cron Step)
- **File**: `steps/daily-summary.step.ts`
- **Purpose**: Compiles and sends daily email activity summary
- **Schedule**: Runs daily at 6:00 PM
- **Enqueues**: `gmail.summary.sent`
- **Delivery**: Sends report to Discord via webhook

## Try It Out

<Steps>
## 📋 Prerequisites

- **Node.js** (v18+)
- **Python** (v3.8+)
- **Gmail API credentials** (client_id and client_secret)
- **Google Cloud project** with Pub/Sub API enabled
- **Hugging Face API token**
- **Discord webhook URL** (for daily summaries)

## 🚀 Quick Start

1. **Clone this repository**
   ```bash
   git clone https://github.com/yourusername/gmail-flow.git
   cd gmail-flow
   ```

2. **Install Node.js dependencies**
   ```bash
   pnpm install
   ```

3. **Install Python dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure environment variables**
   ```bash
   cp .env.example .env
   ```
   Then edit the `.env` file with your credentials (see setup sections below).

5. **Start the development server**
   ```bash
   pnpm dev
   ```

6. **Open the iii development console**
   
   Navigate to [http://localhost:3000](http://localhost:3000) to view the workflow.

## 🔧 Detailed Setup

### Setting up Google Cloud Project and Gmail API

Before you can use the Gmail Account Manager, you need to set up a Google Cloud project with the Gmail API and Pub/Sub:

1. **Create a Google Cloud Project**:
   - Go to [Google Cloud Console](https://console.cloud.google.com/)
   - Click on "New Project" and follow the steps to create a new project
   - Note your project ID for later use

2. **Enable the Gmail API**:
   - In your project, go to "APIs & Services" > "Library"
   - Search for "Gmail API" and click on it
   - Click "Enable"

3. **Enable the Pub/Sub API**:
   - In your project, go to "APIs & Services" > "Library"
   - Search for "Cloud Pub/Sub API" and click on it
   - Click "Enable"

4. **Create OAuth Credentials**:
   - Go to "APIs & Services" > "Credentials"
   - Click "Create Credentials" > "OAuth client ID"
   - Set the application type to "Desktop app"
   - Click "Create"
   - Note your Client ID and Client Secret for your `.env` file:
     ```
     GOOGLE_CLIENT_ID=your_client_id
     GOOGLE_CLIENT_SECRET=your_client_secret
     ```

### Setting up Google Pub/Sub for Gmail Notifications

To enable real-time email notifications, you need to set up a Google Cloud Pub/Sub topic and subscription:

1. **Create a Pub/Sub Topic**:
   - In your Google Cloud Console, go to "Pub/Sub" > "Topics"
   - Click "Create Topic"
   - Name your topic (e.g., `gmail-notifications`)
   - Add the service account `gmail-api-push@system.gserviceaccount.com` as a Topic Publisher to allow Gmail to publish notifications
   - Click "Create"
   - Note the full topic name (usually `projects/your-project-id/topics/gmail-notifications`) for your `.env` file:
     ```
     GOOGLE_PUBSUB_TOPIC=projects/your-project-id/topics/gmail-notifications
     ```

2. **Create a Pub/Sub Subscription**:
   - Once your topic is created, click "Create Subscription"
   - Name your subscription (e.g., `gmail-notifications-push`)
   - Set the Delivery Type to "Push"
   - Set the Endpoint URL to your webhook URL (e.g., `https://your-domain.com/api/gmail-webhook`)
     - For local development, you'll need to use a tool like ngrok to expose your local server
   - Click "Create"

3. **Set up Domain Verification** (if needed):
   - If you're using a custom domain for your webhook endpoint, you may need to verify domain ownership
   - Follow the instructions in Google Cloud Console for domain verification

### Gmail API Authentication

This project includes a complete OAuth2 authentication flow for the Gmail API:

1. Start the development server: `pnpm dev`
2. Navigate to the authentication workflow in the iii development console
3. The workflow will generate an authorization URL
4. Open the URL in your browser and authorize the application
5. The application will receive and store your authentication tokens

### Discord Webhook Configuration

To receive daily email summaries in Discord, follow these steps to set up a webhook:

1. **Create a Discord Server** (skip if you already have one):
   - Open Discord and click the "+" icon on the left sidebar
   - Select "Create My Own" and follow the setup wizard

2. **Create a Channel for Notifications**:
   - Right-click on your server name and select "Server Settings"
   - Go to "Channels" and click "Create Channel"
   - Name it (e.g., "email-summaries") and click "Create"

3. **Create a Webhook**:
   - Right-click on your new channel and select "Edit Channel"
   - Go to "Integrations" tab
   - Click "Create Webhook"
   - Give it a name (e.g., "Gmail Summary Bot")
   - Optionally, customize the avatar
   - Click "Copy Webhook URL"

4. **Add Webhook URL to Environment Variables**:
   - Open your `.env` file
   - Add or update the Discord webhook URL:
     ```
     DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/your-webhook-url
     ```

5. **Test the Webhook**:
   - You can test if your webhook is working correctly with this curl command:
     ```bash
     curl -X POST -H "Content-Type: application/json" \
     -d '{"content": "Testing Gmail Account Manager webhook"}' \
     https://discord.com/api/webhooks/your-webhook-url
     ```
   - You should see the message appear in your Discord channel

### Hugging Face Setup

1. **Create a Hugging Face Account**:
   - Sign up at [Hugging Face](https://huggingface.co/join)

2. **Generate an API Token**:
   - Go to your [Hugging Face account settings](https://huggingface.co/settings/tokens)
   - Create a new API token
   - Copy the token to your `.env` file:
     ```
     HUGGINGFACE_API_TOKEN=your_api_token
     ```

</Steps>

## 📁 Project Structure

- `steps/` - Contains all workflow steps
  - `gmail-get-auth-url.step.ts` - Generates OAuth2 URL
  - `gmail-auth.step.ts` - Handles OAuth2 flow
  - `gmail-token-status.step.ts` - Manages token refresh
  - `gmail-webhook.step.ts` - Webhook endpoint for Gmail notifications
  - `gmail-watch.step.ts` - Sets up Gmail push notifications
  - `fetch-email.step.ts` - Fetches email content from Gmail API
  - `analyze-email.step.py` - Python step for email analysis using Hugging Face
  - `organize-email.step.ts` - Organizes emails (labels, archives)
  - `auto-responder.step.ts` - Generates appropriate responses
  - `daily-summary.step.ts` - Sends daily summary to Discord
- `services/` - Shared service modules
- `config/` - Configuration files
- `.motia/` - Motia framework configuration

## 📦 Dependencies

### Node.js Dependencies
- **motia**: Motia framework
- **googleapis**, **google-auth-library**: Google API integration
- **gmail-api-parse-message-ts**: Gmail message parsing
- **axios**: HTTP client
- **zod**: Schema validation
- **react**: UI components

### Python Dependencies
- **transformers**, **torch**: Machine learning models
- **scikit-learn**, **numpy**, **pandas**: Data processing
- **huggingface_hub**: Access to Hugging Face models
- **python-dotenv**: Environment variable loading

## 🛠️ Troubleshooting

- **Python Module Errors**: Ensure you've installed all required Python packages with `pip install -r requirements.txt`
- **Authentication Errors**: Verify your API credentials and follow the authentication flow
- **Webhook Issues**: Make sure the webhook endpoint is publicly accessible or properly configured for testing
- **Token Refresh Errors**: Check that your OAuth tokens are valid and that the refresh flow is working properly
- **Pub/Sub Not Working**: Verify that your Pub/Sub topic and subscription are properly configured and that your service account has the necessary permissions

## 📝 Environment Variables

Create a `.env` file with the following variables:

```
# Google API Configuration
GOOGLE_CLIENT_ID=your_client_id
GOOGLE_CLIENT_SECRET=your_client_secret
GOOGLE_PUBSUB_TOPIC=projects/your-project-id/topics/gmail-notifications

# HuggingFace Configuration
HUGGINGFACE_API_TOKEN=your_huggingface_token

# Discord Integration
DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/your-webhook-url

# Auto-Responder Configuration
AUTO_RESPONDER_NAME=Your Name
AUTO_RESPONDER_EMAIL=your-email@example.com
```



## Examples
[gmail-automation](/docs/examples/gmail-automation): Code example
---
title: 'Gmail Automation'
description: Build an automated email system with smart labeling, auto-responses, and AI-powered filtering
---

---

## Workflow Overview

<div className="my-8">![Gmail Automation](./../img/gmail-automation.png)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/integrations/communication/gmail-workflow)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## Let's build a Gmail automation system that:

- 📊 Smart email classification by category (work, personal, social, promotion, spam, update)
- 🚨 Urgency detection (high, medium, low) with prioritization
- 💬 Intelligent automated responses based on email context
- 🏷️ Automatic email organization (labeling, archiving)
- 📈 Daily summary reports via Discord
- 🔒 Secure Gmail API integration with OAuth2 authentication flow
- ⚡ Real-time email monitoring with webhook notifications

## The Steps

<Folder name="steps" defaultOpen>
  <File name="analyze-email.step.py" />
  <File name="auto-responder.step.ts" />
  <File name="daily-summary.step.ts" />
  <File name="fetch-email.step.ts" />
  <File name="gmail-webhook.step.ts" />
  <File name="organize-email.step.ts" />
</Folder>

<Callout type="info">
This example uses the `steps/` directory, but you can also use `src/` or both. Motia discovers step files from either location automatically.
</Callout>

View the source code for each step in the [GitHub repository](https://github.com/MotiaDev/motia-examples/tree/main/examples/integrations/communication/gmail-workflow).

## Visual Overview

Here's how the automation flow works:

<div className="my-8">![Flow: Gmail Automation Steps](../img/gmail-automation.png)</div>

## 🌊 Workflow Architecture

The Gmail Account Manager workflow consists of the following steps:

### 1. Gmail Authentication (Multi-Step Flow)
- **Files**: 
  - `steps/gmail-get-auth-url.step.ts`: Generates OAuth2 authorization URL
  - `steps/gmail-auth.step.ts`: Handles authorization code exchange
  - `steps/gmail-token-status.step.ts`: Checks token validity and refreshes if needed

### 2. Gmail Webhook (HTTP Step)
- **File**: `steps/gmail-webhook.step.ts`
- **Purpose**: Receives notifications from Gmail when new emails arrive
- **Enqueues**: `gmail.new_email` event with message details
- **Endpoint**: `POST /api/gmail-webhook`

### 3. Gmail Watch (HTTP Step)
- **File**: `steps/gmail-watch.step.ts`
- **Purpose**: Sets up push notifications for the Gmail account
- **Endpoint**: `GET /api/watch`

### 4. Fetch Email (Queue Step)
- **File**: `steps/fetch-email.step.ts`
- **Purpose**: Retrieves the full email content from Gmail API
- **Queue trigger**: `gmail.email.received`
- **Enqueues**: `gmail.email.fetched` with complete email data
- **Key Functions**: Authenticates with Gmail API, fetches message content, parses attachments

### 5. Analyze Email (Queue Step)
- **File**: `steps/analyze-email.step.py`
- **Purpose**: Uses Hugging Face models to analyze email content
- **Queue trigger**: `gmail.email.fetched`
- **Enqueues**: `gmail.email.analyzed` with analysis results
- **Analysis Performed**: 
  - Category classification
  - Urgency detection
  - Sentiment analysis
  - Key information extraction

### 6. Organize Email (Queue Step)
- **File**: `steps/organize-email.step.ts`
- **Purpose**: Applies labels and organization based on analysis
- **Queue trigger**: `gmail.email.analyzed`
- **Enqueues**: `[gmail.email.organized, gmail.email.archived]`
- **Actions**: Creates/applies labels, archives certain emails, marks importance

### 7. Auto-Respond to Email (Queue Step)
- **File**: `steps/auto-responder.step.ts`
- **Purpose**: Generates and sends appropriate responses for certain emails
- **Queue trigger**: `gmail.email.analyzed`
- **Enqueues**: `gmail.email.responded`
- **Features**: 
  - Template selection based on email context
  - Personalization of responses
  - Auto-reply for urgent messages
  - Follow-up scheduling

### 8. Daily Summary (Cron Step)
- **File**: `steps/daily-summary.step.ts`
- **Purpose**: Compiles and sends daily email activity summary
- **Schedule**: Runs daily at 6:00 PM
- **Enqueues**: `gmail.summary.sent`
- **Delivery**: Sends report to Discord via webhook

## Try It Out

<Steps>
## 📋 Prerequisites

- **Node.js** (v18+)
- **Python** (v3.8+)
- **Gmail API credentials** (client_id and client_secret)
- **Google Cloud project** with Pub/Sub API enabled
- **Hugging Face API token**
- **Discord webhook URL** (for daily summaries)

## 🚀 Quick Start

1. **Clone this repository**
   ```bash
   git clone https://github.com/yourusername/gmail-flow.git
   cd gmail-flow
   ```

2. **Install Node.js dependencies**
   ```bash
   pnpm install
   ```

3. **Install Python dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure environment variables**
   ```bash
   cp .env.example .env
   ```
   Then edit the `.env` file with your credentials (see setup sections below).

5. **Start the development server**
   ```bash
   pnpm dev
   ```

6. **Open the iii development console**
   
   Navigate to [http://localhost:3000](http://localhost:3000) to view the workflow.

## 🔧 Detailed Setup

### Setting up Google Cloud Project and Gmail API

Before you can use the Gmail Account Manager, you need to set up a Google Cloud project with the Gmail API and Pub/Sub:

1. **Create a Google Cloud Project**:
   - Go to [Google Cloud Console](https://console.cloud.google.com/)
   - Click on "New Project" and follow the steps to create a new project
   - Note your project ID for later use

2. **Enable the Gmail API**:
   - In your project, go to "APIs & Services" > "Library"
   - Search for "Gmail API" and click on it
   - Click "Enable"

3. **Enable the Pub/Sub API**:
   - In your project, go to "APIs & Services" > "Library"
   - Search for "Cloud Pub/Sub API" and click on it
   - Click "Enable"

4. **Create OAuth Credentials**:
   - Go to "APIs & Services" > "Credentials"
   - Click "Create Credentials" > "OAuth client ID"
   - Set the application type to "Desktop app"
   - Click "Create"
   - Note your Client ID and Client Secret for your `.env` file:
     ```
     GOOGLE_CLIENT_ID=your_client_id
     GOOGLE_CLIENT_SECRET=your_client_secret
     ```

### Setting up Google Pub/Sub for Gmail Notifications

To enable real-time email notifications, you need to set up a Google Cloud Pub/Sub topic and subscription:

1. **Create a Pub/Sub Topic**:
   - In your Google Cloud Console, go to "Pub/Sub" > "Topics"
   - Click "Create Topic"
   - Name your topic (e.g., `gmail-notifications`)
   - Add the service account `gmail-api-push@system.gserviceaccount.com` as a Topic Publisher to allow Gmail to publish notifications
   - Click "Create"
   - Note the full topic name (usually `projects/your-project-id/topics/gmail-notifications`) for your `.env` file:
     ```
     GOOGLE_PUBSUB_TOPIC=projects/your-project-id/topics/gmail-notifications
     ```

2. **Create a Pub/Sub Subscription**:
   - Once your topic is created, click "Create Subscription"
   - Name your subscription (e.g., `gmail-notifications-push`)
   - Set the Delivery Type to "Push"
   - Set the Endpoint URL to your webhook URL (e.g., `https://your-domain.com/api/gmail-webhook`)
     - For local development, you'll need to use a tool like ngrok to expose your local server
   - Click "Create"

3. **Set up Domain Verification** (if needed):
   - If you're using a custom domain for your webhook endpoint, you may need to verify domain ownership
   - Follow the instructions in Google Cloud Console for domain verification

### Gmail API Authentication

This project includes a complete OAuth2 authentication flow for the Gmail API:

1. Start the development server: `pnpm dev`
2. Navigate to the authentication workflow in the iii development console
3. The workflow will generate an authorization URL
4. Open the URL in your browser and authorize the application
5. The application will receive and store your authentication tokens

### Discord Webhook Configuration

To receive daily email summaries in Discord, follow these steps to set up a webhook:

1. **Create a Discord Server** (skip if you already have one):
   - Open Discord and click the "+" icon on the left sidebar
   - Select "Create My Own" and follow the setup wizard

2. **Create a Channel for Notifications**:
   - Right-click on your server name and select "Server Settings"
   - Go to "Channels" and click "Create Channel"
   - Name it (e.g., "email-summaries") and click "Create"

3. **Create a Webhook**:
   - Right-click on your new channel and select "Edit Channel"
   - Go to "Integrations" tab
   - Click "Create Webhook"
   - Give it a name (e.g., "Gmail Summary Bot")
   - Optionally, customize the avatar
   - Click "Copy Webhook URL"

4. **Add Webhook URL to Environment Variables**:
   - Open your `.env` file
   - Add or update the Discord webhook URL:
     ```
     DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/your-webhook-url
     ```

5. **Test the Webhook**:
   - You can test if your webhook is working correctly with this curl command:
     ```bash
     curl -X POST -H "Content-Type: application/json" \
     -d '{"content": "Testing Gmail Account Manager webhook"}' \
     https://discord.com/api/webhooks/your-webhook-url
     ```
   - You should see the message appear in your Discord channel

### Hugging Face Setup

1. **Create a Hugging Face Account**:
   - Sign up at [Hugging Face](https://huggingface.co/join)

2. **Generate an API Token**:
   - Go to your [Hugging Face account settings](https://huggingface.co/settings/tokens)
   - Create a new API token
   - Copy the token to your `.env` file:
     ```
     HUGGINGFACE_API_TOKEN=your_api_token
     ```

</Steps>

## 📁 Project Structure

- `steps/` - Contains all workflow steps
  - `gmail-get-auth-url.step.ts` - Generates OAuth2 URL
  - `gmail-auth.step.ts` - Handles OAuth2 flow
  - `gmail-token-status.step.ts` - Manages token refresh
  - `gmail-webhook.step.ts` - Webhook endpoint for Gmail notifications
  - `gmail-watch.step.ts` - Sets up Gmail push notifications
  - `fetch-email.step.ts` - Fetches email content from Gmail API
  - `analyze-email.step.py` - Python step for email analysis using Hugging Face
  - `organize-email.step.ts` - Organizes emails (labels, archives)
  - `auto-responder.step.ts` - Generates appropriate responses
  - `daily-summary.step.ts` - Sends daily summary to Discord
- `services/` - Shared service modules
- `config/` - Configuration files
- `.motia/` - Motia framework configuration

## 📦 Dependencies

### Node.js Dependencies
- **motia**: Motia framework
- **googleapis**, **google-auth-library**: Google API integration
- **gmail-api-parse-message-ts**: Gmail message parsing
- **axios**: HTTP client
- **zod**: Schema validation
- **react**: UI components

### Python Dependencies
- **transformers**, **torch**: Machine learning models
- **scikit-learn**, **numpy**, **pandas**: Data processing
- **huggingface_hub**: Access to Hugging Face models
- **python-dotenv**: Environment variable loading

## 🛠️ Troubleshooting

- **Python Module Errors**: Ensure you've installed all required Python packages with `pip install -r requirements.txt`
- **Authentication Errors**: Verify your API credentials and follow the authentication flow
- **Webhook Issues**: Make sure the webhook endpoint is publicly accessible or properly configured for testing
- **Token Refresh Errors**: Check that your OAuth tokens are valid and that the refresh flow is working properly
- **Pub/Sub Not Working**: Verify that your Pub/Sub topic and subscription are properly configured and that your service account has the necessary permissions

## 📝 Environment Variables

Create a `.env` file with the following variables:

```
# Google API Configuration
GOOGLE_CLIENT_ID=your_client_id
GOOGLE_CLIENT_SECRET=your_client_secret
GOOGLE_PUBSUB_TOPIC=projects/your-project-id/topics/gmail-notifications

# HuggingFace Configuration
HUGGINGFACE_API_TOKEN=your_huggingface_token

# Discord Integration
DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/your-webhook-url

# Auto-Responder Configuration
AUTO_RESPONDER_NAME=Your Name
AUTO_RESPONDER_EMAIL=your-email@example.com
```


-   [human-in-the-loop-workflows](/docs/examples/human-in-the-loop-workflows): Documentation for human-in-the-loop-workflows.
---
title: Human-in-the-Loop Workflows
description: Build workflows that pause for human decisions and resume when ready
---

Some workflows need humans to make decisions.

Maybe it's approving a high-value order. Or reviewing content before publishing. Or signing off on a production deployment. These workflows need to **pause**, wait for a human decision, and **continue** when the decision arrives.

Motia handles this naturally. You save your progress, stop emitting events, and create an API webhook for the human to call. When they make their decision, the webhook picks up right where you left off.

## How It Works

Human-in-the-Loop workflows in Motia work like this:

1. **Process automatically when possible** - Let the system handle what it can
2. **Save "awaiting" state when human needed** - Mark the pause point clearly
3. **Stop enqueuing** - The workflow naturally pauses
4. **Webhook resumes the flow** - External systems call an API to continue

No special "pause" or "wait" commands. Just save state and use HTTP trigger steps as re-entry points.

---

## Key Ideas

| Concept | What It Means |
|---------|---------------|
| **Workflows don't sleep** | They don't "wait." They save state and stop processing. |
| **HTTP steps are re-entry points** | External systems call webhooks to restart the flow |
| **State checkpointing** | Every `state.set()` is a save point you can resume from |
| **Virtual connections** | Use `virtualSubscribes` and `virtualEnqueues` to show how webhooks fit in the flow visually |

<Callout type="info">
The workflow doesn't have a concept of time. It only knows: "Is the right state present? Has the right step been triggered?"
</Callout>

---

## Real Example: Order Approval

Let's build an order processing system that auto-approves low-risk orders but pauses for human review on high-risk ones.

**Example Location:** `examples/foundational/workflow-patterns/human-in-the-loop/`

[View on GitHub →](https://github.com/MotiaDev/motia-examples/tree/main/examples/foundational/workflow-patterns/human-in-the-loop)

### The Flow

![HTL Example](../img/htl-example.png)


### Step 1: Submit Order

An API receives the order and saves it immediately:

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript title="src/01-submit-order.step.ts"
import { type Handlers, type StepConfig } from 'motia'

export const config = {
  name: 'SubmitOrder',
  description: 'Submit an order for processing',
  triggers: [
    { type: 'http', path: '/orders', method: 'POST' },
  ],
  enqueues: ['order.submitted'],
  flows: ['order-approval'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (req, { state, enqueue, logger }) => {
  const orderId = crypto.randomUUID()
  
  const order = {
    id: orderId,
    items: req.body.items,
    total: req.body.total,
    status: 'pending_analysis',
    currentStep: 'submitted',
    completedSteps: ['submitted'],  // Track progress for idempotency
    createdAt: new Date().toISOString()
  }
  
  // Save immediately - this is our first checkpoint
  await state.set('orders', orderId, order)
  
  logger.info('Order submitted', { orderId })
  
  // Kick off risk analysis
  await enqueue({
    topic: 'order.submitted',
    data: { orderId }
  })

  return { status: 201, body: { orderId, status: order.status } }
}
```

</Tab>
<Tab value='Python'>

```python title="src/submit_order_step.py"
import uuid
from datetime import datetime

config = {
    "name": "SubmitOrder",
    "description": "Submit an order for processing",
    "triggers": [
        {"type": "http", "path": "/orders", "method": "POST"}
    ],
    "enqueues": ["order.submitted"],
    "flows": ["order-approval"]
}

async def handler(req, context):
    order_id = str(uuid.uuid4())
    
    # Access request body
    body = req.get("body", {})
    
    order = {
        "id": order_id,
        "items": body.get("items"),
        "total": body.get("total"),
        "status": "pending_analysis",
        "current_step": "submitted",
        "completed_steps": ["submitted"],
        "created_at": datetime.now().isoformat()
    }
    
    # Save immediately - first checkpoint
    await context.state.set("orders", order_id, order)
    
    context.logger.info("Order submitted", {"orderId": order_id})
    
    # Kick off risk analysis
    await context.enqueue({
        "topic": "order.submitted",
        "data": {"orderId": order_id}
    })

    return {"status": 201, "body": {"orderId": order_id, "status": order["status"]}}
```

</Tab>
<Tab value='JavaScript'>

```javascript title="src/submit-order.step.js"
import crypto from 'crypto'

export const config = {
  name: 'SubmitOrder',
  description: 'Submit an order for processing',
  triggers: [
    { type: 'http', path: '/orders', method: 'POST' },
  ],
  enqueues: ['order.submitted'],
  flows: ['order-approval'],
}

export const handler = async (req, { state, enqueue, logger }) => {
  const orderId = crypto.randomUUID()
  const { items, total } = req.body

  const order = {
    id: orderId,
    items,
    total,
    status: 'pending_analysis',
    currentStep: 'submitted',
    completedSteps: ['submitted'],
    createdAt: new Date().toISOString()
  }

  // Save immediately - first checkpoint
  await state.set('orders', orderId, order)

  logger.info('Order submitted', { orderId })

  await enqueue({
    topic: 'order.submitted',
    data: { orderId }
  })

  return { status: 201, body: { orderId, status: order.status } }
}
```

</Tab>
</Tabs>

👉 **Key point:** We save the order immediately with `currentStep` and `completedSteps`. This becomes our checkpoint system.

### Step 2: Analyze Risk

This step decides whether to auto-approve or pause for human review:

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript title="src/02-analyze-risk.step.ts"
import { type Handlers, type StepConfig } from 'motia'

export const config = {
  name: 'AnalyzeRisk',
  description: 'Analyze order risk and route accordingly',
  triggers: [
    { type: 'queue', topic: 'order.submitted' },
  ],
  enqueues: ['order.auto_approved'],
  virtualEnqueues: [{ topic: 'approval.required', label: 'Requires human approval' }],
  flows: ['order-approval'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (input, { state, enqueue, logger }) => {
  const { orderId } = input
  const order = await state.get('orders', orderId)
  
  // Skip if already analyzed (idempotency)
  if (order.completedSteps.includes('risk_analysis')) {
    return
  }
  
  // Calculate risk score
  const riskScore = calculateRiskScore(order)
  order.riskScore = riskScore
  order.completedSteps.push('risk_analysis')
  
  if (riskScore > 70) {
    // High risk - PAUSE for human approval
    order.status = 'awaiting_approval'
    order.currentStep = 'awaiting_approval'
    await state.set('orders', orderId, order)
    
    logger.warn('Order requires approval - workflow paused', { orderId, riskScore })
    
    // NO EMIT - workflow stops here
    // Webhook will restart it when human makes decision
    
  } else {
    // Low risk - bypass gate and auto-approve
    order.status = 'approved'
    order.approvedBy = 'system'
    order.completedSteps.push('approved')
    await state.set('orders', orderId, order)
    
    logger.info('Order auto-approved', { orderId, riskScore })
    
    // Continue immediately
    await enqueue({ topic: 'order.auto_approved', data: { orderId } })
  }
}

function calculateRiskScore(order: any): number {
  let score = 0
  if (order.total > 1000) score += 40
  else if (order.total > 500) score += 20
  
  const itemCount = order.items.reduce((sum, item) => sum + item.quantity, 0)
  if (itemCount > 10) score += 30
  
  score += Math.random() * 40
  return Math.min(Math.round(score), 100)
}
```

</Tab>
<Tab value='Python'>

```python title="src/analyze_risk_step.py"
import random

config = {
    "name": "AnalyzeRisk",
    "description": "Analyze order risk and route accordingly",
    "triggers": [
        {"type": "queue", "topic": "order.submitted"}
    ],
    "enqueues": ["order.auto_approved"],
    "virtualEnqueues": [{"topic": "approval.required", "label": "Requires human approval"}],
    "flows": ["order-approval"]
}

async def handler(input_data, context):
    order_id = input_data.get("orderId")
    order = await context.state.get("orders", order_id)
    
    # Skip if already analyzed
    if "risk_analysis" in order.get("completed_steps", []):
        return
    
    # Calculate risk
    risk_score = calculate_risk_score(order)
    order["risk_score"] = risk_score
    order["completed_steps"].append("risk_analysis")
    
    if risk_score > 70:
        # High risk - PAUSE
        order["status"] = "awaiting_approval"
        order["current_step"] = "awaiting_approval"
        await context.state.set("orders", order_id, order)
        
        context.logger.warn("Order requires approval - workflow paused", 
                           {"orderId": order_id, "riskScore": risk_score})
        # NO EMIT - workflow stops
        
    else:
        # Low risk - bypass gate
        order["status"] = "approved"
        order["approved_by"] = "system"
        order["completed_steps"].append("approved")
        await context.state.set("orders", order_id, order)
        
        context.logger.info("Order auto-approved", 
                           {"orderId": order_id, "riskScore": risk_score})
        
        await context.enqueue({
            "topic": "order.auto_approved",
            "data": {"orderId": order_id}
        })

def calculate_risk_score(order):
    score = 0
    total = order.get("total", 0)
    if total > 1000:
        score += 40
    elif total > 500:
        score += 20
    
    items = order.get("items", [])
    item_count = sum(item.get("quantity", 0) for item in items)
    if item_count > 10:
        score += 30
    
    score += random.random() * 40
    return min(round(score), 100)
```

</Tab>
<Tab value='JavaScript'>

```javascript title="src/analyze-risk.step.js"
export const config = {
  name: 'AnalyzeRisk',
  description: 'Analyze order risk and route accordingly',
  triggers: [
    { type: 'queue', topic: 'order.submitted' },
  ],
  enqueues: ['order.auto_approved'],
  virtualEnqueues: [{ topic: 'approval.required', label: 'Requires human approval' }],
  flows: ['order-approval'],
}

export const handler = async (input, { state, enqueue, logger }) => {
  const { orderId } = input
  const order = await state.get('orders', orderId)
  
  // Skip if already analyzed (idempotency)
  if (order.completedSteps.includes('risk_analysis')) {
    return
  }
  
  const riskScore = calculateRiskScore(order)
  order.riskScore = riskScore
  order.completedSteps.push('risk_analysis')
  
  if (riskScore > 70) {
    // High risk - PAUSE
    order.status = 'awaiting_approval'
    order.currentStep = 'awaiting_approval'
    await state.set('orders', orderId, order)
    
    logger.warn('Order requires approval - workflow paused', { orderId, riskScore })
    // NO EMIT - workflow stops here
    
  } else {
    // Low risk - bypass gate
    order.status = 'approved'
    order.approvedBy = 'system'
    order.completedSteps.push('approved')
    await state.set('orders', orderId, order)
    
    logger.info('Order auto-approved', { orderId, riskScore })
    await enqueue({ topic: 'order.auto_approved', data: { orderId } })
  }
}

function calculateRiskScore(order) {
  let score = 0
  if (order.total > 1000) score += 40
  else if (order.total > 500) score += 20
  
  const itemCount = order.items.reduce((sum, item) => sum + item.quantity, 0)
  if (itemCount > 10) score += 30
  
  score += Math.random() * 40
  return Math.min(Math.round(score), 100)
}
```

</Tab>
</Tabs>

👉 **The key decision:**
- **High risk:** Save "awaiting" state and **don't enqueue** → workflow stops
- **Low risk:** Emit immediately → workflow continues

### Step 3: Human Approval Gate (Visual Noop)

This creates a visual node in the iii development console showing where the workflow pauses:

```typescript title="src/03-human-approval-gate.step.ts"
import type { NoopConfig } from 'motia'

export const config: NoopConfig = {
  type: 'noop',
  name: 'HumanApprovalGate',
  description: 'Workflow pauses here - awaiting human decision via webhook',
  flows: ['order-approval'],
  
  // Receives signal that approval is needed
  virtualSubscribes: ['approval.required'],
  
  // Shows connection to webhook that continues flow
  virtualEnqueues: ['human.decision'],
}
```
👉 **In the iii development console:** This Noop appears between AnalyzeRisk and ApprovalWebhook.


### Step 4: Approval Webhook (Re-Entry Point)

External systems (UI, Slack, etc.) call this webhook to provide the human decision:

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript title="src/04-approval-webhook.step.ts"
import { type Handlers, type StepConfig } from 'motia'

export const config = {
  name: 'ApprovalWebhook',
  description: 'Webhook for human approval decisions',
  triggers: [
    { type: 'http', path: '/webhooks/orders/:orderId/approve', method: 'POST' },
  ],
  enqueues: ['order.approved'],
  virtualSubscribes: ['human.decision'],
  flows: ['order-approval'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (req, { state, enqueue, logger }) => {
  const { orderId } = req.pathParams
  const { approved, approvedBy, notes } = req.body
  
  // Load the checkpoint
  const order = await state.get('orders', orderId)
  
  if (!order) {
    return { status: 404, body: { error: 'Order not found' } }
  }
  
  // Verify we're at the right pause point
  if (order.currentStep !== 'awaiting_approval') {
    return { status: 400, body: { error: 'Order not awaiting approval' } }
  }
  
  if (approved) {
    // Apply decision
    order.status = 'approved'
    order.approvedBy = approvedBy
    order.approvedAt = new Date().toISOString()
    order.completedSteps.push('approved')
    await state.set('orders', orderId, order)
    
    logger.info('Order approved - resuming workflow', { orderId, approvedBy })
    
    // Resume the workflow
    await enqueue({ topic: 'order.approved', data: { orderId } })

    return { status: 200, body: { success: true, message: 'Order approved' } }
  } else {
    // Rejected - workflow ends
    order.status = 'rejected'
    order.rejectedBy = approvedBy
    order.rejectionReason = notes
    await state.set('orders', orderId, order)
    
    logger.info('Order rejected - workflow ends', { orderId })
    return { status: 200, body: { success: true, message: 'Order rejected' } }
  }
}
```

</Tab>
<Tab value='Python'>

```python title="src/approval_webhook_step.py"
from datetime import datetime

config = {
    "name": "ApprovalWebhook",
    "description": "Webhook for human approval decisions",
    "triggers": [
        {"type": "http", "path": "/webhooks/orders/:orderId/approve", "method": "POST"}
    ],
    "enqueues": ["order.approved"],
    "virtualSubscribes": ["human.decision"],
    "flows": ["order-approval"]
}

async def handler(req, context):
    # Access path params and body
    path_params = req.get("pathParams", {})
    body = req.get("body", {})
    
    order_id = path_params.get("orderId")
    approved = body.get("approved")
    approved_by = body.get("approvedBy")
    notes = body.get("notes")
    
    # Load checkpoint
    order = await context.state.get("orders", order_id)
    
    if not order:
        return {"status": 404, "body": {"error": "Order not found"}}
    
    # Verify pause point
    if order["current_step"] != "awaiting_approval":
        return {"status": 400, "body": {"error": "Not awaiting approval"}}
    
    if approved:
        # Resume workflow
        order["status"] = "approved"
        order["approved_by"] = approved_by
        order["approved_at"] = datetime.now().isoformat()
        order["completed_steps"].append("approved")
        await context.state.set("orders", order_id, order)
        
        context.logger.info("Order approved - resuming workflow", 
                           {"orderId": order_id, "approvedBy": approved_by})
        
        await context.enqueue({
            "topic": "order.approved",
            "data": {"orderId": order_id}
        })
        
        return {"status": 200, "body": {"success": True}}
    else:
        # Rejected - end workflow
        order["status"] = "rejected"
        order["rejected_by"] = approved_by
        await context.state.set("orders", order_id, order)
        
        return {"status": 200, "body": {"success": True}}
```

</Tab>
<Tab value='JavaScript'>

```javascript title="src/approval-webhook.step.js"
export const config = {
  name: 'ApprovalWebhook',
  description: 'Webhook for human approval decisions',
  triggers: [
    { type: 'http', path: '/webhooks/orders/:orderId/approve', method: 'POST' },
  ],
  enqueues: ['order.approved'],
  virtualSubscribes: ['human.decision'],
  flows: ['order-approval'],
}

export const handler = async (req, { state, enqueue, logger }) => {
  const { orderId } = req.pathParams
  const { approved, approvedBy, notes } = req.body
  
  // Load checkpoint
  const order = await state.get('orders', orderId)
  
  if (!order) {
    return { status: 404, body: { error: 'Order not found' } }
  }
  
  // Verify pause point
  if (order.currentStep !== 'awaiting_approval') {
    return { status: 400, body: { error: 'Not awaiting approval' } }
  }
  
  if (approved) {
    // Resume workflow
    order.status = 'approved'
    order.approvedBy = approvedBy
    order.approvedAt = new Date().toISOString()
    order.completedSteps.push('approved')
    await state.set('orders', orderId, order)
    
    logger.info('Order approved - resuming', { orderId, approvedBy })
    
    await enqueue({ topic: 'order.approved', data: { orderId } })
    return { status: 200, body: { success: true } }
  } else {
    // Rejected - end workflow
    order.status = 'rejected'
    order.rejectedBy = approvedBy
    await state.set('orders', orderId, order)

    logger.info('Order rejected', { orderId })
    return { status: 200, body: { success: true } }
  }
}
```

</Tab>
</Tabs>

👉 **The pattern:** Load checkpoint → Verify state → Apply decision → Resume or end

### Step 5: Complete Order

Final step that runs after approval:

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript title="src/05-complete-order.step.ts"
import { type Handlers, type StepConfig } from 'motia'

export const config = {
  name: 'CompleteOrder',
  description: 'Complete an approved order',
  triggers: [
    { type: 'queue', topic: 'order.approved' },
    { type: 'queue', topic: 'order.auto_approved' },
  ],
  enqueues: [],
  flows: ['order-approval'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (input, { state, logger }) => {
  const { orderId } = input
  const order = await state.get('orders', orderId)
  
  // Skip if already completed (idempotency)
  if (order.completedSteps.includes('completed')) {
    return
  }
  
  // Process fulfillment
  await simulateFulfillment(order)
  
  order.status = 'completed'
  order.completedAt = new Date().toISOString()
  order.completedSteps.push('completed')
  await state.set('orders', orderId, order)
  
  logger.info('Order completed', { orderId, approvedBy: order.approvedBy })
}

async function simulateFulfillment(order: any) {
  // In production: charge payment, create shipment, send email
  await new Promise(resolve => setTimeout(resolve, 1000))
}
```

</Tab>
<Tab value='Python'>

```python title="src/complete_order_step.py"
import asyncio

config = {
    "name": "CompleteOrder",
    "description": "Complete an approved order",
    "triggers": [
        {"type": "queue", "topic": "order.approved"},
        {"type": "queue", "topic": "order.auto_approved"}
    ],
    "enqueues": [],
    "flows": ["order-approval"]
}

async def handler(input_data, context):
    order_id = input_data.get("orderId")
    order = await context.state.get("orders", order_id)
    
    # Skip if already completed (idempotency)
    if "completed" in order.get("completed_steps", []):
        return
    
    # Fulfill order
    await asyncio.sleep(1)
    
    order["status"] = "completed"
    order["completed_steps"].append("completed")
    await context.state.set("orders", order_id, order)
    
    context.logger.info("Order completed", {"orderId": order_id})
```

</Tab>
<Tab value='JavaScript'>

```javascript title="src/complete-order.step.js"
export const config = {
  name: 'CompleteOrder',
  description: 'Complete an approved order',
  triggers: [
    { type: 'queue', topic: 'order.approved' },
    { type: 'queue', topic: 'order.auto_approved' },
  ],
  enqueues: [],
  flows: ['order-approval'],
}

export const handler = async (input, { state, logger }) => {
  const { orderId } = input
  const order = await state.get('orders', orderId)
  
  // Skip if already completed (idempotency)
  if (order.completedSteps.includes('completed')) {
    return
  }
  
  // Fulfill order
  await new Promise(resolve => setTimeout(resolve, 1000))
  
  order.status = 'completed'
  order.completedSteps.push('completed')
  await state.set('orders', orderId, order)
  
  logger.info('Order completed', { orderId, approvedBy: order.approvedBy })
}
```

</Tab>
</Tabs>

---

## Recovery Pattern: Timeout Detection

What happens if a human never responds? In production, you need a safety mechanism to detect and escalate stuck workflows.

### Step 6: Timeout Detection (Cron)

A scheduled job periodically scans for orders stuck in approval:

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript title="src/06-detect-timeouts.step.ts"
import { type Handlers, type StepConfig, cron } from 'motia'

export const config = {
  name: 'DetectTimeouts',
  description: 'Find orders stuck awaiting approval and escalate',
  triggers: [
    cron('0 */5 * * * * *'),
  ],
  enqueues: [],
  flows: ['order-approval'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async ({ state, logger }) => {
  const orders = await state.list('orders')
  const now = Date.now()
  const timeoutMs = 10 * 60 * 1000  // 10 minutes (demo - use 24 hours in production)
  
  let stuckCount = 0
  
  for (const order of orders) {
    // Find orders stuck in awaiting_approval
    if (order.status === 'awaiting_approval') {
      const lastUpdate = new Date(order.updatedAt || order.createdAt).getTime()
      const age = now - lastUpdate
      
      if (age > timeoutMs) {
        stuckCount++
        
        logger.warn('Approval timeout detected', {
          orderId: order.id,
          ageMinutes: Math.round(age / (60 * 1000)),
          riskScore: order.riskScore,
          total: order.total
        })
        
        // Mark as timed out
        order.status = 'timeout'
        order.timeoutAt = new Date().toISOString()
        order.timeoutReason = `No approval within ${Math.round(timeoutMs / (60 * 1000))} min`
        await state.set('orders', order.id, order)
        
        // In production, take action:
        // 1. Send escalation notification (Slack, email)
        // 2. Auto-reject if too old
        // 3. Assign to different manager
        // 4. Create support ticket
        
        logger.info('Escalation triggered', {
          orderId: order.id,
          action: 'timeout_escalation',
          notifyChannel: '#urgent-approvals'
        })
      }
    }
  }
  
  if (stuckCount > 0) {
    logger.info('Timeout detection complete', { 
      stuckCount,
      totalOrders: orders.length 
    })
  }
}
```

</Tab>
<Tab value='Python'>

```python title="src/detect_timeouts_step.py"
from datetime import datetime, timezone
import time

config = {
    "name": "DetectTimeouts",
    "description": "Find orders stuck awaiting approval and escalate",
    "triggers": [
        {"type": "cron", "expression": "0 */5 * * * * *"}
    ],
    "enqueues": [],
    "flows": ["order-approval"]
}

async def handler(context):
    orders = await context.state.list("orders")
    now = time.time() * 1000  # Convert to milliseconds
    timeout_ms = 10 * 60 * 1000  # 10 minutes (demo - use 24 hours in production)
    
    stuck_count = 0
    
    for order in orders:
        # Find orders stuck in awaiting_approval
        if order.get("status") == "awaiting_approval":
            last_update_str = order.get("updated_at") or order.get("created_at")
            last_update = datetime.fromisoformat(last_update_str.replace("Z", "+00:00"))
            last_update_ms = last_update.timestamp() * 1000
            age = now - last_update_ms
            
            if age > timeout_ms:
                stuck_count += 1
                
                context.logger.warn("Approval timeout detected", {
                    "orderId": order["id"],
                    "ageMinutes": round(age / (60 * 1000)),
                    "riskScore": order.get("risk_score"),
                    "total": order.get("total")
                })
                
                # Mark as timed out
                order["status"] = "timeout"
                order["timeout_at"] = datetime.now(timezone.utc).isoformat()
                order["timeout_reason"] = f"No approval within {round(timeout_ms / (60 * 1000))} min"
                await context.state.set("orders", order["id"], order)
                
                # Escalate
                context.logger.info("Escalation triggered", {
                    "orderId": order["id"],
                    "action": "timeout_escalation",
                    "notifyChannel": "#urgent-approvals"
                })
    
    if stuck_count > 0:
        context.logger.info("Timeout detection complete", {
            "stuckCount": stuck_count,
            "totalOrders": len(orders)
        })
```

</Tab>
<Tab value='JavaScript'>

```javascript title="src/detect-timeouts.step.js"
import { cron } from 'motia'

export const config = {
  name: 'DetectTimeouts',
  description: 'Find orders stuck awaiting approval and escalate',
  triggers: [
    cron('0 */5 * * * * *'),
  ],
  enqueues: [],
  flows: ['order-approval'],
}

export const handler = async ({ state, logger }) => {
  const orders = await state.list('orders')
  const now = Date.now()
  const timeoutMs = 10 * 60 * 1000  // 10 minutes (demo - use 24 hours in production)
  
  let stuckCount = 0
  
  for (const order of orders) {
    // Find orders stuck in awaiting_approval
    if (order.status === 'awaiting_approval') {
      const lastUpdate = new Date(order.updatedAt || order.createdAt).getTime()
      const age = now - lastUpdate
      
      if (age > timeoutMs) {
        stuckCount++
        
        logger.warn('Approval timeout detected', {
          orderId: order.id,
          ageMinutes: Math.round(age / (60 * 1000)),
          riskScore: order.riskScore,
          total: order.total
        })
        
        // Mark as timed out
        order.status = 'timeout'
        order.timeoutAt = new Date().toISOString()
        order.timeoutReason = `No approval within ${Math.round(timeoutMs / (60 * 1000))} min`
        await state.set('orders', order.id, order)
        
        // Escalate
        logger.info('Escalation triggered', {
          orderId: order.id,
          action: 'timeout_escalation',
          notifyChannel: '#urgent-approvals'
        })
      }
    }
  }
  
  if (stuckCount > 0) {
    logger.info('Timeout detection complete', { 
      stuckCount,
      totalOrders: orders.length 
    })
  }
}
```

</Tab>
</Tabs>

👉 **Why this matters:** Without timeout detection, orders could be stuck forever. This cron job acts as a safety net, ensuring no workflow is forgotten.

**Production actions:**
- 📧 Send escalation emails/Slack messages
- 🔄 Reassign to different approvers
- ⏰ Auto-reject after threshold
- 🎫 Create support tickets for investigation

---

## 🎨 Visual Flow in the iii Development Console

When you open the example in the iii development console, you'll see **5 nodes**:

![HTL Example](../img/htl-example.png)

1. **SubmitOrder** (green) - API entry point
2. **AnalyzeRisk** (blue) - Risk calculation and decision point
3. **HumanApprovalGate** (gray Noop) - ⏸️ **Pause indicator** showing where workflow stops
4. **ApprovalWebhook** (green) - Re-entry point for human decisions
5. **CompleteOrder** (blue) - Final fulfillment step

The **virtual connections** (dashed lines) show:
- `approval.required` → HumanApprovalGate
- `human.decision` → ApprovalWebhook

This visualizes exactly where external systems restart the flow. **Low-risk orders bypass the gate entirely** - they flow directly from AnalyzeRisk to CompleteOrder.

---

## Trying It Out

Ready to see it in action? Let's get the project running.

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/foundational/workflow-patterns/human-in-the-loop)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

<Steps>

### Install Dependencies

First, install the necessary npm packages.

```bash
npm install
```

### Run the Project

Start the Motia development server.

```bash
npm run dev
```

Open [`http://localhost:3000`](http://localhost:3000) in your browser to access the iii development console. You'll see the **HumanApprovalGate** (Noop node) showing where the workflow pauses for human decisions.

### Test High-Risk Order (Will Pause)

Submit an order with high value to trigger the approval gate:

```bash
curl -X POST http://localhost:3111/orders \
  -H "Content-Type: application/json" \
  -d '{
    "items": [{"name": "Expensive Item", "price": 500, "quantity": 3}],
    "customerEmail": "test@example.com",
    "total": 1500
  }'
```

**Response:**
```json
{
  "orderId": "abc-123",
  "status": "awaiting_approval"
}
```

**Check the iii development console:** The flow stops at HumanApprovalGate. No more steps run. The workflow is **paused** and waiting for human decision.

### Resume via Webhook (Hours/Days Later)

When you're ready (could be minutes, hours, or even days later), approve the order:

```bash
# User clicks "Approve" button in UI → Makes this call
curl -X POST http://localhost:3111/webhooks/orders/abc-123/approve \
  -H "Content-Type: application/json" \
  -d '{
    "approved": true,
    "approvedBy": "manager@company.com",
    "notes": "Verified customer identity"
  }'
```

**Check the iii development console:** Flow resumes! It loads state, enqueues `order.approved`, and CompleteOrder runs to fulfill the order.

### Test Low-Risk Order (Bypasses Gate)

Submit a low-value order that auto-approves:

```bash
curl -X POST http://localhost:3111/orders \
  -H "Content-Type: application/json" \
  -d '{
    "items": [{"name": "Widget", "price": 10, "quantity": 1}],
    "customerEmail": "test@example.com",
    "total": 10
  }'
```

**Check the iii development console:** Flows straight through SubmitOrder → AnalyzeRisk → CompleteOrder. The HumanApprovalGate is completely bypassed!

</Steps>

---

## State Management

Your state tracks the workflow position:

```typescript
{
  id: 'abc-123',
  status: 'awaiting_approval',      // What state we're in
  currentStep: 'awaiting_approval',  // Where we paused
  completedSteps: ['submitted', 'risk_analysis'],  // What's done
  
  // Business data
  items: [...],
  total: 1500,
  riskScore: 85,
  
  // Approval tracking
  approvedBy: null,      // Filled in by webhook
  approvedAt: null,
  
  // Timestamps
  createdAt: '2026-01-05T10:00:00Z',
  updatedAt: '2026-01-05T10:00:02Z',
}
```

When the webhook is called, it:
1. Loads this state
2. Verifies `currentStep === 'awaiting_approval'`
3. Updates with approval info
4. Enqueues to continue

---

## 💻 Dive into the Code

Want to explore the complete implementation? Check out the full source code and additional examples in our GitHub repository:

<div className="not-prose">
  <div className="bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-blue-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Explore More Examples</h3>
        <p className="text-gray-600 mb-4">Get hands-on with the complete source code, configuration files, and additional examples to accelerate your learning.</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/foundational/workflow-patterns/human-in-the-loop" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-blue-600 hover:bg-blue-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            View Human-in-the-Loop Example
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            More Examples →
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Summary

Building Human-in-the-Loop workflows in Motia:

1. **Save state when pausing** - Mark clearly with `status: 'awaiting_something'`
2. **Don't enqueue** - Workflow stops naturally
3. **Create webhook API** - This is your re-entry point
4. **Use virtual connections** - Show the pause visually in the iii development console with Noops
5. **External systems call webhook** - UI, Slack, etc. restart the flow
6. **Idempotent steps** - Always check `completedSteps` before doing work

Your workflow can pause for minutes, hours, or days. When the webhook is called, it loads state and continues exactly where it left off.

---

## Use Cases

This pattern works for:
- **Order approvals** - High-value or risky purchases
- **Content moderation** - Review before publishing
- **Document signing** - Wait for signatures
- **Deployment approvals** - Manager sign-off for production
- **Support escalations** - Human agent intervention
- **Compliance review** - Legal approval required




## Examples
[human-in-the-loop-workflows](/docs/examples/human-in-the-loop-workflows): Code example
---
title: Human-in-the-Loop Workflows
description: Build workflows that pause for human decisions and resume when ready
---

Some workflows need humans to make decisions.

Maybe it's approving a high-value order. Or reviewing content before publishing. Or signing off on a production deployment. These workflows need to **pause**, wait for a human decision, and **continue** when the decision arrives.

Motia handles this naturally. You save your progress, stop emitting events, and create an API webhook for the human to call. When they make their decision, the webhook picks up right where you left off.

## How It Works

Human-in-the-Loop workflows in Motia work like this:

1. **Process automatically when possible** - Let the system handle what it can
2. **Save "awaiting" state when human needed** - Mark the pause point clearly
3. **Stop enqueuing** - The workflow naturally pauses
4. **Webhook resumes the flow** - External systems call an API to continue

No special "pause" or "wait" commands. Just save state and use HTTP trigger steps as re-entry points.

---

## Key Ideas

| Concept | What It Means |
|---------|---------------|
| **Workflows don't sleep** | They don't "wait." They save state and stop processing. |
| **HTTP steps are re-entry points** | External systems call webhooks to restart the flow |
| **State checkpointing** | Every `state.set()` is a save point you can resume from |
| **Virtual connections** | Use `virtualSubscribes` and `virtualEnqueues` to show how webhooks fit in the flow visually |

<Callout type="info">
The workflow doesn't have a concept of time. It only knows: "Is the right state present? Has the right step been triggered?"
</Callout>

---

## Real Example: Order Approval

Let's build an order processing system that auto-approves low-risk orders but pauses for human review on high-risk ones.

**Example Location:** `examples/foundational/workflow-patterns/human-in-the-loop/`

[View on GitHub →](https://github.com/MotiaDev/motia-examples/tree/main/examples/foundational/workflow-patterns/human-in-the-loop)

### The Flow

![HTL Example](../img/htl-example.png)


### Step 1: Submit Order

An API receives the order and saves it immediately:

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript title="src/01-submit-order.step.ts"
import { type Handlers, type StepConfig } from 'motia'

export const config = {
  name: 'SubmitOrder',
  description: 'Submit an order for processing',
  triggers: [
    { type: 'http', path: '/orders', method: 'POST' },
  ],
  enqueues: ['order.submitted'],
  flows: ['order-approval'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (req, { state, enqueue, logger }) => {
  const orderId = crypto.randomUUID()
  
  const order = {
    id: orderId,
    items: req.body.items,
    total: req.body.total,
    status: 'pending_analysis',
    currentStep: 'submitted',
    completedSteps: ['submitted'],  // Track progress for idempotency
    createdAt: new Date().toISOString()
  }
  
  // Save immediately - this is our first checkpoint
  await state.set('orders', orderId, order)
  
  logger.info('Order submitted', { orderId })
  
  // Kick off risk analysis
  await enqueue({
    topic: 'order.submitted',
    data: { orderId }
  })

  return { status: 201, body: { orderId, status: order.status } }
}
```

</Tab>
<Tab value='Python'>

```python title="src/submit_order_step.py"
import uuid
from datetime import datetime

config = {
    "name": "SubmitOrder",
    "description": "Submit an order for processing",
    "triggers": [
        {"type": "http", "path": "/orders", "method": "POST"}
    ],
    "enqueues": ["order.submitted"],
    "flows": ["order-approval"]
}

async def handler(req, context):
    order_id = str(uuid.uuid4())
    
    # Access request body
    body = req.get("body", {})
    
    order = {
        "id": order_id,
        "items": body.get("items"),
        "total": body.get("total"),
        "status": "pending_analysis",
        "current_step": "submitted",
        "completed_steps": ["submitted"],
        "created_at": datetime.now().isoformat()
    }
    
    # Save immediately - first checkpoint
    await context.state.set("orders", order_id, order)
    
    context.logger.info("Order submitted", {"orderId": order_id})
    
    # Kick off risk analysis
    await context.enqueue({
        "topic": "order.submitted",
        "data": {"orderId": order_id}
    })

    return {"status": 201, "body": {"orderId": order_id, "status": order["status"]}}
```

</Tab>
<Tab value='JavaScript'>

```javascript title="src/submit-order.step.js"
import crypto from 'crypto'

export const config = {
  name: 'SubmitOrder',
  description: 'Submit an order for processing',
  triggers: [
    { type: 'http', path: '/orders', method: 'POST' },
  ],
  enqueues: ['order.submitted'],
  flows: ['order-approval'],
}

export const handler = async (req, { state, enqueue, logger }) => {
  const orderId = crypto.randomUUID()
  const { items, total } = req.body

  const order = {
    id: orderId,
    items,
    total,
    status: 'pending_analysis',
    currentStep: 'submitted',
    completedSteps: ['submitted'],
    createdAt: new Date().toISOString()
  }

  // Save immediately - first checkpoint
  await state.set('orders', orderId, order)

  logger.info('Order submitted', { orderId })

  await enqueue({
    topic: 'order.submitted',
    data: { orderId }
  })

  return { status: 201, body: { orderId, status: order.status } }
}
```

</Tab>
</Tabs>

👉 **Key point:** We save the order immediately with `currentStep` and `completedSteps`. This becomes our checkpoint system.

### Step 2: Analyze Risk

This step decides whether to auto-approve or pause for human review:

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript title="src/02-analyze-risk.step.ts"
import { type Handlers, type StepConfig } from 'motia'

export const config = {
  name: 'AnalyzeRisk',
  description: 'Analyze order risk and route accordingly',
  triggers: [
    { type: 'queue', topic: 'order.submitted' },
  ],
  enqueues: ['order.auto_approved'],
  virtualEnqueues: [{ topic: 'approval.required', label: 'Requires human approval' }],
  flows: ['order-approval'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (input, { state, enqueue, logger }) => {
  const { orderId } = input
  const order = await state.get('orders', orderId)
  
  // Skip if already analyzed (idempotency)
  if (order.completedSteps.includes('risk_analysis')) {
    return
  }
  
  // Calculate risk score
  const riskScore = calculateRiskScore(order)
  order.riskScore = riskScore
  order.completedSteps.push('risk_analysis')
  
  if (riskScore > 70) {
    // High risk - PAUSE for human approval
    order.status = 'awaiting_approval'
    order.currentStep = 'awaiting_approval'
    await state.set('orders', orderId, order)
    
    logger.warn('Order requires approval - workflow paused', { orderId, riskScore })
    
    // NO EMIT - workflow stops here
    // Webhook will restart it when human makes decision
    
  } else {
    // Low risk - bypass gate and auto-approve
    order.status = 'approved'
    order.approvedBy = 'system'
    order.completedSteps.push('approved')
    await state.set('orders', orderId, order)
    
    logger.info('Order auto-approved', { orderId, riskScore })
    
    // Continue immediately
    await enqueue({ topic: 'order.auto_approved', data: { orderId } })
  }
}

function calculateRiskScore(order: any): number {
  let score = 0
  if (order.total > 1000) score += 40
  else if (order.total > 500) score += 20
  
  const itemCount = order.items.reduce((sum, item) => sum + item.quantity, 0)
  if (itemCount > 10) score += 30
  
  score += Math.random() * 40
  return Math.min(Math.round(score), 100)
}
```

</Tab>
<Tab value='Python'>

```python title="src/analyze_risk_step.py"
import random

config = {
    "name": "AnalyzeRisk",
    "description": "Analyze order risk and route accordingly",
    "triggers": [
        {"type": "queue", "topic": "order.submitted"}
    ],
    "enqueues": ["order.auto_approved"],
    "virtualEnqueues": [{"topic": "approval.required", "label": "Requires human approval"}],
    "flows": ["order-approval"]
}

async def handler(input_data, context):
    order_id = input_data.get("orderId")
    order = await context.state.get("orders", order_id)
    
    # Skip if already analyzed
    if "risk_analysis" in order.get("completed_steps", []):
        return
    
    # Calculate risk
    risk_score = calculate_risk_score(order)
    order["risk_score"] = risk_score
    order["completed_steps"].append("risk_analysis")
    
    if risk_score > 70:
        # High risk - PAUSE
        order["status"] = "awaiting_approval"
        order["current_step"] = "awaiting_approval"
        await context.state.set("orders", order_id, order)
        
        context.logger.warn("Order requires approval - workflow paused", 
                           {"orderId": order_id, "riskScore": risk_score})
        # NO EMIT - workflow stops
        
    else:
        # Low risk - bypass gate
        order["status"] = "approved"
        order["approved_by"] = "system"
        order["completed_steps"].append("approved")
        await context.state.set("orders", order_id, order)
        
        context.logger.info("Order auto-approved", 
                           {"orderId": order_id, "riskScore": risk_score})
        
        await context.enqueue({
            "topic": "order.auto_approved",
            "data": {"orderId": order_id}
        })

def calculate_risk_score(order):
    score = 0
    total = order.get("total", 0)
    if total > 1000:
        score += 40
    elif total > 500:
        score += 20
    
    items = order.get("items", [])
    item_count = sum(item.get("quantity", 0) for item in items)
    if item_count > 10:
        score += 30
    
    score += random.random() * 40
    return min(round(score), 100)
```

</Tab>
<Tab value='JavaScript'>

```javascript title="src/analyze-risk.step.js"
export const config = {
  name: 'AnalyzeRisk',
  description: 'Analyze order risk and route accordingly',
  triggers: [
    { type: 'queue', topic: 'order.submitted' },
  ],
  enqueues: ['order.auto_approved'],
  virtualEnqueues: [{ topic: 'approval.required', label: 'Requires human approval' }],
  flows: ['order-approval'],
}

export const handler = async (input, { state, enqueue, logger }) => {
  const { orderId } = input
  const order = await state.get('orders', orderId)
  
  // Skip if already analyzed (idempotency)
  if (order.completedSteps.includes('risk_analysis')) {
    return
  }
  
  const riskScore = calculateRiskScore(order)
  order.riskScore = riskScore
  order.completedSteps.push('risk_analysis')
  
  if (riskScore > 70) {
    // High risk - PAUSE
    order.status = 'awaiting_approval'
    order.currentStep = 'awaiting_approval'
    await state.set('orders', orderId, order)
    
    logger.warn('Order requires approval - workflow paused', { orderId, riskScore })
    // NO EMIT - workflow stops here
    
  } else {
    // Low risk - bypass gate
    order.status = 'approved'
    order.approvedBy = 'system'
    order.completedSteps.push('approved')
    await state.set('orders', orderId, order)
    
    logger.info('Order auto-approved', { orderId, riskScore })
    await enqueue({ topic: 'order.auto_approved', data: { orderId } })
  }
}

function calculateRiskScore(order) {
  let score = 0
  if (order.total > 1000) score += 40
  else if (order.total > 500) score += 20
  
  const itemCount = order.items.reduce((sum, item) => sum + item.quantity, 0)
  if (itemCount > 10) score += 30
  
  score += Math.random() * 40
  return Math.min(Math.round(score), 100)
}
```

</Tab>
</Tabs>

👉 **The key decision:**
- **High risk:** Save "awaiting" state and **don't enqueue** → workflow stops
- **Low risk:** Emit immediately → workflow continues

### Step 3: Human Approval Gate (Visual Noop)

This creates a visual node in the iii development console showing where the workflow pauses:

```typescript title="src/03-human-approval-gate.step.ts"
import type { NoopConfig } from 'motia'

export const config: NoopConfig = {
  type: 'noop',
  name: 'HumanApprovalGate',
  description: 'Workflow pauses here - awaiting human decision via webhook',
  flows: ['order-approval'],
  
  // Receives signal that approval is needed
  virtualSubscribes: ['approval.required'],
  
  // Shows connection to webhook that continues flow
  virtualEnqueues: ['human.decision'],
}
```
👉 **In the iii development console:** This Noop appears between AnalyzeRisk and ApprovalWebhook.


### Step 4: Approval Webhook (Re-Entry Point)

External systems (UI, Slack, etc.) call this webhook to provide the human decision:

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript title="src/04-approval-webhook.step.ts"
import { type Handlers, type StepConfig } from 'motia'

export const config = {
  name: 'ApprovalWebhook',
  description: 'Webhook for human approval decisions',
  triggers: [
    { type: 'http', path: '/webhooks/orders/:orderId/approve', method: 'POST' },
  ],
  enqueues: ['order.approved'],
  virtualSubscribes: ['human.decision'],
  flows: ['order-approval'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (req, { state, enqueue, logger }) => {
  const { orderId } = req.pathParams
  const { approved, approvedBy, notes } = req.body
  
  // Load the checkpoint
  const order = await state.get('orders', orderId)
  
  if (!order) {
    return { status: 404, body: { error: 'Order not found' } }
  }
  
  // Verify we're at the right pause point
  if (order.currentStep !== 'awaiting_approval') {
    return { status: 400, body: { error: 'Order not awaiting approval' } }
  }
  
  if (approved) {
    // Apply decision
    order.status = 'approved'
    order.approvedBy = approvedBy
    order.approvedAt = new Date().toISOString()
    order.completedSteps.push('approved')
    await state.set('orders', orderId, order)
    
    logger.info('Order approved - resuming workflow', { orderId, approvedBy })
    
    // Resume the workflow
    await enqueue({ topic: 'order.approved', data: { orderId } })

    return { status: 200, body: { success: true, message: 'Order approved' } }
  } else {
    // Rejected - workflow ends
    order.status = 'rejected'
    order.rejectedBy = approvedBy
    order.rejectionReason = notes
    await state.set('orders', orderId, order)
    
    logger.info('Order rejected - workflow ends', { orderId })
    return { status: 200, body: { success: true, message: 'Order rejected' } }
  }
}
```

</Tab>
<Tab value='Python'>

```python title="src/approval_webhook_step.py"
from datetime import datetime

config = {
    "name": "ApprovalWebhook",
    "description": "Webhook for human approval decisions",
    "triggers": [
        {"type": "http", "path": "/webhooks/orders/:orderId/approve", "method": "POST"}
    ],
    "enqueues": ["order.approved"],
    "virtualSubscribes": ["human.decision"],
    "flows": ["order-approval"]
}

async def handler(req, context):
    # Access path params and body
    path_params = req.get("pathParams", {})
    body = req.get("body", {})
    
    order_id = path_params.get("orderId")
    approved = body.get("approved")
    approved_by = body.get("approvedBy")
    notes = body.get("notes")
    
    # Load checkpoint
    order = await context.state.get("orders", order_id)
    
    if not order:
        return {"status": 404, "body": {"error": "Order not found"}}
    
    # Verify pause point
    if order["current_step"] != "awaiting_approval":
        return {"status": 400, "body": {"error": "Not awaiting approval"}}
    
    if approved:
        # Resume workflow
        order["status"] = "approved"
        order["approved_by"] = approved_by
        order["approved_at"] = datetime.now().isoformat()
        order["completed_steps"].append("approved")
        await context.state.set("orders", order_id, order)
        
        context.logger.info("Order approved - resuming workflow", 
                           {"orderId": order_id, "approvedBy": approved_by})
        
        await context.enqueue({
            "topic": "order.approved",
            "data": {"orderId": order_id}
        })
        
        return {"status": 200, "body": {"success": True}}
    else:
        # Rejected - end workflow
        order["status"] = "rejected"
        order["rejected_by"] = approved_by
        await context.state.set("orders", order_id, order)
        
        return {"status": 200, "body": {"success": True}}
```

</Tab>
<Tab value='JavaScript'>

```javascript title="src/approval-webhook.step.js"
export const config = {
  name: 'ApprovalWebhook',
  description: 'Webhook for human approval decisions',
  triggers: [
    { type: 'http', path: '/webhooks/orders/:orderId/approve', method: 'POST' },
  ],
  enqueues: ['order.approved'],
  virtualSubscribes: ['human.decision'],
  flows: ['order-approval'],
}

export const handler = async (req, { state, enqueue, logger }) => {
  const { orderId } = req.pathParams
  const { approved, approvedBy, notes } = req.body
  
  // Load checkpoint
  const order = await state.get('orders', orderId)
  
  if (!order) {
    return { status: 404, body: { error: 'Order not found' } }
  }
  
  // Verify pause point
  if (order.currentStep !== 'awaiting_approval') {
    return { status: 400, body: { error: 'Not awaiting approval' } }
  }
  
  if (approved) {
    // Resume workflow
    order.status = 'approved'
    order.approvedBy = approvedBy
    order.approvedAt = new Date().toISOString()
    order.completedSteps.push('approved')
    await state.set('orders', orderId, order)
    
    logger.info('Order approved - resuming', { orderId, approvedBy })
    
    await enqueue({ topic: 'order.approved', data: { orderId } })
    return { status: 200, body: { success: true } }
  } else {
    // Rejected - end workflow
    order.status = 'rejected'
    order.rejectedBy = approvedBy
    await state.set('orders', orderId, order)

    logger.info('Order rejected', { orderId })
    return { status: 200, body: { success: true } }
  }
}
```

</Tab>
</Tabs>

👉 **The pattern:** Load checkpoint → Verify state → Apply decision → Resume or end

### Step 5: Complete Order

Final step that runs after approval:

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript title="src/05-complete-order.step.ts"
import { type Handlers, type StepConfig } from 'motia'

export const config = {
  name: 'CompleteOrder',
  description: 'Complete an approved order',
  triggers: [
    { type: 'queue', topic: 'order.approved' },
    { type: 'queue', topic: 'order.auto_approved' },
  ],
  enqueues: [],
  flows: ['order-approval'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (input, { state, logger }) => {
  const { orderId } = input
  const order = await state.get('orders', orderId)
  
  // Skip if already completed (idempotency)
  if (order.completedSteps.includes('completed')) {
    return
  }
  
  // Process fulfillment
  await simulateFulfillment(order)
  
  order.status = 'completed'
  order.completedAt = new Date().toISOString()
  order.completedSteps.push('completed')
  await state.set('orders', orderId, order)
  
  logger.info('Order completed', { orderId, approvedBy: order.approvedBy })
}

async function simulateFulfillment(order: any) {
  // In production: charge payment, create shipment, send email
  await new Promise(resolve => setTimeout(resolve, 1000))
}
```

</Tab>
<Tab value='Python'>

```python title="src/complete_order_step.py"
import asyncio

config = {
    "name": "CompleteOrder",
    "description": "Complete an approved order",
    "triggers": [
        {"type": "queue", "topic": "order.approved"},
        {"type": "queue", "topic": "order.auto_approved"}
    ],
    "enqueues": [],
    "flows": ["order-approval"]
}

async def handler(input_data, context):
    order_id = input_data.get("orderId")
    order = await context.state.get("orders", order_id)
    
    # Skip if already completed (idempotency)
    if "completed" in order.get("completed_steps", []):
        return
    
    # Fulfill order
    await asyncio.sleep(1)
    
    order["status"] = "completed"
    order["completed_steps"].append("completed")
    await context.state.set("orders", order_id, order)
    
    context.logger.info("Order completed", {"orderId": order_id})
```

</Tab>
<Tab value='JavaScript'>

```javascript title="src/complete-order.step.js"
export const config = {
  name: 'CompleteOrder',
  description: 'Complete an approved order',
  triggers: [
    { type: 'queue', topic: 'order.approved' },
    { type: 'queue', topic: 'order.auto_approved' },
  ],
  enqueues: [],
  flows: ['order-approval'],
}

export const handler = async (input, { state, logger }) => {
  const { orderId } = input
  const order = await state.get('orders', orderId)
  
  // Skip if already completed (idempotency)
  if (order.completedSteps.includes('completed')) {
    return
  }
  
  // Fulfill order
  await new Promise(resolve => setTimeout(resolve, 1000))
  
  order.status = 'completed'
  order.completedSteps.push('completed')
  await state.set('orders', orderId, order)
  
  logger.info('Order completed', { orderId, approvedBy: order.approvedBy })
}
```

</Tab>
</Tabs>

---

## Recovery Pattern: Timeout Detection

What happens if a human never responds? In production, you need a safety mechanism to detect and escalate stuck workflows.

### Step 6: Timeout Detection (Cron)

A scheduled job periodically scans for orders stuck in approval:

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript title="src/06-detect-timeouts.step.ts"
import { type Handlers, type StepConfig, cron } from 'motia'

export const config = {
  name: 'DetectTimeouts',
  description: 'Find orders stuck awaiting approval and escalate',
  triggers: [
    cron('0 */5 * * * * *'),
  ],
  enqueues: [],
  flows: ['order-approval'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async ({ state, logger }) => {
  const orders = await state.list('orders')
  const now = Date.now()
  const timeoutMs = 10 * 60 * 1000  // 10 minutes (demo - use 24 hours in production)
  
  let stuckCount = 0
  
  for (const order of orders) {
    // Find orders stuck in awaiting_approval
    if (order.status === 'awaiting_approval') {
      const lastUpdate = new Date(order.updatedAt || order.createdAt).getTime()
      const age = now - lastUpdate
      
      if (age > timeoutMs) {
        stuckCount++
        
        logger.warn('Approval timeout detected', {
          orderId: order.id,
          ageMinutes: Math.round(age / (60 * 1000)),
          riskScore: order.riskScore,
          total: order.total
        })
        
        // Mark as timed out
        order.status = 'timeout'
        order.timeoutAt = new Date().toISOString()
        order.timeoutReason = `No approval within ${Math.round(timeoutMs / (60 * 1000))} min`
        await state.set('orders', order.id, order)
        
        // In production, take action:
        // 1. Send escalation notification (Slack, email)
        // 2. Auto-reject if too old
        // 3. Assign to different manager
        // 4. Create support ticket
        
        logger.info('Escalation triggered', {
          orderId: order.id,
          action: 'timeout_escalation',
          notifyChannel: '#urgent-approvals'
        })
      }
    }
  }
  
  if (stuckCount > 0) {
    logger.info('Timeout detection complete', { 
      stuckCount,
      totalOrders: orders.length 
    })
  }
}
```

</Tab>
<Tab value='Python'>

```python title="src/detect_timeouts_step.py"
from datetime import datetime, timezone
import time

config = {
    "name": "DetectTimeouts",
    "description": "Find orders stuck awaiting approval and escalate",
    "triggers": [
        {"type": "cron", "expression": "0 */5 * * * * *"}
    ],
    "enqueues": [],
    "flows": ["order-approval"]
}

async def handler(context):
    orders = await context.state.list("orders")
    now = time.time() * 1000  # Convert to milliseconds
    timeout_ms = 10 * 60 * 1000  # 10 minutes (demo - use 24 hours in production)
    
    stuck_count = 0
    
    for order in orders:
        # Find orders stuck in awaiting_approval
        if order.get("status") == "awaiting_approval":
            last_update_str = order.get("updated_at") or order.get("created_at")
            last_update = datetime.fromisoformat(last_update_str.replace("Z", "+00:00"))
            last_update_ms = last_update.timestamp() * 1000
            age = now - last_update_ms
            
            if age > timeout_ms:
                stuck_count += 1
                
                context.logger.warn("Approval timeout detected", {
                    "orderId": order["id"],
                    "ageMinutes": round(age / (60 * 1000)),
                    "riskScore": order.get("risk_score"),
                    "total": order.get("total")
                })
                
                # Mark as timed out
                order["status"] = "timeout"
                order["timeout_at"] = datetime.now(timezone.utc).isoformat()
                order["timeout_reason"] = f"No approval within {round(timeout_ms / (60 * 1000))} min"
                await context.state.set("orders", order["id"], order)
                
                # Escalate
                context.logger.info("Escalation triggered", {
                    "orderId": order["id"],
                    "action": "timeout_escalation",
                    "notifyChannel": "#urgent-approvals"
                })
    
    if stuck_count > 0:
        context.logger.info("Timeout detection complete", {
            "stuckCount": stuck_count,
            "totalOrders": len(orders)
        })
```

</Tab>
<Tab value='JavaScript'>

```javascript title="src/detect-timeouts.step.js"
import { cron } from 'motia'

export const config = {
  name: 'DetectTimeouts',
  description: 'Find orders stuck awaiting approval and escalate',
  triggers: [
    cron('0 */5 * * * * *'),
  ],
  enqueues: [],
  flows: ['order-approval'],
}

export const handler = async ({ state, logger }) => {
  const orders = await state.list('orders')
  const now = Date.now()
  const timeoutMs = 10 * 60 * 1000  // 10 minutes (demo - use 24 hours in production)
  
  let stuckCount = 0
  
  for (const order of orders) {
    // Find orders stuck in awaiting_approval
    if (order.status === 'awaiting_approval') {
      const lastUpdate = new Date(order.updatedAt || order.createdAt).getTime()
      const age = now - lastUpdate
      
      if (age > timeoutMs) {
        stuckCount++
        
        logger.warn('Approval timeout detected', {
          orderId: order.id,
          ageMinutes: Math.round(age / (60 * 1000)),
          riskScore: order.riskScore,
          total: order.total
        })
        
        // Mark as timed out
        order.status = 'timeout'
        order.timeoutAt = new Date().toISOString()
        order.timeoutReason = `No approval within ${Math.round(timeoutMs / (60 * 1000))} min`
        await state.set('orders', order.id, order)
        
        // Escalate
        logger.info('Escalation triggered', {
          orderId: order.id,
          action: 'timeout_escalation',
          notifyChannel: '#urgent-approvals'
        })
      }
    }
  }
  
  if (stuckCount > 0) {
    logger.info('Timeout detection complete', { 
      stuckCount,
      totalOrders: orders.length 
    })
  }
}
```

</Tab>
</Tabs>

👉 **Why this matters:** Without timeout detection, orders could be stuck forever. This cron job acts as a safety net, ensuring no workflow is forgotten.

**Production actions:**
- 📧 Send escalation emails/Slack messages
- 🔄 Reassign to different approvers
- ⏰ Auto-reject after threshold
- 🎫 Create support tickets for investigation

---

## 🎨 Visual Flow in the iii Development Console

When you open the example in the iii development console, you'll see **5 nodes**:

![HTL Example](../img/htl-example.png)

1. **SubmitOrder** (green) - API entry point
2. **AnalyzeRisk** (blue) - Risk calculation and decision point
3. **HumanApprovalGate** (gray Noop) - ⏸️ **Pause indicator** showing where workflow stops
4. **ApprovalWebhook** (green) - Re-entry point for human decisions
5. **CompleteOrder** (blue) - Final fulfillment step

The **virtual connections** (dashed lines) show:
- `approval.required` → HumanApprovalGate
- `human.decision` → ApprovalWebhook

This visualizes exactly where external systems restart the flow. **Low-risk orders bypass the gate entirely** - they flow directly from AnalyzeRisk to CompleteOrder.

---

## Trying It Out

Ready to see it in action? Let's get the project running.

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/foundational/workflow-patterns/human-in-the-loop)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

<Steps>

### Install Dependencies

First, install the necessary npm packages.

```bash
npm install
```

### Run the Project

Start the Motia development server.

```bash
npm run dev
```

Open [`http://localhost:3000`](http://localhost:3000) in your browser to access the iii development console. You'll see the **HumanApprovalGate** (Noop node) showing where the workflow pauses for human decisions.

### Test High-Risk Order (Will Pause)

Submit an order with high value to trigger the approval gate:

```bash
curl -X POST http://localhost:3111/orders \
  -H "Content-Type: application/json" \
  -d '{
    "items": [{"name": "Expensive Item", "price": 500, "quantity": 3}],
    "customerEmail": "test@example.com",
    "total": 1500
  }'
```

**Response:**
```json
{
  "orderId": "abc-123",
  "status": "awaiting_approval"
}
```

**Check the iii development console:** The flow stops at HumanApprovalGate. No more steps run. The workflow is **paused** and waiting for human decision.

### Resume via Webhook (Hours/Days Later)

When you're ready (could be minutes, hours, or even days later), approve the order:

```bash
# User clicks "Approve" button in UI → Makes this call
curl -X POST http://localhost:3111/webhooks/orders/abc-123/approve \
  -H "Content-Type: application/json" \
  -d '{
    "approved": true,
    "approvedBy": "manager@company.com",
    "notes": "Verified customer identity"
  }'
```

**Check the iii development console:** Flow resumes! It loads state, enqueues `order.approved`, and CompleteOrder runs to fulfill the order.

### Test Low-Risk Order (Bypasses Gate)

Submit a low-value order that auto-approves:

```bash
curl -X POST http://localhost:3111/orders \
  -H "Content-Type: application/json" \
  -d '{
    "items": [{"name": "Widget", "price": 10, "quantity": 1}],
    "customerEmail": "test@example.com",
    "total": 10
  }'
```

**Check the iii development console:** Flows straight through SubmitOrder → AnalyzeRisk → CompleteOrder. The HumanApprovalGate is completely bypassed!

</Steps>

---

## State Management

Your state tracks the workflow position:

```typescript
{
  id: 'abc-123',
  status: 'awaiting_approval',      // What state we're in
  currentStep: 'awaiting_approval',  // Where we paused
  completedSteps: ['submitted', 'risk_analysis'],  // What's done
  
  // Business data
  items: [...],
  total: 1500,
  riskScore: 85,
  
  // Approval tracking
  approvedBy: null,      // Filled in by webhook
  approvedAt: null,
  
  // Timestamps
  createdAt: '2026-01-05T10:00:00Z',
  updatedAt: '2026-01-05T10:00:02Z',
}
```

When the webhook is called, it:
1. Loads this state
2. Verifies `currentStep === 'awaiting_approval'`
3. Updates with approval info
4. Enqueues to continue

---

## 💻 Dive into the Code

Want to explore the complete implementation? Check out the full source code and additional examples in our GitHub repository:

<div className="not-prose">
  <div className="bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-blue-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Explore More Examples</h3>
        <p className="text-gray-600 mb-4">Get hands-on with the complete source code, configuration files, and additional examples to accelerate your learning.</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/foundational/workflow-patterns/human-in-the-loop" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-blue-600 hover:bg-blue-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            View Human-in-the-Loop Example
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            More Examples →
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Summary

Building Human-in-the-Loop workflows in Motia:

1. **Save state when pausing** - Mark clearly with `status: 'awaiting_something'`
2. **Don't enqueue** - Workflow stops naturally
3. **Create webhook API** - This is your re-entry point
4. **Use virtual connections** - Show the pause visually in the iii development console with Noops
5. **External systems call webhook** - UI, Slack, etc. restart the flow
6. **Idempotent steps** - Always check `completedSteps` before doing work

Your workflow can pause for minutes, hours, or days. When the webhook is called, it loads state and continues exactly where it left off.

---

## Use Cases

This pattern works for:
- **Order approvals** - High-value or risky purchases
- **Content moderation** - Review before publishing
- **Document signing** - Wait for signatures
- **Deployment approvals** - Manager sign-off for production
- **Support escalations** - Human agent intervention
- **Compliance review** - Legal approval required



-   [Examples](/docs/examples): Documentation for Examples.
---
title: Examples
---

We have curated examples to help you learn Motia, organized by complexity from basic concepts to production-ready implementations.

## 📚 Basic Examples
Start here to learn core Motia concepts with straightforward implementations.

<Cards>
  <Card
    title="Sentiment Analysis"
    href="/docs/examples/sentiment-analysis"
    description="Learn dynamic workflows with LLM-driven decision making and event routing"
  />
  <Card
    title="Multi-Language Processing"
    href="/docs/examples/multi-language-data-processing"
    description="Combine TypeScript, Python, and JavaScript in unified data pipelines"
  />
</Cards>

## 🔧 Intermediate Examples
Build more complex workflows with integrations and advanced patterns.

<Cards>
  <Card
    title="AI Content Moderation"
    href="/docs/examples/ai-content-moderation"
    description="Human-in-the-loop content moderation with AI analysis and Slack integration"
  />
  <Card
    title="RAG PDF Analyzer"
    href="/docs/examples/rag-docling-weaviate"
    description="Intelligent document processing with Docling and Weaviate vector database"
  />
  <Card
    title="Trello Automation"
    href="/docs/examples/trello-automation"
    description="Automated card progression system with AI-powered summaries and notifications"
  />
</Cards>

## 🏭 Production Examples
Enterprise-ready implementations handling real traffic at scale.

<Cards>
  <Card
    title="Uptime Monitor"
    href="/docs/examples/uptime-discord-monitor"
    description="Complete monitoring system with smart alerting and Discord integration"
  />
  <Card
    title="GitHub Stars Counter"
    href="/docs/examples/github-stars-counter"
    description="Real-time stars counter with secure webhooks and live streaming"
  />
  <Card
    title="GitHub Integration"
    href="/docs/examples/github-integration-workflow"
    description="Automated issue and PR management with AI-powered classification and routing"
  />
  <Card
    title="Gmail Automation"
    href="/docs/examples/gmail-automation"
    description="Smart email classification, auto-responses, and AI-powered filtering with OAuth2"
  />
  <Card
    title="Finance Agent"
    href="/docs/examples/finance-agent"
    description="Event-driven financial analysis with web search and real-time market data"
  />
  <Card
    title="AI Research Agent"
    href="/docs/examples/ai-deep-research-agent"
    description="Comprehensive web research assistant with iterative depth and parallel processing"
  />
</Cards>


<br/>

## 💻 Explore the Source Code

All examples include complete, runnable source code with configuration files, setup instructions, and production-ready implementations:

<div className="not-prose">
  <div className="bg-gradient-to-r from-indigo-50 to-purple-50 border border-indigo-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-indigo-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Motia Examples Repository</h3>
        <p className="text-gray-600 mb-4">Access complete implementations, step-by-step tutorials, and production-ready configurations for all our examples. Perfect for learning, experimentation, and building your own applications.</p>
        <div className="grid grid-cols-1 sm:grid-cols-3 gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center justify-center px-4 py-2 bg-indigo-600 hover:bg-indigo-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            Repository
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/rag-and-search/rag-fundamentals/rag-docling-weaviate-agent" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center justify-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            RAG Example →
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/foundational/infrastructure/motia-uptime-monitor" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center justify-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            Monitor Example →
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

## Contribute

We welcome contributions to the examples. Please submit a PR to the [examples repository](https://github.com/motiadev/motia-examples).



## Examples
[Examples](/docs/examples): Code example
---
title: Examples
---

We have curated examples to help you learn Motia, organized by complexity from basic concepts to production-ready implementations.

## 📚 Basic Examples
Start here to learn core Motia concepts with straightforward implementations.

<Cards>
  <Card
    title="Sentiment Analysis"
    href="/docs/examples/sentiment-analysis"
    description="Learn dynamic workflows with LLM-driven decision making and event routing"
  />
  <Card
    title="Multi-Language Processing"
    href="/docs/examples/multi-language-data-processing"
    description="Combine TypeScript, Python, and JavaScript in unified data pipelines"
  />
</Cards>

## 🔧 Intermediate Examples
Build more complex workflows with integrations and advanced patterns.

<Cards>
  <Card
    title="AI Content Moderation"
    href="/docs/examples/ai-content-moderation"
    description="Human-in-the-loop content moderation with AI analysis and Slack integration"
  />
  <Card
    title="RAG PDF Analyzer"
    href="/docs/examples/rag-docling-weaviate"
    description="Intelligent document processing with Docling and Weaviate vector database"
  />
  <Card
    title="Trello Automation"
    href="/docs/examples/trello-automation"
    description="Automated card progression system with AI-powered summaries and notifications"
  />
</Cards>

## 🏭 Production Examples
Enterprise-ready implementations handling real traffic at scale.

<Cards>
  <Card
    title="Uptime Monitor"
    href="/docs/examples/uptime-discord-monitor"
    description="Complete monitoring system with smart alerting and Discord integration"
  />
  <Card
    title="GitHub Stars Counter"
    href="/docs/examples/github-stars-counter"
    description="Real-time stars counter with secure webhooks and live streaming"
  />
  <Card
    title="GitHub Integration"
    href="/docs/examples/github-integration-workflow"
    description="Automated issue and PR management with AI-powered classification and routing"
  />
  <Card
    title="Gmail Automation"
    href="/docs/examples/gmail-automation"
    description="Smart email classification, auto-responses, and AI-powered filtering with OAuth2"
  />
  <Card
    title="Finance Agent"
    href="/docs/examples/finance-agent"
    description="Event-driven financial analysis with web search and real-time market data"
  />
  <Card
    title="AI Research Agent"
    href="/docs/examples/ai-deep-research-agent"
    description="Comprehensive web research assistant with iterative depth and parallel processing"
  />
</Cards>


<br/>

## 💻 Explore the Source Code

All examples include complete, runnable source code with configuration files, setup instructions, and production-ready implementations:

<div className="not-prose">
  <div className="bg-gradient-to-r from-indigo-50 to-purple-50 border border-indigo-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-indigo-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Motia Examples Repository</h3>
        <p className="text-gray-600 mb-4">Access complete implementations, step-by-step tutorials, and production-ready configurations for all our examples. Perfect for learning, experimentation, and building your own applications.</p>
        <div className="grid grid-cols-1 sm:grid-cols-3 gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center justify-center px-4 py-2 bg-indigo-600 hover:bg-indigo-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            Repository
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/rag-and-search/rag-fundamentals/rag-docling-weaviate-agent" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center justify-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            RAG Example →
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/foundational/infrastructure/motia-uptime-monitor" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center justify-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            Monitor Example →
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

## Contribute

We welcome contributions to the examples. Please submit a PR to the [examples repository](https://github.com/motiadev/motia-examples).


-   [multi-language-data-processing](/docs/examples/multi-language-data-processing): Documentation for multi-language-data-processing.
---
title: 'Multi-Language Processing'
description: 'Multi-Language Data Processing: Building a Unified Pipeline with Motia'
---

Modern backend development often requires combining the strengths of different programming languages. TypeScript for APIs, Python for data processing and AI, JavaScript for rapid prototyping. Traditional approaches involve complex microservices architectures with intricate communication patterns.

This comprehensive guide explores how to build a unified multi-language data processing pipeline using Motia's **step** primitive. We'll cover:

1. **Steps as Core Primitive**: How steps unify different languages under a single abstraction.
2. **Building the Pipeline**: A step-by-step guide to creating a cohesive multi-language data processing workflow.
3. **Unified Execution Model**: How steps enable seamless communication between different runtime environments.
4. **Hands-On Development**: How to build, run, and observe your unified multi-language pipeline.

Let's build a production-ready data processing system where steps unify TypeScript, Python, and JavaScript into a single cohesive workflow.

---

## Workflow Overview

<div className="my-8">![Multi-Language Data Processing](/docs-images/motia-build-your-app-2.gif)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/multi-language-data-processing)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## The Power of Steps: A Unified Multi-Language Primitive

At its core, our data processing pipeline demonstrates how **steps** solve the fundamental challenge of multi-language systems: unifying different programming languages under a single, coherent abstraction. Traditional polyglot architectures require complex inter-process communication and deployment coordination. Motia's **step** primitive unifies everything.

**Steps enable true language unification:**

- **[TypeScript](https://www.typescriptlang.org/)** steps: Strong typing and excellent tooling for APIs and orchestration
- **[Python](https://www.python.org/)** steps: Rich ecosystem for data processing, ML, and scientific computing  
- **[JavaScript](https://developer.mozilla.org/en-US/docs/Web/JavaScript)** steps: Dynamic processing and rapid development
- **[Motia's Step Primitive](https://motia.dev)**: The unifying abstraction that makes all languages work as a single system

Instead of managing multiple services, **steps** provide a single programming model. Whether written in TypeScript, Python, or JavaScript, every step follows the same pattern: receive data, process it, enqueue events. This unification is what makes multi-language development straightforward.

---

## The Anatomy of Our Multi-Language Pipeline

Our application consists of six specialized steps, each leveraging the optimal language for its specific task. Let's explore the complete architecture.

<Folder name="steps" defaultOpen>
  <File name="01-starter.step.ts" />
  <File name="02-bridge.step.ts" />
  <File name="simple-python_step.py" />
  <File name="notify.step.ts" />
  <File name="04-final.step.ts" />
  <File name="05-summary.step.js" />
</Folder>

<Folder name="types" defaultOpen>
  <File name="index.ts" />
</Folder>

<Tabs items={['api-starter', 'bridge-step', 'python-processor', 'notification-handler', 'finalizer', 'summary-generator']}>
  <Tab value="api-starter">
    The entry point for our multi-language workflow. This TypeScript API endpoint receives data, validates it with Zod schemas, and kicks off the processing pipeline.

```typescript
import { type StepConfig } from 'motia'
import { z } from 'zod'

const bodySchema = z.object({
  data: z.record(z.unknown()).optional(),
  message: z.string().optional()
})

// API endpoint to start the multi-language pipeline
export const config = {
  name: 'AppStarter',
  description: 'Start the multi-language app pipeline',
  triggers: [
    { type: 'http', method: 'POST', path: '/start-app', bodySchema },
  ],
  responseSchema: {
    200: z.object({
      message: z.string(),
      appId: z.number(),
      traceId: z.string()
    })
  },
  enqueues: ['app.started'],
  flows: ['data-processing'],
} as const satisfies StepConfig

export const handler = async (req: any, { logger, enqueue, traceId }: any) => {
  logger.info('🚀 Starting multi-language app', { body: req.body, traceId })
  
  const appData = {
    id: Date.now(),
    input: req.body.data || {},
    started_at: new Date().toISOString(),
    traceId
  }

  // Enqueue to next step
  await enqueue({
    topic: 'app.started',
    data: appData
  })

  logger.info('✅ App started successfully', { 
    appId: appData.id,
    traceId 
  })

  return {
    status: 200,
    body: {
      message: 'Multi-language app started successfully',
      appId: appData.id,
      traceId
    }
  }
}
```

  </Tab>
  <Tab value="bridge-step">
    A TypeScript bridge that receives the app start event, processes the data, and forwards it to the Python processing step with proper type transformation.

```typescript
import { type StepConfig } from 'motia'
import { z } from 'zod'

// Bridge step to connect app starter to Python processing
export const config = {
  name: 'AppBridge',
  description: 'Bridge between app start and Python processing',
  triggers: [
    { type: 'queue', topic: 'app.started', input: z.object({
      id: z.number(),
      input: z.record(z.unknown()),
      started_at: z.string(),
      traceId: z.string()
    }) },
  ],
  enqueues: ['data.processed'],
  flows: ['data-processing'],
} as const satisfies StepConfig

export const handler = async (input: any, { logger, enqueue }: any) => {
  logger.info('🌉 Processing app data and sending to Python', { appId: input.id })
  
  // Process data for Python step
  const processedResult = {
    original_id: input.id,
    processed_at: input.started_at,
    result: `Processed: ${JSON.stringify(input.input)}`,
    confidence: 0.95,
    model_version: '1.0'
  }

  // Send to Python processing
  await enqueue({
    topic: 'data.processed',
    data: processedResult
  })

  logger.info('✅ Data sent to Python processing', { 
    originalId: input.id
  })
}
```

  </Tab>
  <Tab value="python-processor">
    The core data processor written in Python, demonstrating how Python steps integrate seamlessly with the TypeScript workflow while maintaining access to Python's rich ecosystem. Note the `_step.py` naming convention.

```python
import time
from datetime import datetime

# Python processing step configuration
config = {
    "name": "ProcessDataPython",
    "description": "Process data using Python capabilities",
    "triggers": [
        {"type": "queue", "topic": "data.processed"}
    ],
    "enqueues": ["python.done"],
    "flows": ["data-processing"]
}

async def handler(input_data, ctx):
    """
    Python step that processes data and demonstrates Python capabilities
    """
    logger = ctx.logger
    enqueue = ctx.enqueue
    
    # Extract data from input
    original_id = input_data.get("original_id")
    result = input_data.get("result", "")
    
    logger.info(f"🐍 Python processing data for ID: {original_id}")
    
    start_time = time.time()
    
    # Simulate Python data processing
    processed_message = f"Python processed: {result}"
    
    # Add some Python-specific processing
    data_analysis = {
        "word_count": len(result.split()) if isinstance(result, str) else 0,
        "character_count": len(result) if isinstance(result, str) else 0,
        "processed_timestamp": datetime.now().isoformat(),
        "processing_language": "Python 3.x"
    }
    
    processing_time = (time.time() - start_time) * 1000  # Convert to milliseconds
    
    # Create result object
    python_result = {
        "id": original_id,
        "python_message": processed_message,
        "processed_by": ["appStarter", "appBridge", "ProcessDataPython"],
        "processing_time": processing_time,
        "analysis": data_analysis
    }
    
    # Enqueue to next step
    await enqueue({
        "topic": "python.done",
        "data": python_result
    })
    
    logger.info(f"✅ Python processing completed in {processing_time:.2f}ms")
```

  </Tab>
  <Tab value="notification-handler">
    A TypeScript notification handler that processes the Python results and sends notifications, showing seamless data flow between Python and TypeScript.

```typescript
import { type StepConfig } from 'motia'
import { z } from 'zod'

export const config = {
  name: 'NotificationHandler',
  description: 'Send notifications after Python processing',
  triggers: [
    { type: 'queue', topic: 'python.done', input: z.object({
      id: z.number(),
      python_message: z.string(),
      processed_by: z.array(z.string()),
      processing_time: z.number(),
      analysis: z.record(z.unknown()).optional()
    }) },
  ],
  enqueues: ['notification.sent'],
  flows: ['data-processing'],
} as const satisfies StepConfig

export const handler = async (input: any, { logger, enqueue }: any) => {
  logger.info('📧 Sending notifications after Python processing', { id: input.id })
  
  // Simulate sending notifications (email, slack, etc.)
  const notification = {
    id: input.id,
    message: `Notification: ${input.python_message}`,
    processed_by: input.processed_by,
    sent_at: new Date().toISOString()
  }

  // Send notification data to final step
  await enqueue({
    topic: 'notification.sent',
    data: {
      ...notification,
      processing_time: input.processing_time
    }
  })

  logger.info('✅ Notifications sent successfully', { id: input.id })
}
```

  </Tab>
  <Tab value="finalizer">
    A TypeScript finalizer that aggregates all the processing results and prepares the final summary data before handing off to JavaScript for metrics generation.

```typescript
import { type StepConfig } from 'motia'
import { z } from 'zod'

// Final step to complete the app - TypeScript
export const config = {
  name: 'AppFinalizer',
  description: 'Complete the basic app and log final results',
  triggers: [
    { type: 'queue', topic: 'notification.sent', input: z.object({
      id: z.number(),
      message: z.string(),
      processed_by: z.array(z.string()),
      sent_at: z.string(),
      processing_time: z.number()
    }) },
  ],
  enqueues: ['app.completed'],
  flows: ['data-processing'],
} as const satisfies StepConfig

export const handler = async (input: any, { logger, enqueue }: any) => {
  logger.info('🏁 Finalizing app', { 
    notificationId: input.id,
    message: input.message 
  })
  
  // Create final app summary
  const summary = {
    appId: input.id,
    status: 'completed',
    completed_at: new Date().toISOString(),
    steps_executed: [
      'app-starter',
      'app-bridge', 
      'python-processor',
      'notification-handler',
      'app-finalizer'
    ],
    result: input.message
  }

  // Send to JavaScript summary generator
  await enqueue({
    topic: 'app.completed',
    data: {
      ...summary,
      total_processing_time: input.processing_time
    }
  })

  logger.info('✅ App finalized successfully', { 
    appId: input.id,
    totalSteps: summary.steps_executed.length
  })
}
```

  </Tab>
  <Tab value="summary-generator">
    The final step uses JavaScript for dynamic summary generation and metrics calculation, showcasing how all three languages work together in a single workflow.

```javascript
// Final summary step - JavaScript
export const config = {
  name: 'summaryGenerator',
  description: 'Generate final summary in JavaScript',
  triggers: [
    { type: 'queue', topic: 'app.completed' },
  ],
  enqueues: [],
  flows: ['data-processing'],
}

export const handler = async (input, { logger }) => {
  logger.info('📊 Generating final summary in JavaScript', { 
    appId: input.appId,
    status: input.status 
  })
  
  // Calculate processing metrics
  const processingTime = input.total_processing_time || 0
  const stepsCount = input.steps_executed ? input.steps_executed.length : 0
  
  // Create comprehensive summary
  const summary = {
    appId: input.appId,
    finalStatus: input.status,
    totalSteps: stepsCount,
    processingTimeMs: processingTime,
    languages: ['TypeScript', 'Python', 'JavaScript'],
    summary: `Multi-language app completed successfully with ${stepsCount} steps`,
    result: input.result,
    completedAt: new Date().toISOString(),
    generatedBy: 'javascript-summary-step'
  }
  
  // Log final summary (final step - no enqueue needed)
  logger.info('✨ Final summary generated successfully', summary)
  
  return summary
}
```

  </Tab>
</Tabs>

---

## Type Definitions

Our unified system uses shared TypeScript types to ensure type safety across the multi-language pipeline:

```typescript
// types/index.ts
export interface AppData {
  id: number
  input: Record<string, unknown>
  started_at: string
  traceId: string
}

export interface ProcessedResult {
  original_id: number
  processed_at: string
  result: string
  confidence: number
  model_version: string
}

export interface PythonResult {
  id: number
  python_message: string
  processed_by: string[]
  processing_time: number
}

export interface NotificationData {
  id: number
  message: string
  processed_by: string[]
  sent_at: string
}

export interface AppSummary {
  appId: number
  status: string
  completed_at: string
  steps_executed: string[]
  result: string
}
```

---

## Explore the Workflow

The [iii development console](https://iii.dev/docs) provides a visual representation of your multi-language pipeline, making it easy to trace data flow between TypeScript, Python, and JavaScript steps.

<div className="my-8">![Multi-Language Workflow](/docs-images/motia-build-your-app-2.gif)</div>

You can monitor real-time execution, view logs from all languages in a unified interface, and trace the complete data flow from the TypeScript API through Python processing to JavaScript summary generation.

---

## Event Flow Architecture

The pipeline follows a clear event-driven flow that connects all languages seamlessly:

1. **`app.started`** - TypeScript API → TypeScript Bridge
2. **`data.processed`** - TypeScript Bridge → Python Processor  
3. **`python.done`** - Python Processor → TypeScript Notification Handler
4. **`notification.sent`** - TypeScript Notification → TypeScript Finalizer
5. **`app.completed`** - TypeScript Finalizer → JavaScript Summary Generator

Each step only needs to know the topics it triggers on and enqueues, creating loose coupling while maintaining strong data flow guarantees.

---

## Key Features & Benefits

### 🧩 **Step as Universal Primitive**
Every piece of logic—whether TypeScript, Python, or JavaScript—follows the same step pattern, creating true unification.

### 🌐 **Seamless Language Integration**
Steps eliminate the complexity of multi-language systems by providing a unified programming model.

### 📊 **Unified Development Experience**
Write, debug, and monitor all languages through a single interface and shared execution model.

### ⚡ **Hot Reload Across Languages**
Edit any step in any language and see changes instantly across the entire pipeline.

### 🔄 **Event-Driven Communication**
Steps communicate through events, enabling loose coupling and independent scaling.

### 🎯 **Single Deployment Model**
Deploy all languages together as a cohesive system, not as separate microservices.

### 🐍 **Python Step Naming**
Python steps use the `_step.py` suffix convention for proper module resolution (e.g., `simple-python_step.py`).

---

## Trying It Out

Ready to build your first multi-language Motia application? Let's get it running.

<Steps>

### Create Your Motia App

Start by creating a new Motia project with the interactive setup.

```shell
npx motia@latest create
```

### Navigate and Start Development

Move into your project directory and start the development server.

```shell
cd my-app  # Replace with your project name
npm run dev
```

### Open the iii Development Console

Navigate to [`http://localhost:3000`](http://localhost:3000) to access the iii development console and view your workflow.

### Test the Multi-Language Pipeline

Send a request to your API endpoint to see the multi-language workflow in action:

```shell
   curl -X POST http://localhost:3111/start-app \
     -H "Content-Type: application/json" \
     -d '{"data": {"test": "value"}, "message": "Hello!"}'
```

Watch in the iii development console as your data flows through:
1. **TypeScript** validation and event emission
2. **TypeScript** bridge processing and forwarding  
3. **Python** data processing with rich logging
4. **TypeScript** notification handling
5. **TypeScript** finalization and aggregation
6. **JavaScript** summary generation and metrics

</Steps>

---

## 💻 Dive into the Code

Want to explore multi-language workflows further? Check out additional examples and the complete source code:

<div className="not-prose">
  <div className="bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-blue-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Multi-Language Examples</h3>
        <p className="text-gray-600 mb-4">Access complete multi-language implementations, configuration examples, and learn how to integrate TypeScript, Python, and JavaScript in production applications.</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-blue-600 hover:bg-blue-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.30 3.297-1.30.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            Explore Examples
          </a>
          <a 
            href="/docs/getting-started/quick-start" 
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            Quick Start →
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Conclusion: The Power of Unification Through Steps

This multi-language data processing pipeline demonstrates how **steps** fundamentally change multi-language development. By providing a single primitive that works across TypeScript, Python, and JavaScript, we've eliminated the traditional complexity of polyglot architectures.

**The step primitive enables true unification:**
- **Universal Pattern** - Every step, regardless of language, follows the same receive-process-enqueue pattern
- **Seamless Integration** - Add Ruby, Go, Rust, or any language using the same step abstraction
- **Unified Deployment** - All languages deploy together as a single, coherent system
- **Shared Development Model** - Write, debug, and monitor everything through the same interface

**Key benefits of step-based unification:**
- **Single Mental Model** - Learn the step pattern once, apply it to any language
- **Cohesive System** - All components work together as parts of one application, not separate services
- **Consistent Experience** - Development, debugging, and monitoring work the same way across all languages
- **Natural Scaling** - Each step can scale independently while maintaining system coherence

**Extend your pipeline with more steps:**
- Add specialized processing steps for different data types and business logic
- Integrate machine learning workflows with Python steps for AI processing
- Build real-time analytics with streaming steps for live data processing
- Connect to enterprise systems through database and API integration steps
- Implement scheduled processing with cron steps for batch operations

The **step primitive** makes all extensions natural and straightforward—every new capability follows the same unified pattern.

Ready to unify your multi-language systems? Start building with steps today!


## Examples
[multi-language-data-processing](/docs/examples/multi-language-data-processing): Code example
---
title: 'Multi-Language Processing'
description: 'Multi-Language Data Processing: Building a Unified Pipeline with Motia'
---

Modern backend development often requires combining the strengths of different programming languages. TypeScript for APIs, Python for data processing and AI, JavaScript for rapid prototyping. Traditional approaches involve complex microservices architectures with intricate communication patterns.

This comprehensive guide explores how to build a unified multi-language data processing pipeline using Motia's **step** primitive. We'll cover:

1. **Steps as Core Primitive**: How steps unify different languages under a single abstraction.
2. **Building the Pipeline**: A step-by-step guide to creating a cohesive multi-language data processing workflow.
3. **Unified Execution Model**: How steps enable seamless communication between different runtime environments.
4. **Hands-On Development**: How to build, run, and observe your unified multi-language pipeline.

Let's build a production-ready data processing system where steps unify TypeScript, Python, and JavaScript into a single cohesive workflow.

---

## Workflow Overview

<div className="my-8">![Multi-Language Data Processing](/docs-images/motia-build-your-app-2.gif)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/multi-language-data-processing)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## The Power of Steps: A Unified Multi-Language Primitive

At its core, our data processing pipeline demonstrates how **steps** solve the fundamental challenge of multi-language systems: unifying different programming languages under a single, coherent abstraction. Traditional polyglot architectures require complex inter-process communication and deployment coordination. Motia's **step** primitive unifies everything.

**Steps enable true language unification:**

- **[TypeScript](https://www.typescriptlang.org/)** steps: Strong typing and excellent tooling for APIs and orchestration
- **[Python](https://www.python.org/)** steps: Rich ecosystem for data processing, ML, and scientific computing  
- **[JavaScript](https://developer.mozilla.org/en-US/docs/Web/JavaScript)** steps: Dynamic processing and rapid development
- **[Motia's Step Primitive](https://motia.dev)**: The unifying abstraction that makes all languages work as a single system

Instead of managing multiple services, **steps** provide a single programming model. Whether written in TypeScript, Python, or JavaScript, every step follows the same pattern: receive data, process it, enqueue events. This unification is what makes multi-language development straightforward.

---

## The Anatomy of Our Multi-Language Pipeline

Our application consists of six specialized steps, each leveraging the optimal language for its specific task. Let's explore the complete architecture.

<Folder name="steps" defaultOpen>
  <File name="01-starter.step.ts" />
  <File name="02-bridge.step.ts" />
  <File name="simple-python_step.py" />
  <File name="notify.step.ts" />
  <File name="04-final.step.ts" />
  <File name="05-summary.step.js" />
</Folder>

<Folder name="types" defaultOpen>
  <File name="index.ts" />
</Folder>

<Tabs items={['api-starter', 'bridge-step', 'python-processor', 'notification-handler', 'finalizer', 'summary-generator']}>
  <Tab value="api-starter">
    The entry point for our multi-language workflow. This TypeScript API endpoint receives data, validates it with Zod schemas, and kicks off the processing pipeline.

```typescript
import { type StepConfig } from 'motia'
import { z } from 'zod'

const bodySchema = z.object({
  data: z.record(z.unknown()).optional(),
  message: z.string().optional()
})

// API endpoint to start the multi-language pipeline
export const config = {
  name: 'AppStarter',
  description: 'Start the multi-language app pipeline',
  triggers: [
    { type: 'http', method: 'POST', path: '/start-app', bodySchema },
  ],
  responseSchema: {
    200: z.object({
      message: z.string(),
      appId: z.number(),
      traceId: z.string()
    })
  },
  enqueues: ['app.started'],
  flows: ['data-processing'],
} as const satisfies StepConfig

export const handler = async (req: any, { logger, enqueue, traceId }: any) => {
  logger.info('🚀 Starting multi-language app', { body: req.body, traceId })
  
  const appData = {
    id: Date.now(),
    input: req.body.data || {},
    started_at: new Date().toISOString(),
    traceId
  }

  // Enqueue to next step
  await enqueue({
    topic: 'app.started',
    data: appData
  })

  logger.info('✅ App started successfully', { 
    appId: appData.id,
    traceId 
  })

  return {
    status: 200,
    body: {
      message: 'Multi-language app started successfully',
      appId: appData.id,
      traceId
    }
  }
}
```

  </Tab>
  <Tab value="bridge-step">
    A TypeScript bridge that receives the app start event, processes the data, and forwards it to the Python processing step with proper type transformation.

```typescript
import { type StepConfig } from 'motia'
import { z } from 'zod'

// Bridge step to connect app starter to Python processing
export const config = {
  name: 'AppBridge',
  description: 'Bridge between app start and Python processing',
  triggers: [
    { type: 'queue', topic: 'app.started', input: z.object({
      id: z.number(),
      input: z.record(z.unknown()),
      started_at: z.string(),
      traceId: z.string()
    }) },
  ],
  enqueues: ['data.processed'],
  flows: ['data-processing'],
} as const satisfies StepConfig

export const handler = async (input: any, { logger, enqueue }: any) => {
  logger.info('🌉 Processing app data and sending to Python', { appId: input.id })
  
  // Process data for Python step
  const processedResult = {
    original_id: input.id,
    processed_at: input.started_at,
    result: `Processed: ${JSON.stringify(input.input)}`,
    confidence: 0.95,
    model_version: '1.0'
  }

  // Send to Python processing
  await enqueue({
    topic: 'data.processed',
    data: processedResult
  })

  logger.info('✅ Data sent to Python processing', { 
    originalId: input.id
  })
}
```

  </Tab>
  <Tab value="python-processor">
    The core data processor written in Python, demonstrating how Python steps integrate seamlessly with the TypeScript workflow while maintaining access to Python's rich ecosystem. Note the `_step.py` naming convention.

```python
import time
from datetime import datetime

# Python processing step configuration
config = {
    "name": "ProcessDataPython",
    "description": "Process data using Python capabilities",
    "triggers": [
        {"type": "queue", "topic": "data.processed"}
    ],
    "enqueues": ["python.done"],
    "flows": ["data-processing"]
}

async def handler(input_data, ctx):
    """
    Python step that processes data and demonstrates Python capabilities
    """
    logger = ctx.logger
    enqueue = ctx.enqueue
    
    # Extract data from input
    original_id = input_data.get("original_id")
    result = input_data.get("result", "")
    
    logger.info(f"🐍 Python processing data for ID: {original_id}")
    
    start_time = time.time()
    
    # Simulate Python data processing
    processed_message = f"Python processed: {result}"
    
    # Add some Python-specific processing
    data_analysis = {
        "word_count": len(result.split()) if isinstance(result, str) else 0,
        "character_count": len(result) if isinstance(result, str) else 0,
        "processed_timestamp": datetime.now().isoformat(),
        "processing_language": "Python 3.x"
    }
    
    processing_time = (time.time() - start_time) * 1000  # Convert to milliseconds
    
    # Create result object
    python_result = {
        "id": original_id,
        "python_message": processed_message,
        "processed_by": ["appStarter", "appBridge", "ProcessDataPython"],
        "processing_time": processing_time,
        "analysis": data_analysis
    }
    
    # Enqueue to next step
    await enqueue({
        "topic": "python.done",
        "data": python_result
    })
    
    logger.info(f"✅ Python processing completed in {processing_time:.2f}ms")
```

  </Tab>
  <Tab value="notification-handler">
    A TypeScript notification handler that processes the Python results and sends notifications, showing seamless data flow between Python and TypeScript.

```typescript
import { type StepConfig } from 'motia'
import { z } from 'zod'

export const config = {
  name: 'NotificationHandler',
  description: 'Send notifications after Python processing',
  triggers: [
    { type: 'queue', topic: 'python.done', input: z.object({
      id: z.number(),
      python_message: z.string(),
      processed_by: z.array(z.string()),
      processing_time: z.number(),
      analysis: z.record(z.unknown()).optional()
    }) },
  ],
  enqueues: ['notification.sent'],
  flows: ['data-processing'],
} as const satisfies StepConfig

export const handler = async (input: any, { logger, enqueue }: any) => {
  logger.info('📧 Sending notifications after Python processing', { id: input.id })
  
  // Simulate sending notifications (email, slack, etc.)
  const notification = {
    id: input.id,
    message: `Notification: ${input.python_message}`,
    processed_by: input.processed_by,
    sent_at: new Date().toISOString()
  }

  // Send notification data to final step
  await enqueue({
    topic: 'notification.sent',
    data: {
      ...notification,
      processing_time: input.processing_time
    }
  })

  logger.info('✅ Notifications sent successfully', { id: input.id })
}
```

  </Tab>
  <Tab value="finalizer">
    A TypeScript finalizer that aggregates all the processing results and prepares the final summary data before handing off to JavaScript for metrics generation.

```typescript
import { type StepConfig } from 'motia'
import { z } from 'zod'

// Final step to complete the app - TypeScript
export const config = {
  name: 'AppFinalizer',
  description: 'Complete the basic app and log final results',
  triggers: [
    { type: 'queue', topic: 'notification.sent', input: z.object({
      id: z.number(),
      message: z.string(),
      processed_by: z.array(z.string()),
      sent_at: z.string(),
      processing_time: z.number()
    }) },
  ],
  enqueues: ['app.completed'],
  flows: ['data-processing'],
} as const satisfies StepConfig

export const handler = async (input: any, { logger, enqueue }: any) => {
  logger.info('🏁 Finalizing app', { 
    notificationId: input.id,
    message: input.message 
  })
  
  // Create final app summary
  const summary = {
    appId: input.id,
    status: 'completed',
    completed_at: new Date().toISOString(),
    steps_executed: [
      'app-starter',
      'app-bridge', 
      'python-processor',
      'notification-handler',
      'app-finalizer'
    ],
    result: input.message
  }

  // Send to JavaScript summary generator
  await enqueue({
    topic: 'app.completed',
    data: {
      ...summary,
      total_processing_time: input.processing_time
    }
  })

  logger.info('✅ App finalized successfully', { 
    appId: input.id,
    totalSteps: summary.steps_executed.length
  })
}
```

  </Tab>
  <Tab value="summary-generator">
    The final step uses JavaScript for dynamic summary generation and metrics calculation, showcasing how all three languages work together in a single workflow.

```javascript
// Final summary step - JavaScript
export const config = {
  name: 'summaryGenerator',
  description: 'Generate final summary in JavaScript',
  triggers: [
    { type: 'queue', topic: 'app.completed' },
  ],
  enqueues: [],
  flows: ['data-processing'],
}

export const handler = async (input, { logger }) => {
  logger.info('📊 Generating final summary in JavaScript', { 
    appId: input.appId,
    status: input.status 
  })
  
  // Calculate processing metrics
  const processingTime = input.total_processing_time || 0
  const stepsCount = input.steps_executed ? input.steps_executed.length : 0
  
  // Create comprehensive summary
  const summary = {
    appId: input.appId,
    finalStatus: input.status,
    totalSteps: stepsCount,
    processingTimeMs: processingTime,
    languages: ['TypeScript', 'Python', 'JavaScript'],
    summary: `Multi-language app completed successfully with ${stepsCount} steps`,
    result: input.result,
    completedAt: new Date().toISOString(),
    generatedBy: 'javascript-summary-step'
  }
  
  // Log final summary (final step - no enqueue needed)
  logger.info('✨ Final summary generated successfully', summary)
  
  return summary
}
```

  </Tab>
</Tabs>

---

## Type Definitions

Our unified system uses shared TypeScript types to ensure type safety across the multi-language pipeline:

```typescript
// types/index.ts
export interface AppData {
  id: number
  input: Record<string, unknown>
  started_at: string
  traceId: string
}

export interface ProcessedResult {
  original_id: number
  processed_at: string
  result: string
  confidence: number
  model_version: string
}

export interface PythonResult {
  id: number
  python_message: string
  processed_by: string[]
  processing_time: number
}

export interface NotificationData {
  id: number
  message: string
  processed_by: string[]
  sent_at: string
}

export interface AppSummary {
  appId: number
  status: string
  completed_at: string
  steps_executed: string[]
  result: string
}
```

---

## Explore the Workflow

The [iii development console](https://iii.dev/docs) provides a visual representation of your multi-language pipeline, making it easy to trace data flow between TypeScript, Python, and JavaScript steps.

<div className="my-8">![Multi-Language Workflow](/docs-images/motia-build-your-app-2.gif)</div>

You can monitor real-time execution, view logs from all languages in a unified interface, and trace the complete data flow from the TypeScript API through Python processing to JavaScript summary generation.

---

## Event Flow Architecture

The pipeline follows a clear event-driven flow that connects all languages seamlessly:

1. **`app.started`** - TypeScript API → TypeScript Bridge
2. **`data.processed`** - TypeScript Bridge → Python Processor  
3. **`python.done`** - Python Processor → TypeScript Notification Handler
4. **`notification.sent`** - TypeScript Notification → TypeScript Finalizer
5. **`app.completed`** - TypeScript Finalizer → JavaScript Summary Generator

Each step only needs to know the topics it triggers on and enqueues, creating loose coupling while maintaining strong data flow guarantees.

---

## Key Features & Benefits

### 🧩 **Step as Universal Primitive**
Every piece of logic—whether TypeScript, Python, or JavaScript—follows the same step pattern, creating true unification.

### 🌐 **Seamless Language Integration**
Steps eliminate the complexity of multi-language systems by providing a unified programming model.

### 📊 **Unified Development Experience**
Write, debug, and monitor all languages through a single interface and shared execution model.

### ⚡ **Hot Reload Across Languages**
Edit any step in any language and see changes instantly across the entire pipeline.

### 🔄 **Event-Driven Communication**
Steps communicate through events, enabling loose coupling and independent scaling.

### 🎯 **Single Deployment Model**
Deploy all languages together as a cohesive system, not as separate microservices.

### 🐍 **Python Step Naming**
Python steps use the `_step.py` suffix convention for proper module resolution (e.g., `simple-python_step.py`).

---

## Trying It Out

Ready to build your first multi-language Motia application? Let's get it running.

<Steps>

### Create Your Motia App

Start by creating a new Motia project with the interactive setup.

```shell
npx motia@latest create
```

### Navigate and Start Development

Move into your project directory and start the development server.

```shell
cd my-app  # Replace with your project name
npm run dev
```

### Open the iii Development Console

Navigate to [`http://localhost:3000`](http://localhost:3000) to access the iii development console and view your workflow.

### Test the Multi-Language Pipeline

Send a request to your API endpoint to see the multi-language workflow in action:

```shell
   curl -X POST http://localhost:3111/start-app \
     -H "Content-Type: application/json" \
     -d '{"data": {"test": "value"}, "message": "Hello!"}'
```

Watch in the iii development console as your data flows through:
1. **TypeScript** validation and event emission
2. **TypeScript** bridge processing and forwarding  
3. **Python** data processing with rich logging
4. **TypeScript** notification handling
5. **TypeScript** finalization and aggregation
6. **JavaScript** summary generation and metrics

</Steps>

---

## 💻 Dive into the Code

Want to explore multi-language workflows further? Check out additional examples and the complete source code:

<div className="not-prose">
  <div className="bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-blue-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Multi-Language Examples</h3>
        <p className="text-gray-600 mb-4">Access complete multi-language implementations, configuration examples, and learn how to integrate TypeScript, Python, and JavaScript in production applications.</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-blue-600 hover:bg-blue-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.30 3.297-1.30.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            Explore Examples
          </a>
          <a 
            href="/docs/getting-started/quick-start" 
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            Quick Start →
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Conclusion: The Power of Unification Through Steps

This multi-language data processing pipeline demonstrates how **steps** fundamentally change multi-language development. By providing a single primitive that works across TypeScript, Python, and JavaScript, we've eliminated the traditional complexity of polyglot architectures.

**The step primitive enables true unification:**
- **Universal Pattern** - Every step, regardless of language, follows the same receive-process-enqueue pattern
- **Seamless Integration** - Add Ruby, Go, Rust, or any language using the same step abstraction
- **Unified Deployment** - All languages deploy together as a single, coherent system
- **Shared Development Model** - Write, debug, and monitor everything through the same interface

**Key benefits of step-based unification:**
- **Single Mental Model** - Learn the step pattern once, apply it to any language
- **Cohesive System** - All components work together as parts of one application, not separate services
- **Consistent Experience** - Development, debugging, and monitoring work the same way across all languages
- **Natural Scaling** - Each step can scale independently while maintaining system coherence

**Extend your pipeline with more steps:**
- Add specialized processing steps for different data types and business logic
- Integrate machine learning workflows with Python steps for AI processing
- Build real-time analytics with streaming steps for live data processing
- Connect to enterprise systems through database and API integration steps
- Implement scheduled processing with cron steps for batch operations

The **step primitive** makes all extensions natural and straightforward—every new capability follows the same unified pattern.

Ready to unify your multi-language systems? Start building with steps today!

-   [rag-docling-weaviate](/docs/examples/rag-docling-weaviate): Documentation for rag-docling-weaviate.
---
title: 'RAG PDF Analyzer'
description: 'Intelligent Document Processing: Building a RAG System with Motia'
---

In the era of AI-powered applications, the ability to extract insights from documents is crucial. Whether you're building a knowledge base, a research assistant, or a customer support system, you need to transform static PDFs into queryable, intelligent systems. This is where Retrieval-Augmented Generation (RAG) architecture shines, and where the Motia framework provides an elegant solution.

This comprehensive guide explores how to build a production-ready RAG system that intelligently processes PDFs and answers questions about their content. We'll cover:

1.  **The RAG Architecture**: Understanding how document processing, vector storage, and AI generation work together.
2.  **Motia's Event-Driven Approach**: How `steps` create a scalable, maintainable RAG pipeline.
3.  **Building the Workflow**: A detailed walkthrough of our polyglot processing pipeline.
4.  **Advanced Features**: Real-time progress tracking, error handling, and production considerations.
5.  **Hands-On Testing**: How to ingest documents and query your knowledge base.

Let's transform your documents into an intelligent AI assistant.

---

## Workflow Overview

<div className="my-8">![RAG Workflow](./../img/rag-docling-weaviate-agent.png)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/rag-and-search/rag-fundamentals/rag-docling-weaviate-agent)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## The Power of Intelligent Document Processing


At its core, our RAG agent solves a fundamental challenge: how do you make unstructured documents searchable and queryable by AI? Traditional approaches often involve complex, monolithic systems that are difficult to scale and maintain. Our Motia-powered solution breaks this down into discrete, event-driven steps that each handle a specific aspect of the pipeline.

The magic happens through the integration of three powerful technologies:

-   **[Docling](https://github.com/docling-project/docling)**: Advanced PDF parsing with intelligent chunking that preserves document structure
-   **[Weaviate](https://weaviate.io/)**: Cloud-native vector database with built-in OpenAI integration
-   **[Motia](https://motia.dev)**: Event-driven framework that orchestrates the entire pipeline

Instead of a brittle, tightly-coupled system, we get a resilient architecture where each component can be scaled, modified, or replaced independently.

---

## The Anatomy of Our RAG Pipeline

Our application consists of seven specialized steps, each handling a specific part of the document processing and querying workflow. Let's explore the complete architecture.

<Folder name="steps" defaultOpen>
  <Folder name="api-steps" defaultOpen>
    <File name="api-process-pdfs.step.ts" />
    <File name="api-query-rag.step.ts" />
  </Folder>
  <Folder name="event-steps" defaultOpen>
    <File name="init-weaviate.step.ts" />
    <File name="read-pdfs.step.ts" />
    <File name="process-pdfs.step.py" />
    <File name="load-weaviate.step.ts" />
  </Folder>
</Folder>

<Tabs items={['api-process-pdfs', 'init-weaviate', 'read-pdfs', 'process-pdfs', 'load-weaviate', 'api-query-rag']}>
  <Tab value="api-process-pdfs">
    The entry point for document ingestion. This API endpoint receives a folder path, kicks off the processing pipeline, and returns immediately with a tracking ID for real-time progress monitoring.

    ```ts
    import { type Handlers, type StepConfig } from 'motia'
    import { z } from 'zod'
    import { v4 as uuidv4 } from 'uuid'

    export const config = {
      name: 'api-process-pdfs',
      description: 'API endpoint to start PDF processing pipeline',
      triggers: [
        { type: 'http', path: '/api/rag/process-pdfs', method: 'POST', bodySchema: z.object({
          folderPath: z.string().min(1, 'folderPath is required'),
        }) },
      ],
      enqueues: ['rag.read.pdfs'],
      flows: ['rag-workflow'],
    } as const satisfies StepConfig

    export const handler: Handlers<typeof config> = async (req, { enqueue, logger }) => {
      const { folderPath } = req.body
      const streamId = uuidv4()

      logger.info('Starting PDF processing pipeline', { folderPath, streamId })

      // Enqueue event to start the processing chain
      await enqueue({
        topic: 'rag.read.pdfs',
        data: { folderPath, streamId },
      })

      return {
        status: 200,
        body: { 
          message: 'PDF processing started',
          streamId,
          status: 'processing'
        },
      }
    }
    ```

  </Tab>
  <Tab value="init-weaviate">
    Ensures the Weaviate vector database is properly configured with the correct schema for our documents. This step creates the "Books" collection with OpenAI embeddings and GPT-4o generation capabilities.

    ```ts
    import weaviate, { WeaviateClient, vectorizer, generative } from 'weaviate-client'
    import { type Handlers, type StepConfig } from 'motia'
    import { z } from 'zod'

    export const config = {
      name: 'init-weaviate',
      description: 'Initialize Weaviate vector database',
      triggers: [
        { type: 'queue', topic: 'rag.read.pdfs', input: z.object({
          folderPath: z.string(),
          streamId: z.string().optional(),
        }) },
      ],
      enqueues: [],
      flows: ['rag-workflow'],
    } as const satisfies StepConfig

    const WEAVIATE_SCHEMA = {
      name: 'Books',
      description: 'Document chunks with metadata',
      vectorizers: vectorizer.text2VecOpenAI({
        model: 'text-embedding-3-small',
        sourceProperties: ['text'],
      }),
      generative: generative.openAI({
        model: 'gpt-4o',
        maxTokens: 4096,
      }),
      properties: [
        { name: 'text', dataType: 'text' as const },
        { name: 'title', dataType: 'text' as const },
        { name: 'source', dataType: 'text' as const },
        { name: 'page', dataType: 'number' as const },
      ],
    }

    export const handler: Handlers<typeof config> = async (input, { logger }) => {
      logger.info('Initializing Weaviate client')
      
      const client = await weaviate.connectToWeaviateCloud(process.env.WEAVIATE_URL!, {
        authCredentials: new weaviate.ApiKey(process.env.WEAVIATE_API_KEY!),
        headers: { 'X-OpenAI-Api-Key': process.env.OPENAI_API_KEY! },
      })

      try {
        const exists = await client.collections.get('Books').exists()
        if (!exists) {
          logger.info('Creating Books collection with OpenAI integration...')
          await client.collections.create(WEAVIATE_SCHEMA)
          logger.info('Collection created successfully')
        } else {
          logger.info('Books collection already exists')
        }
      } catch (error) {
        logger.error('Error initializing Weaviate', { error })
        throw error
      } finally {
        await client.close()
      }
    }
    ```

  </Tab>
  <Tab value="read-pdfs">
    Scans the specified folder for PDF files and prepares them for processing. Includes intelligent path resolution to handle various folder structures.

    ```ts
    import { readdir } from 'fs/promises'
    import { join, resolve, basename } from 'path'
    import { type Handlers, type StepConfig } from 'motia'
    import { z } from 'zod'

    export const config = {
      name: 'read-pdfs',
      description: 'Read PDF files from folder',
      triggers: [
        { type: 'queue', topic: 'rag.read.pdfs', input: z.object({
          folderPath: z.string(),
          streamId: z.string().optional(),
        }) },
      ],
      enqueues: [{ topic: 'rag.process.pdfs', label: 'Start processing PDFs' }],
      flows: ['rag-workflow'],
    } as const satisfies StepConfig

    export const handler: Handlers<typeof config> = async (input, { enqueue, logger }) => {
      const { folderPath: inputFolderPath, streamId } = input
      logger.info(`Reading PDFs from folder: ${inputFolderPath}`)

      // Intelligent path resolution to prevent ENOENT errors
      const currentDirName = basename(process.cwd())
      let resolvedFolderPath = resolve(inputFolderPath)

      // Handle duplicated path segments
      const duplicatedSegment = `${currentDirName}/${currentDirName}`
      if (resolvedFolderPath.includes(duplicatedSegment)) {
        resolvedFolderPath = resolvedFolderPath.replace(duplicatedSegment, currentDirName)
      }

      logger.info(`Resolved folder path: ${resolvedFolderPath}`)

      try {
        const files = await readdir(resolvedFolderPath)
        const pdfFiles = files.filter((file) => file.endsWith('.pdf'))

        logger.info(`Found ${pdfFiles.length} PDF files`)

        const filesInfo = await Promise.all(
          pdfFiles.map(async (pdfFile) => {
            const filePath = join(resolvedFolderPath, pdfFile)
            return {
              filePath,
              fileName: pdfFile,
            }
          })
        )

        await enqueue({
          topic: 'rag.process.pdfs',
          data: { files: filesInfo, streamId },
        })
      } catch (error) {
        logger.error(`Failed to read PDFs from folder: ${resolvedFolderPath}`, { error })
        throw error
      }
    }
    ```

  </Tab>
  <Tab value="process-pdfs">
    The heart of our document processing pipeline. This Python step uses Docling to intelligently parse and chunk PDFs, preserving document structure and context.

    ```python
    import json
    import os
    from pathlib import Path
    from typing import Any, Dict, List
    from docling.document_converter import DocumentConverter
    from docling.chunking import HybridChunker
    from docling.datamodel.base_models import InputFormat
    from docling.datamodel.pipeline_options import PdfPipelineOptions
    from docling.document_converter import PdfFormatOption

    def handler(input_data: Dict[str, Any], context: Dict[str, Any]) -> None:
        """Process PDFs using Docling with intelligent chunking"""
        logger = context['logger']
        enqueue = context['enqueue']
        
        files = input_data.get('files', [])
        stream_id = input_data.get('streamId')
        
        logger.info(f"Processing {len(files)} PDF files with Docling")
        
        # Configure Docling with optimized settings
        pipeline_options = PdfPipelineOptions(
            do_ocr=True,
            do_table_structure=True,
            table_structure_options={
                "do_cell_matching": True,
            }
        )
        
        doc_converter = DocumentConverter(
            format_options={
                InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)
            }
        )
        
        # Initialize the hybrid chunker for intelligent document segmentation
        chunker = HybridChunker(
            tokenizer="cl100k_base",
            max_tokens=512,
            overlap_tokens=50,
            heading_hierarchies=True,
            split_by_page=False
        )
        
        all_chunks = []
        
        for file_info in files:
            file_path = file_info['filePath']
            file_name = file_info['fileName']
            
            logger.info(f"Processing file: {file_name}")
            
            try:
                # Convert PDF to structured document
                result = doc_converter.convert(file_path)
                doc = result.document
                
                logger.info(f"Converted {file_name}: {len(doc.pages)} pages")
                
                # Apply intelligent chunking
                chunks = list(chunker.chunk(doc))
                logger.info(f"Generated {len(chunks)} chunks for {file_name}")
                
                # Prepare chunks for Weaviate
                for i, chunk in enumerate(chunks):
                    chunk_data = {
                        'text': chunk.text,
                        'title': file_name,
                        'source': file_path,
                        'page': getattr(chunk, 'page_no', i + 1),
                        'chunk_id': f"{file_name}_chunk_{i}"
                    }
                    all_chunks.append(chunk_data)
                    
            except Exception as e:
                logger.error(f"Error processing {file_name}: {str(e)}")
                continue
        
        logger.info(f"Total chunks generated: {len(all_chunks)}")
        
        if all_chunks:
            # Enqueue chunks for Weaviate ingestion
            enqueue({
                'topic': 'rag.load.weaviate',
                'data': {
                    'chunks': all_chunks,
                    'streamId': stream_id,
                    'totalFiles': len(files),
                    'totalChunks': len(all_chunks)
                }
            })
        else:
            logger.warning("No chunks generated from PDF processing")
    ```

  </Tab>
  <Tab value="load-weaviate">
    Efficiently batches and loads the processed document chunks into Weaviate with progress tracking and error handling.

    ```ts
    import weaviate from 'weaviate-client'
    import { type Handlers, type StepConfig } from 'motia'
    import { z } from 'zod'

    const ChunkSchema = z.object({
      text: z.string(),
      title: z.string(),
      source: z.string(),
      page: z.number(),
      chunk_id: z.string(),
    })

    export const config = {
      name: 'load-weaviate',
      description: 'Load document chunks into Weaviate',
      triggers: [
        { type: 'queue', topic: 'rag.load.weaviate', input: z.object({
          chunks: z.array(ChunkSchema),
          streamId: z.string().optional(),
          totalFiles: z.number().optional(),
          totalChunks: z.number().optional(),
        }) },
      ],
      enqueues: [],
      flows: ['rag-workflow'],
    } as const satisfies StepConfig

    export const handler: Handlers<typeof config> = async (input, { logger }) => {
      const { chunks, streamId, totalFiles, totalChunks } = input
      
      logger.info('Loading chunks into Weaviate', { 
        chunkCount: chunks.length,
        totalFiles,
        totalChunks,
        streamId 
      })

      const client = await weaviate.connectToWeaviateCloud(process.env.WEAVIATE_URL!, {
        authCredentials: new weaviate.ApiKey(process.env.WEAVIATE_API_KEY!),
        headers: { 'X-OpenAI-Api-Key': process.env.OPENAI_API_KEY! },
      })

      try {
        const collection = client.collections.get('Books')
        const BATCH_SIZE = 100

        // Process chunks in batches for optimal performance
        for (let i = 0; i < chunks.length; i += BATCH_SIZE) {
          const batch = chunks.slice(i, i + BATCH_SIZE)
          const batchNumber = Math.floor(i / BATCH_SIZE) + 1
          const totalBatches = Math.ceil(chunks.length / BATCH_SIZE)

          logger.info(`Inserting batch ${batchNumber}/${totalBatches}`, {
            batchSize: batch.length,
            streamId
          })

          const objects = batch.map(chunk => ({
            properties: {
              text: chunk.text,
              title: chunk.title,
              source: chunk.source,
              page: chunk.page,
            }
          }))

          const result = await collection.data.insertMany(objects)
          
          if (result.hasErrors) {
            logger.error('Batch insertion had errors', { 
              errors: result.errors,
              batchNumber,
              streamId 
            })
          } else {
            logger.info(`Successfully inserted batch ${batchNumber}/${totalBatches}`)
          }
        }

        logger.info('Successfully loaded all chunks into Weaviate', {
          totalChunks: chunks.length,
          streamId
        })

      } catch (error) {
        logger.error('Error loading chunks into Weaviate', { error, streamId })
        throw error
      } finally {
        await client.close()
      }
    }
    ```

  </Tab>
  <Tab value="api-query-rag">
    The query interface that performs semantic search and generates contextual answers using Weaviate's integrated OpenAI capabilities.

    ```ts
    import weaviate from 'weaviate-client'
    import { type Handlers, type StepConfig } from 'motia'
    import { z } from 'zod'

    const RAGResponse = z.object({
      answer: z.string(),
      chunks: z.array(z.object({
        text: z.string(),
        title: z.string(),
        source: z.string(),
        page: z.number(),
      })),
      query: z.string(),
      timestamp: z.string(),
    })

    export const config = {
      name: 'api-query-rag',
      description: 'Query the RAG system for answers',
      triggers: [
        { type: 'http', path: '/api/rag/query', method: 'POST', bodySchema: z.object({
          query: z.string().min(1, 'Query is required'),
          limit: z.number().min(1).max(10).default(3),
        }) },
      ],
      enqueues: [],
      flows: ['rag-workflow'],
    } as const satisfies StepConfig

    export const handler: Handlers<typeof config> = async (req, { logger }) => {
      const { query, limit = 3 } = req.body

      logger.info('Processing RAG query', { query, limit })

      const client = await weaviate.connectToWeaviateCloud(process.env.WEAVIATE_URL!, {
        authCredentials: new weaviate.ApiKey(process.env.WEAVIATE_API_KEY!),
        headers: { 'X-OpenAI-Api-Key': process.env.OPENAI_API_KEY! },
      })

      try {
        const collection = client.collections.get('Books')
        
        // Perform semantic search with AI generation
        const results = await collection.generate.nearText(
          query,
          { limit, distance: 0.6 },
          { 
            singlePrompt: `Answer this question based on the provided context: ${query}. 
                          Be specific and cite the sources when possible.` 
          }
        )

        // Extract the generated answer and source chunks
        const generatedAnswer = results.generated || 'No answer could be generated.'
        
        const chunks = results.objects.map(obj => ({
          text: obj.properties.text as string,
          title: obj.properties.title as string,
          source: obj.properties.source as string,
          page: obj.properties.page as number,
        }))

        const response = RAGResponse.parse({
          answer: generatedAnswer,
          chunks,
          query,
          timestamp: new Date().toISOString(),
        })

        logger.info('RAG query completed successfully', { 
          query, 
          chunksFound: chunks.length,
          answerLength: generatedAnswer.length 
        })

        return {
          status: 200,
          body: response,
        }

      } catch (error) {
        logger.error('Error processing RAG query', { error, query })
        return {
          status: 500,
          body: { error: 'Failed to process query' },
        }
      } finally {
        await client.close()
      }
    }
    ```

  </Tab>
</Tabs>

---

## Explore the Workflow

The [iii development console](https://iii.dev/docs) provides a visual representation of your RAG pipeline, making it easy to understand the flow and debug any issues.

<div className="my-8">![RAG Workflow](./../img/rag-example.gif)</div>

You can monitor real-time processing, view logs, and trace the execution of each step directly in the iii development console. This makes development and debugging significantly easier compared to traditional monolithic approaches.

---

## Key Features & Benefits

### 🚀 **Event-Driven Architecture**
Each step is independent and communicates through events, making the system highly scalable and maintainable.

### 🧠 **Intelligent Document Processing**  
Docling's hybrid chunking preserves document structure while creating optimal chunks for embedding.

### ⚡ **High-Performance Vector Search**
Weaviate's cloud-native architecture provides fast, scalable similarity search with built-in OpenAI integration.

### 🔄 **Real-Time Progress Tracking**
Monitor document processing progress with detailed logging and status updates.

### 🌐 **Polyglot Support**
Seamlessly combine Python (Docling) and TypeScript (orchestration) in a single workflow.

### 🛡️ **Production-Ready**
Built-in error handling, batch processing, and resource cleanup ensure reliability.

---

## Trying It Out

Ready to build your own intelligent document assistant? Let's get the system running.

<Steps>

### Install Dependencies

Install both Node.js and Python dependencies. The prepare script automatically sets up the Python virtual environment.

```shell
npm install
```

### Set Your Environment Variables

You'll need API keys for OpenAI and Weaviate Cloud. Create a `.env` file:

```shell
OPENAI_API_KEY="sk-..."
WEAVIATE_URL="https://your-cluster.weaviate.network"
WEAVIATE_API_KEY="your-weaviate-api-key"
```

### Run the Project

Start the Motia development server to begin processing documents.

```shell
npm run dev
```

### Process Your First Documents

Add some PDF files to the `docs/pdfs/` folder, then start the ingestion pipeline:

```shell
curl -X POST http://localhost:3111/api/rag/process-pdfs \
  -H "Content-Type: application/json" \
  -d '{"folderPath":"docs/pdfs"}'
```

Watch the logs as your documents are processed through the pipeline:
1. **PDF Reading**: Files are discovered and queued
2. **Docling Processing**: Intelligent chunking with structure preservation  
3. **Weaviate Loading**: Chunks are embedded and stored

### Query Your Knowledge Base

Once processing is complete, you can ask questions about your documents:

#### General Query
```shell
curl -X POST http://localhost:3111/api/rag/query \
  -H "Content-Type: application/json" \
  -d '{"query":"What are the main topics covered in these documents?","limit":3}'
```

#### Specific Question
```shell
curl -X POST http://localhost:3111/api/rag/query \
  -H "Content-Type: application/json" \
  -d '{"query":"What methodology was used in the research?","limit":5}'
```

The response includes both a generated answer and the source chunks with page numbers for verification.

</Steps>

---

## Advanced Usage

### Custom Chunking Strategies

Modify the Python processing step to implement custom chunking logic:

```python
# In process-pdfs.step.py
chunker = HybridChunker(
    tokenizer="cl100k_base",
    max_tokens=1024,  # Larger chunks for more context
    overlap_tokens=100,  # More overlap for better continuity
    heading_hierarchies=True,
    split_by_page=True  # Preserve page boundaries
)
```

### Batch Processing Optimization

Adjust batch sizes in the Weaviate loading step for optimal performance:

```ts
// In load-weaviate.step.ts
const BATCH_SIZE = 50  // Smaller batches for large documents
```

### Multi-Collection Support

Extend the system to handle different document types by creating separate Weaviate collections:

```ts
const COLLECTIONS = {
  research: 'ResearchPapers',
  manuals: 'TechnicalManuals', 
  reports: 'BusinessReports'
}
```

---

## Troubleshooting

### Common Issues

**ENOENT Path Errors**: The system automatically handles path normalization, but ensure your `folderPath` is relative to the project root.

**Empty Answers**: Check that documents were successfully processed by examining the logs. Verify your OpenAI API key is valid.

**Weaviate Connection Issues**: Ensure your `WEAVIATE_URL` and `WEAVIATE_API_KEY` are correct and your cluster is running.

### Performance Tips

- **Document Size**: For large PDFs, consider preprocessing to split them into smaller files
- **Batch Size**: Adjust the Weaviate batch size based on your cluster's capacity
- **Chunking Strategy**: Experiment with different chunk sizes and overlap for your specific use case

---

## 💻 Dive into the Code

Want to explore the complete RAG implementation? Check out the full source code, including all steps, configuration files, and setup instructions:

<div className="not-prose">
  <div className="bg-gradient-to-r from-purple-50 to-pink-50 border border-purple-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-purple-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Complete RAG Implementation</h3>
        <p className="text-gray-600 mb-4">Access the full source code for this RAG agent, including Python processing scripts, TypeScript orchestration, and production configuration.</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/rag-and-search/rag-fundamentals/rag-docling-weaviate-agent" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-purple-600 hover:bg-purple-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.30.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            View RAG Example
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            More Examples →
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Conclusion: The Future of Document Intelligence

This RAG system demonstrates the power of combining best-in-class technologies with Motia's event-driven architecture. By breaking down complex document processing into discrete, manageable steps, we've created a system that's not only powerful but also maintainable and scalable.

The polyglot nature of the solution: Python for document processing, TypeScript for orchestration, shows how Motia enables you to use the right tool for each job without sacrificing integration or maintainability.

From here, you can extend the system by:
- Adding support for other document formats (Word, PowerPoint, etc.)
- Implementing document classification and routing
- Adding real-time document updates and synchronization
- Building a web interface for document management
- Integrating with existing business systems

The event-driven architecture makes all of these extensions straightforward to implement without disrupting the existing pipeline.

Ready to transform your documents into intelligent, queryable knowledge bases? Start building with Motia today!



## Examples
[rag-docling-weaviate](/docs/examples/rag-docling-weaviate): Code example
---
title: 'RAG PDF Analyzer'
description: 'Intelligent Document Processing: Building a RAG System with Motia'
---

In the era of AI-powered applications, the ability to extract insights from documents is crucial. Whether you're building a knowledge base, a research assistant, or a customer support system, you need to transform static PDFs into queryable, intelligent systems. This is where Retrieval-Augmented Generation (RAG) architecture shines, and where the Motia framework provides an elegant solution.

This comprehensive guide explores how to build a production-ready RAG system that intelligently processes PDFs and answers questions about their content. We'll cover:

1.  **The RAG Architecture**: Understanding how document processing, vector storage, and AI generation work together.
2.  **Motia's Event-Driven Approach**: How `steps` create a scalable, maintainable RAG pipeline.
3.  **Building the Workflow**: A detailed walkthrough of our polyglot processing pipeline.
4.  **Advanced Features**: Real-time progress tracking, error handling, and production considerations.
5.  **Hands-On Testing**: How to ingest documents and query your knowledge base.

Let's transform your documents into an intelligent AI assistant.

---

## Workflow Overview

<div className="my-8">![RAG Workflow](./../img/rag-docling-weaviate-agent.png)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/rag-and-search/rag-fundamentals/rag-docling-weaviate-agent)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## The Power of Intelligent Document Processing


At its core, our RAG agent solves a fundamental challenge: how do you make unstructured documents searchable and queryable by AI? Traditional approaches often involve complex, monolithic systems that are difficult to scale and maintain. Our Motia-powered solution breaks this down into discrete, event-driven steps that each handle a specific aspect of the pipeline.

The magic happens through the integration of three powerful technologies:

-   **[Docling](https://github.com/docling-project/docling)**: Advanced PDF parsing with intelligent chunking that preserves document structure
-   **[Weaviate](https://weaviate.io/)**: Cloud-native vector database with built-in OpenAI integration
-   **[Motia](https://motia.dev)**: Event-driven framework that orchestrates the entire pipeline

Instead of a brittle, tightly-coupled system, we get a resilient architecture where each component can be scaled, modified, or replaced independently.

---

## The Anatomy of Our RAG Pipeline

Our application consists of seven specialized steps, each handling a specific part of the document processing and querying workflow. Let's explore the complete architecture.

<Folder name="steps" defaultOpen>
  <Folder name="api-steps" defaultOpen>
    <File name="api-process-pdfs.step.ts" />
    <File name="api-query-rag.step.ts" />
  </Folder>
  <Folder name="event-steps" defaultOpen>
    <File name="init-weaviate.step.ts" />
    <File name="read-pdfs.step.ts" />
    <File name="process-pdfs.step.py" />
    <File name="load-weaviate.step.ts" />
  </Folder>
</Folder>

<Tabs items={['api-process-pdfs', 'init-weaviate', 'read-pdfs', 'process-pdfs', 'load-weaviate', 'api-query-rag']}>
  <Tab value="api-process-pdfs">
    The entry point for document ingestion. This API endpoint receives a folder path, kicks off the processing pipeline, and returns immediately with a tracking ID for real-time progress monitoring.

    ```ts
    import { type Handlers, type StepConfig } from 'motia'
    import { z } from 'zod'
    import { v4 as uuidv4 } from 'uuid'

    export const config = {
      name: 'api-process-pdfs',
      description: 'API endpoint to start PDF processing pipeline',
      triggers: [
        { type: 'http', path: '/api/rag/process-pdfs', method: 'POST', bodySchema: z.object({
          folderPath: z.string().min(1, 'folderPath is required'),
        }) },
      ],
      enqueues: ['rag.read.pdfs'],
      flows: ['rag-workflow'],
    } as const satisfies StepConfig

    export const handler: Handlers<typeof config> = async (req, { enqueue, logger }) => {
      const { folderPath } = req.body
      const streamId = uuidv4()

      logger.info('Starting PDF processing pipeline', { folderPath, streamId })

      // Enqueue event to start the processing chain
      await enqueue({
        topic: 'rag.read.pdfs',
        data: { folderPath, streamId },
      })

      return {
        status: 200,
        body: { 
          message: 'PDF processing started',
          streamId,
          status: 'processing'
        },
      }
    }
    ```

  </Tab>
  <Tab value="init-weaviate">
    Ensures the Weaviate vector database is properly configured with the correct schema for our documents. This step creates the "Books" collection with OpenAI embeddings and GPT-4o generation capabilities.

    ```ts
    import weaviate, { WeaviateClient, vectorizer, generative } from 'weaviate-client'
    import { type Handlers, type StepConfig } from 'motia'
    import { z } from 'zod'

    export const config = {
      name: 'init-weaviate',
      description: 'Initialize Weaviate vector database',
      triggers: [
        { type: 'queue', topic: 'rag.read.pdfs', input: z.object({
          folderPath: z.string(),
          streamId: z.string().optional(),
        }) },
      ],
      enqueues: [],
      flows: ['rag-workflow'],
    } as const satisfies StepConfig

    const WEAVIATE_SCHEMA = {
      name: 'Books',
      description: 'Document chunks with metadata',
      vectorizers: vectorizer.text2VecOpenAI({
        model: 'text-embedding-3-small',
        sourceProperties: ['text'],
      }),
      generative: generative.openAI({
        model: 'gpt-4o',
        maxTokens: 4096,
      }),
      properties: [
        { name: 'text', dataType: 'text' as const },
        { name: 'title', dataType: 'text' as const },
        { name: 'source', dataType: 'text' as const },
        { name: 'page', dataType: 'number' as const },
      ],
    }

    export const handler: Handlers<typeof config> = async (input, { logger }) => {
      logger.info('Initializing Weaviate client')
      
      const client = await weaviate.connectToWeaviateCloud(process.env.WEAVIATE_URL!, {
        authCredentials: new weaviate.ApiKey(process.env.WEAVIATE_API_KEY!),
        headers: { 'X-OpenAI-Api-Key': process.env.OPENAI_API_KEY! },
      })

      try {
        const exists = await client.collections.get('Books').exists()
        if (!exists) {
          logger.info('Creating Books collection with OpenAI integration...')
          await client.collections.create(WEAVIATE_SCHEMA)
          logger.info('Collection created successfully')
        } else {
          logger.info('Books collection already exists')
        }
      } catch (error) {
        logger.error('Error initializing Weaviate', { error })
        throw error
      } finally {
        await client.close()
      }
    }
    ```

  </Tab>
  <Tab value="read-pdfs">
    Scans the specified folder for PDF files and prepares them for processing. Includes intelligent path resolution to handle various folder structures.

    ```ts
    import { readdir } from 'fs/promises'
    import { join, resolve, basename } from 'path'
    import { type Handlers, type StepConfig } from 'motia'
    import { z } from 'zod'

    export const config = {
      name: 'read-pdfs',
      description: 'Read PDF files from folder',
      triggers: [
        { type: 'queue', topic: 'rag.read.pdfs', input: z.object({
          folderPath: z.string(),
          streamId: z.string().optional(),
        }) },
      ],
      enqueues: [{ topic: 'rag.process.pdfs', label: 'Start processing PDFs' }],
      flows: ['rag-workflow'],
    } as const satisfies StepConfig

    export const handler: Handlers<typeof config> = async (input, { enqueue, logger }) => {
      const { folderPath: inputFolderPath, streamId } = input
      logger.info(`Reading PDFs from folder: ${inputFolderPath}`)

      // Intelligent path resolution to prevent ENOENT errors
      const currentDirName = basename(process.cwd())
      let resolvedFolderPath = resolve(inputFolderPath)

      // Handle duplicated path segments
      const duplicatedSegment = `${currentDirName}/${currentDirName}`
      if (resolvedFolderPath.includes(duplicatedSegment)) {
        resolvedFolderPath = resolvedFolderPath.replace(duplicatedSegment, currentDirName)
      }

      logger.info(`Resolved folder path: ${resolvedFolderPath}`)

      try {
        const files = await readdir(resolvedFolderPath)
        const pdfFiles = files.filter((file) => file.endsWith('.pdf'))

        logger.info(`Found ${pdfFiles.length} PDF files`)

        const filesInfo = await Promise.all(
          pdfFiles.map(async (pdfFile) => {
            const filePath = join(resolvedFolderPath, pdfFile)
            return {
              filePath,
              fileName: pdfFile,
            }
          })
        )

        await enqueue({
          topic: 'rag.process.pdfs',
          data: { files: filesInfo, streamId },
        })
      } catch (error) {
        logger.error(`Failed to read PDFs from folder: ${resolvedFolderPath}`, { error })
        throw error
      }
    }
    ```

  </Tab>
  <Tab value="process-pdfs">
    The heart of our document processing pipeline. This Python step uses Docling to intelligently parse and chunk PDFs, preserving document structure and context.

    ```python
    import json
    import os
    from pathlib import Path
    from typing import Any, Dict, List
    from docling.document_converter import DocumentConverter
    from docling.chunking import HybridChunker
    from docling.datamodel.base_models import InputFormat
    from docling.datamodel.pipeline_options import PdfPipelineOptions
    from docling.document_converter import PdfFormatOption

    def handler(input_data: Dict[str, Any], context: Dict[str, Any]) -> None:
        """Process PDFs using Docling with intelligent chunking"""
        logger = context['logger']
        enqueue = context['enqueue']
        
        files = input_data.get('files', [])
        stream_id = input_data.get('streamId')
        
        logger.info(f"Processing {len(files)} PDF files with Docling")
        
        # Configure Docling with optimized settings
        pipeline_options = PdfPipelineOptions(
            do_ocr=True,
            do_table_structure=True,
            table_structure_options={
                "do_cell_matching": True,
            }
        )
        
        doc_converter = DocumentConverter(
            format_options={
                InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)
            }
        )
        
        # Initialize the hybrid chunker for intelligent document segmentation
        chunker = HybridChunker(
            tokenizer="cl100k_base",
            max_tokens=512,
            overlap_tokens=50,
            heading_hierarchies=True,
            split_by_page=False
        )
        
        all_chunks = []
        
        for file_info in files:
            file_path = file_info['filePath']
            file_name = file_info['fileName']
            
            logger.info(f"Processing file: {file_name}")
            
            try:
                # Convert PDF to structured document
                result = doc_converter.convert(file_path)
                doc = result.document
                
                logger.info(f"Converted {file_name}: {len(doc.pages)} pages")
                
                # Apply intelligent chunking
                chunks = list(chunker.chunk(doc))
                logger.info(f"Generated {len(chunks)} chunks for {file_name}")
                
                # Prepare chunks for Weaviate
                for i, chunk in enumerate(chunks):
                    chunk_data = {
                        'text': chunk.text,
                        'title': file_name,
                        'source': file_path,
                        'page': getattr(chunk, 'page_no', i + 1),
                        'chunk_id': f"{file_name}_chunk_{i}"
                    }
                    all_chunks.append(chunk_data)
                    
            except Exception as e:
                logger.error(f"Error processing {file_name}: {str(e)}")
                continue
        
        logger.info(f"Total chunks generated: {len(all_chunks)}")
        
        if all_chunks:
            # Enqueue chunks for Weaviate ingestion
            enqueue({
                'topic': 'rag.load.weaviate',
                'data': {
                    'chunks': all_chunks,
                    'streamId': stream_id,
                    'totalFiles': len(files),
                    'totalChunks': len(all_chunks)
                }
            })
        else:
            logger.warning("No chunks generated from PDF processing")
    ```

  </Tab>
  <Tab value="load-weaviate">
    Efficiently batches and loads the processed document chunks into Weaviate with progress tracking and error handling.

    ```ts
    import weaviate from 'weaviate-client'
    import { type Handlers, type StepConfig } from 'motia'
    import { z } from 'zod'

    const ChunkSchema = z.object({
      text: z.string(),
      title: z.string(),
      source: z.string(),
      page: z.number(),
      chunk_id: z.string(),
    })

    export const config = {
      name: 'load-weaviate',
      description: 'Load document chunks into Weaviate',
      triggers: [
        { type: 'queue', topic: 'rag.load.weaviate', input: z.object({
          chunks: z.array(ChunkSchema),
          streamId: z.string().optional(),
          totalFiles: z.number().optional(),
          totalChunks: z.number().optional(),
        }) },
      ],
      enqueues: [],
      flows: ['rag-workflow'],
    } as const satisfies StepConfig

    export const handler: Handlers<typeof config> = async (input, { logger }) => {
      const { chunks, streamId, totalFiles, totalChunks } = input
      
      logger.info('Loading chunks into Weaviate', { 
        chunkCount: chunks.length,
        totalFiles,
        totalChunks,
        streamId 
      })

      const client = await weaviate.connectToWeaviateCloud(process.env.WEAVIATE_URL!, {
        authCredentials: new weaviate.ApiKey(process.env.WEAVIATE_API_KEY!),
        headers: { 'X-OpenAI-Api-Key': process.env.OPENAI_API_KEY! },
      })

      try {
        const collection = client.collections.get('Books')
        const BATCH_SIZE = 100

        // Process chunks in batches for optimal performance
        for (let i = 0; i < chunks.length; i += BATCH_SIZE) {
          const batch = chunks.slice(i, i + BATCH_SIZE)
          const batchNumber = Math.floor(i / BATCH_SIZE) + 1
          const totalBatches = Math.ceil(chunks.length / BATCH_SIZE)

          logger.info(`Inserting batch ${batchNumber}/${totalBatches}`, {
            batchSize: batch.length,
            streamId
          })

          const objects = batch.map(chunk => ({
            properties: {
              text: chunk.text,
              title: chunk.title,
              source: chunk.source,
              page: chunk.page,
            }
          }))

          const result = await collection.data.insertMany(objects)
          
          if (result.hasErrors) {
            logger.error('Batch insertion had errors', { 
              errors: result.errors,
              batchNumber,
              streamId 
            })
          } else {
            logger.info(`Successfully inserted batch ${batchNumber}/${totalBatches}`)
          }
        }

        logger.info('Successfully loaded all chunks into Weaviate', {
          totalChunks: chunks.length,
          streamId
        })

      } catch (error) {
        logger.error('Error loading chunks into Weaviate', { error, streamId })
        throw error
      } finally {
        await client.close()
      }
    }
    ```

  </Tab>
  <Tab value="api-query-rag">
    The query interface that performs semantic search and generates contextual answers using Weaviate's integrated OpenAI capabilities.

    ```ts
    import weaviate from 'weaviate-client'
    import { type Handlers, type StepConfig } from 'motia'
    import { z } from 'zod'

    const RAGResponse = z.object({
      answer: z.string(),
      chunks: z.array(z.object({
        text: z.string(),
        title: z.string(),
        source: z.string(),
        page: z.number(),
      })),
      query: z.string(),
      timestamp: z.string(),
    })

    export const config = {
      name: 'api-query-rag',
      description: 'Query the RAG system for answers',
      triggers: [
        { type: 'http', path: '/api/rag/query', method: 'POST', bodySchema: z.object({
          query: z.string().min(1, 'Query is required'),
          limit: z.number().min(1).max(10).default(3),
        }) },
      ],
      enqueues: [],
      flows: ['rag-workflow'],
    } as const satisfies StepConfig

    export const handler: Handlers<typeof config> = async (req, { logger }) => {
      const { query, limit = 3 } = req.body

      logger.info('Processing RAG query', { query, limit })

      const client = await weaviate.connectToWeaviateCloud(process.env.WEAVIATE_URL!, {
        authCredentials: new weaviate.ApiKey(process.env.WEAVIATE_API_KEY!),
        headers: { 'X-OpenAI-Api-Key': process.env.OPENAI_API_KEY! },
      })

      try {
        const collection = client.collections.get('Books')
        
        // Perform semantic search with AI generation
        const results = await collection.generate.nearText(
          query,
          { limit, distance: 0.6 },
          { 
            singlePrompt: `Answer this question based on the provided context: ${query}. 
                          Be specific and cite the sources when possible.` 
          }
        )

        // Extract the generated answer and source chunks
        const generatedAnswer = results.generated || 'No answer could be generated.'
        
        const chunks = results.objects.map(obj => ({
          text: obj.properties.text as string,
          title: obj.properties.title as string,
          source: obj.properties.source as string,
          page: obj.properties.page as number,
        }))

        const response = RAGResponse.parse({
          answer: generatedAnswer,
          chunks,
          query,
          timestamp: new Date().toISOString(),
        })

        logger.info('RAG query completed successfully', { 
          query, 
          chunksFound: chunks.length,
          answerLength: generatedAnswer.length 
        })

        return {
          status: 200,
          body: response,
        }

      } catch (error) {
        logger.error('Error processing RAG query', { error, query })
        return {
          status: 500,
          body: { error: 'Failed to process query' },
        }
      } finally {
        await client.close()
      }
    }
    ```

  </Tab>
</Tabs>

---

## Explore the Workflow

The [iii development console](https://iii.dev/docs) provides a visual representation of your RAG pipeline, making it easy to understand the flow and debug any issues.

<div className="my-8">![RAG Workflow](./../img/rag-example.gif)</div>

You can monitor real-time processing, view logs, and trace the execution of each step directly in the iii development console. This makes development and debugging significantly easier compared to traditional monolithic approaches.

---

## Key Features & Benefits

### 🚀 **Event-Driven Architecture**
Each step is independent and communicates through events, making the system highly scalable and maintainable.

### 🧠 **Intelligent Document Processing**  
Docling's hybrid chunking preserves document structure while creating optimal chunks for embedding.

### ⚡ **High-Performance Vector Search**
Weaviate's cloud-native architecture provides fast, scalable similarity search with built-in OpenAI integration.

### 🔄 **Real-Time Progress Tracking**
Monitor document processing progress with detailed logging and status updates.

### 🌐 **Polyglot Support**
Seamlessly combine Python (Docling) and TypeScript (orchestration) in a single workflow.

### 🛡️ **Production-Ready**
Built-in error handling, batch processing, and resource cleanup ensure reliability.

---

## Trying It Out

Ready to build your own intelligent document assistant? Let's get the system running.

<Steps>

### Install Dependencies

Install both Node.js and Python dependencies. The prepare script automatically sets up the Python virtual environment.

```shell
npm install
```

### Set Your Environment Variables

You'll need API keys for OpenAI and Weaviate Cloud. Create a `.env` file:

```shell
OPENAI_API_KEY="sk-..."
WEAVIATE_URL="https://your-cluster.weaviate.network"
WEAVIATE_API_KEY="your-weaviate-api-key"
```

### Run the Project

Start the Motia development server to begin processing documents.

```shell
npm run dev
```

### Process Your First Documents

Add some PDF files to the `docs/pdfs/` folder, then start the ingestion pipeline:

```shell
curl -X POST http://localhost:3111/api/rag/process-pdfs \
  -H "Content-Type: application/json" \
  -d '{"folderPath":"docs/pdfs"}'
```

Watch the logs as your documents are processed through the pipeline:
1. **PDF Reading**: Files are discovered and queued
2. **Docling Processing**: Intelligent chunking with structure preservation  
3. **Weaviate Loading**: Chunks are embedded and stored

### Query Your Knowledge Base

Once processing is complete, you can ask questions about your documents:

#### General Query
```shell
curl -X POST http://localhost:3111/api/rag/query \
  -H "Content-Type: application/json" \
  -d '{"query":"What are the main topics covered in these documents?","limit":3}'
```

#### Specific Question
```shell
curl -X POST http://localhost:3111/api/rag/query \
  -H "Content-Type: application/json" \
  -d '{"query":"What methodology was used in the research?","limit":5}'
```

The response includes both a generated answer and the source chunks with page numbers for verification.

</Steps>

---

## Advanced Usage

### Custom Chunking Strategies

Modify the Python processing step to implement custom chunking logic:

```python
# In process-pdfs.step.py
chunker = HybridChunker(
    tokenizer="cl100k_base",
    max_tokens=1024,  # Larger chunks for more context
    overlap_tokens=100,  # More overlap for better continuity
    heading_hierarchies=True,
    split_by_page=True  # Preserve page boundaries
)
```

### Batch Processing Optimization

Adjust batch sizes in the Weaviate loading step for optimal performance:

```ts
// In load-weaviate.step.ts
const BATCH_SIZE = 50  // Smaller batches for large documents
```

### Multi-Collection Support

Extend the system to handle different document types by creating separate Weaviate collections:

```ts
const COLLECTIONS = {
  research: 'ResearchPapers',
  manuals: 'TechnicalManuals', 
  reports: 'BusinessReports'
}
```

---

## Troubleshooting

### Common Issues

**ENOENT Path Errors**: The system automatically handles path normalization, but ensure your `folderPath` is relative to the project root.

**Empty Answers**: Check that documents were successfully processed by examining the logs. Verify your OpenAI API key is valid.

**Weaviate Connection Issues**: Ensure your `WEAVIATE_URL` and `WEAVIATE_API_KEY` are correct and your cluster is running.

### Performance Tips

- **Document Size**: For large PDFs, consider preprocessing to split them into smaller files
- **Batch Size**: Adjust the Weaviate batch size based on your cluster's capacity
- **Chunking Strategy**: Experiment with different chunk sizes and overlap for your specific use case

---

## 💻 Dive into the Code

Want to explore the complete RAG implementation? Check out the full source code, including all steps, configuration files, and setup instructions:

<div className="not-prose">
  <div className="bg-gradient-to-r from-purple-50 to-pink-50 border border-purple-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-purple-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Complete RAG Implementation</h3>
        <p className="text-gray-600 mb-4">Access the full source code for this RAG agent, including Python processing scripts, TypeScript orchestration, and production configuration.</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/rag-and-search/rag-fundamentals/rag-docling-weaviate-agent" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-purple-600 hover:bg-purple-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.30.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            View RAG Example
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            More Examples →
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Conclusion: The Future of Document Intelligence

This RAG system demonstrates the power of combining best-in-class technologies with Motia's event-driven architecture. By breaking down complex document processing into discrete, manageable steps, we've created a system that's not only powerful but also maintainable and scalable.

The polyglot nature of the solution: Python for document processing, TypeScript for orchestration, shows how Motia enables you to use the right tool for each job without sacrificing integration or maintainability.

From here, you can extend the system by:
- Adding support for other document formats (Word, PowerPoint, etc.)
- Implementing document classification and routing
- Adding real-time document updates and synchronization
- Building a web interface for document management
- Integrating with existing business systems

The event-driven architecture makes all of these extensions straightforward to implement without disrupting the existing pipeline.

Ready to transform your documents into intelligent, queryable knowledge bases? Start building with Motia today!


-   [sentiment-analysis](/docs/examples/sentiment-analysis): Documentation for sentiment-analysis.
---
title: 'Sentiment Analysis'
description: 'Dynamic Workflows: Building a Sentiment Analyzer with Motia'
---

In modern application development, workflows are rarely linear. Whether you're building a simple "prompt => response" system or a complex, multi-stage data processing pipeline, you often need your application to make decisions and route data dynamically. This is where the power of event-driven architecture shines, and where the Motia framework provides a clear path forward.

---

## Workflow Overview

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/foundational/api-patterns/sentimental-analysis)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

This guide explores how to build a dynamic sentiment analysis application that uses an LLM to determine how to proceed. We'll cover:

1.  **The Motia Philosophy**: How `steps` as a core primitive simplify complex architectures.
2.  **Building the Workflow**: A step-by-step guide to creating the four key components of our application.
3.  **Visualizing the Flow**: How events chain together to create a cohesive, dynamic system.
4.  **Hands-On with the API**: How to run and test your new sentiment analyzer.

Let's dive in.

---

## A Step at a Time

At the heart of the Motia framework is a simple but powerful idea: the **`step`**. A step is a self-contained, independent unit of logic that listens for an event, performs a task, and, optionally, enqueues a new event. This concept is the core primitive that allows you to break down even the most complex architectures into a series of simple, manageable components.

Instead of a monolithic application where business logic is tightly coupled, Motia encourages a decoupled, event-driven approach. This has several key advantages:

-   **Clarity**: Each step has a single responsibility, making the application easier to understand and reason about.
-   **Scalability**: Steps can be scaled independently, so you can allocate resources where they're needed most.
-   **Extensibility**: Adding new functionality is as simple as creating a new step and subscribing it to an existing event.
-   **Resilience**: The decoupled nature of steps means that a failure in one part of the system doesn't necessarily bring down the entire application.

In this project, we'll see this philosophy in action as we build a sentiment analyzer with four distinct steps, each with its own clear purpose.

---

## The Anatomy of Our Sentiment Analyzer

Our application will be composed of four steps. Let's explore each one.

<Folder name="steps" defaultOpen>
  <File name="analyzeSentimentApi.step.ts" />
  <File name="openAiAnalyzeSentiment.step.ts" />
  <File name="handlePositive.step.ts" />
  <File name="handleNegative.step.ts" />
</Folder>

<Tabs items={['analyzeSentimentApi', 'openAiAnalyzeSentiment', 'handlePositive', 'handleNegative']}>
  <Tab value="analyzeSentimentApi">
    This is the entry point to our workflow. It's a step with an HTTP trigger that listens for `POST` requests, validates the incoming data, and enqueues an `openai.analyzeSentimentRequest` event.

    ```ts
    // Receives user text, enqueues "openai.analyzeSentimentRequest".
    import { type Handlers, type StepConfig } from 'motia'
    import { z } from 'zod'

    export const config = {
      name: 'analyzeSentimentApi',
      description: 'Receives user text and enqueues an event to trigger sentiment analysis.',
      triggers: [
        { type: 'http', path: '/api/analyze-sentiment', method: 'POST', bodySchema: z.object({
          text: z.string().min(1, 'text is required'),
        }) },
      ],
      enqueues: ['openai.analyzeSentimentRequest'],
      flows: ['sentiment-demo'],
    } as const satisfies StepConfig

    export const handler: Handlers<typeof config> = async (req, { enqueue, logger }) => {
      const { text } = req.body

      logger.info('[AnalyzeSentimentAPI] Received text', { text })

      // Enqueue an event to call OpenAI
      await enqueue({
        topic: 'openai.analyzeSentimentRequest',
        data: { text },
      })

      // Return right away
      return {
        status: 200,
        body: { status: 'Accepted', message: 'Your text is being analyzed' },
      }
    }
    ```

  </Tab>
  <Tab value="openAiAnalyzeSentiment">
    This step is the brains of our operation. It listens for the `openai.analyzeSentimentRequest` topic via a queue trigger, calls the OpenAI API, and then based on the response, enqueues either a `openai.positiveSentiment` or `openai.negativeSentiment` event. This is where the dynamic routing happens.

    ```ts
    // Calls OpenAI, instructing it to ONLY return JSON like {"sentiment":"positive","analysis":"..."}
    import { type Handlers, type StepConfig } from 'motia'
    import { z } from 'zod'
    import { OpenAI } from 'openai'

    const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY })

    export const config = {
      name: 'openAiSentimentAnalyzer',
      description: 'Calls OpenAI to analyze sentiment and enqueues corresponding events.',
      triggers: [
        { type: 'queue', topic: 'openai.analyzeSentimentRequest', input: z.object({ text: z.string() }) },
      ],
      enqueues: ['openai.positiveSentiment', 'openai.negativeSentiment'],
      flows: ['sentiment-demo'],
    } as const satisfies StepConfig

    export const handler: Handlers<typeof config> = async (input, { enqueue, logger }) => {
      logger.info('[OpenAI Sentiment Analyzer] Prompting OpenAI...', { text: input.text })

      try {
        // We'll ask the model to ONLY return JSON with a "sentiment" field
        const systemPrompt =
          'You are an assistant that returns only JSON: {"sentiment":"positive|negative","analysis":"..."}'
        const userPrompt = `Analyze the sentiment of this text: "${input.text}". Return JSON with keys "sentiment" and "analysis".`

        // 4) Use the new openai syntax:
        const response = await openai.chat.completions.create({
          model: 'gpt-3.5-turbo',
          messages: [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: userPrompt },
          ],
        })

        // 5) Log and parse the response
        const content = response.choices[0]?.message?.content || ''
        logger.info('[OpenAI Sentiment Analyzer] Raw response', { content })

        let parsed: { sentiment?: string; analysis?: string } = {}
        try {
          parsed = JSON.parse(content.trim())
        } catch (err) {
          logger.error('[OpenAI Sentiment Analyzer] Unable to parse JSON', { error: err })
          // If it's not JSON, we bail or handle differently
          return
        }

        // 6) Decide how to route the event
        if (parsed.sentiment) {
          if (parsed.sentiment.toLowerCase() === 'positive') {
            await enqueue({
              topic: 'openai.positiveSentiment',
              data: { ...parsed, sentiment: parsed.sentiment },
            })
          } else {
            // default to negative
            await enqueue({
              topic: 'openai.negativeSentiment',
              data: { ...parsed, sentiment: parsed.sentiment },
            })
          }
        } else {
          logger.error('[OpenAI Sentiment Analyzer] Sentiment is missing from the parsed response', { parsed })
        }
      } catch (err) {
        if (err instanceof Error) {
          logger.error('[OpenAI Sentiment Analyzer] Error calling OpenAI', { error: err.message })
        } else {
          logger.error('[OpenAI Sentiment Analyzer] An unknown error occurred while calling OpenAI', { error: err })
        }
      }
    }
    ```
  </Tab>
  <Tab value="handlePositive">
    A specialized responder that listens for the `openai.positiveSentiment` event and logs a confirmation message. In a real-world application, this could trigger a Slack notification, send an email, or kick off another workflow.

    ```ts
    // Handles "openai.positiveSentiment"
    import { type Handlers, type StepConfig } from 'motia'
    import { z } from 'zod'

    export const config = {
      name: 'handlePositive',
      description: 'Handles positive sentiment responses.',
      triggers: [
        { type: 'queue', topic: 'openai.positiveSentiment', input: z.object({
          sentiment: z.string(),
          analysis: z.string().optional(),
        }) },
      ],
      enqueues: [],
      flows: ['sentiment-demo'],
    } as const satisfies StepConfig

    export const handler: Handlers<typeof config> = async (input, { logger }) => {
      logger.info('[Positive Responder] The sentiment is positive!', { analysis: input.analysis })
      // Maybe notify a Slack channel: "All good vibes here!"
    }
    ```

  </Tab>
  <Tab value="handleNegative">
    Similar to the positive handler, this step listens for the `openai.negativeSentiment` event. This is where you could implement logic to escalate a customer complaint, create a support ticket, or alert the on-call team.

    ```ts
    // Handles "openai.negativeSentiment"
    import { type Handlers, type StepConfig } from 'motia'
    import { z } from 'zod'

    export const config = {
      name: 'handleNegative',
      description: 'Handles negative or unknown sentiment responses.',
      triggers: [
        { type: 'queue', topic: 'openai.negativeSentiment', input: z.object({
          sentiment: z.string(),
          analysis: z.string().optional(),
        }) },
      ],
      enqueues: [],
      flows: ['sentiment-demo'],
    } as const satisfies StepConfig

    export const handler: Handlers<typeof config> = async (input, { logger }) => {
      logger.info('[Negative Responder] The sentiment is negative or unknown.', { analysis: input.analysis })
      // Could escalate to a service, or respond gently, etc.
    }
    ```

  </Tab>
</Tabs>

---

## Explore the Workflow

You can explore the workflow visually in the [iii development console](https://iii.dev/docs).

<div className="my-8">![Flow](./../img/sentimental-analyzer.png)</div>

You can also read your files and watch logs, traces, and debug your architecture directly in the console.

---

## Trying It Out

Ready to see it in action? Let's get the project running.

<Steps>

### Install Dependencies

First, install the necessary npm packages.

```shell
npm install
```

### Set Your Environment Variables

You'll need an OpenAI API key for this project. Export it as an environment variable.

```shell
export OPENAI_API_KEY="sk-..."
```

### Run the Project

Start the Motia development server.

```shell
npm run dev
```

### Test the API

Now you can send requests to your API and see the workflow in action.

#### Positive Sentiment

```shell
curl -X POST http://localhost:3111/api/analyze-sentiment \
  -H "Content-Type: application/json" \
  -d '{"text":"I absolutely love this new device! It is amazing and works perfectly."}'
```

Check your logs, and you should see the `[Positive Responder]` has been triggered.

#### Negative Sentiment

```shell
curl -X POST http://localhost:3111/api/analyze-sentiment \
  -H "Content-Type: application/json" \
  -d '{"text":"This is the worst product I have ever used. It broke after one day."}'
```

This time, the `[Negative Responder]` will fire.

</Steps>

---

## 💻 Dive into the Code

Want to explore the complete implementation? Check out the full source code and additional examples in our GitHub repository:

<div className="not-prose">
  <div className="bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-blue-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Explore More Examples</h3>
        <p className="text-gray-600 mb-4">Get hands-on with the complete source code, configuration files, and additional examples to accelerate your learning.</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/foundational/api-patterns/sentimental-analysis" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-blue-600 hover:bg-blue-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            View Sentiment Example
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            More Examples →
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Conclusion: The Power of a Simple Primitive

This sentiment analysis application is a powerful demonstration of the Motia philosophy. By embracing the `step` as a core primitive, we've turned a potentially complex, branching workflow into a series of simple, understandable, and scalable components.

This is just the beginning. From here, you can extend the application by adding new steps to handle neutral sentiment, send notifications, or store results in a database. The event-driven architecture of Motia makes it easy to add new functionality without disrupting the existing flow.

We encourage you to explore, experiment, and see for yourself how Motia can simplify your most complex backend challenges. Happy coding!


## Examples
[sentiment-analysis](/docs/examples/sentiment-analysis): Code example
---
title: 'Sentiment Analysis'
description: 'Dynamic Workflows: Building a Sentiment Analyzer with Motia'
---

In modern application development, workflows are rarely linear. Whether you're building a simple "prompt => response" system or a complex, multi-stage data processing pipeline, you often need your application to make decisions and route data dynamically. This is where the power of event-driven architecture shines, and where the Motia framework provides a clear path forward.

---

## Workflow Overview

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/foundational/api-patterns/sentimental-analysis)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

This guide explores how to build a dynamic sentiment analysis application that uses an LLM to determine how to proceed. We'll cover:

1.  **The Motia Philosophy**: How `steps` as a core primitive simplify complex architectures.
2.  **Building the Workflow**: A step-by-step guide to creating the four key components of our application.
3.  **Visualizing the Flow**: How events chain together to create a cohesive, dynamic system.
4.  **Hands-On with the API**: How to run and test your new sentiment analyzer.

Let's dive in.

---

## A Step at a Time

At the heart of the Motia framework is a simple but powerful idea: the **`step`**. A step is a self-contained, independent unit of logic that listens for an event, performs a task, and, optionally, enqueues a new event. This concept is the core primitive that allows you to break down even the most complex architectures into a series of simple, manageable components.

Instead of a monolithic application where business logic is tightly coupled, Motia encourages a decoupled, event-driven approach. This has several key advantages:

-   **Clarity**: Each step has a single responsibility, making the application easier to understand and reason about.
-   **Scalability**: Steps can be scaled independently, so you can allocate resources where they're needed most.
-   **Extensibility**: Adding new functionality is as simple as creating a new step and subscribing it to an existing event.
-   **Resilience**: The decoupled nature of steps means that a failure in one part of the system doesn't necessarily bring down the entire application.

In this project, we'll see this philosophy in action as we build a sentiment analyzer with four distinct steps, each with its own clear purpose.

---

## The Anatomy of Our Sentiment Analyzer

Our application will be composed of four steps. Let's explore each one.

<Folder name="steps" defaultOpen>
  <File name="analyzeSentimentApi.step.ts" />
  <File name="openAiAnalyzeSentiment.step.ts" />
  <File name="handlePositive.step.ts" />
  <File name="handleNegative.step.ts" />
</Folder>

<Tabs items={['analyzeSentimentApi', 'openAiAnalyzeSentiment', 'handlePositive', 'handleNegative']}>
  <Tab value="analyzeSentimentApi">
    This is the entry point to our workflow. It's a step with an HTTP trigger that listens for `POST` requests, validates the incoming data, and enqueues an `openai.analyzeSentimentRequest` event.

    ```ts
    // Receives user text, enqueues "openai.analyzeSentimentRequest".
    import { type Handlers, type StepConfig } from 'motia'
    import { z } from 'zod'

    export const config = {
      name: 'analyzeSentimentApi',
      description: 'Receives user text and enqueues an event to trigger sentiment analysis.',
      triggers: [
        { type: 'http', path: '/api/analyze-sentiment', method: 'POST', bodySchema: z.object({
          text: z.string().min(1, 'text is required'),
        }) },
      ],
      enqueues: ['openai.analyzeSentimentRequest'],
      flows: ['sentiment-demo'],
    } as const satisfies StepConfig

    export const handler: Handlers<typeof config> = async (req, { enqueue, logger }) => {
      const { text } = req.body

      logger.info('[AnalyzeSentimentAPI] Received text', { text })

      // Enqueue an event to call OpenAI
      await enqueue({
        topic: 'openai.analyzeSentimentRequest',
        data: { text },
      })

      // Return right away
      return {
        status: 200,
        body: { status: 'Accepted', message: 'Your text is being analyzed' },
      }
    }
    ```

  </Tab>
  <Tab value="openAiAnalyzeSentiment">
    This step is the brains of our operation. It listens for the `openai.analyzeSentimentRequest` topic via a queue trigger, calls the OpenAI API, and then based on the response, enqueues either a `openai.positiveSentiment` or `openai.negativeSentiment` event. This is where the dynamic routing happens.

    ```ts
    // Calls OpenAI, instructing it to ONLY return JSON like {"sentiment":"positive","analysis":"..."}
    import { type Handlers, type StepConfig } from 'motia'
    import { z } from 'zod'
    import { OpenAI } from 'openai'

    const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY })

    export const config = {
      name: 'openAiSentimentAnalyzer',
      description: 'Calls OpenAI to analyze sentiment and enqueues corresponding events.',
      triggers: [
        { type: 'queue', topic: 'openai.analyzeSentimentRequest', input: z.object({ text: z.string() }) },
      ],
      enqueues: ['openai.positiveSentiment', 'openai.negativeSentiment'],
      flows: ['sentiment-demo'],
    } as const satisfies StepConfig

    export const handler: Handlers<typeof config> = async (input, { enqueue, logger }) => {
      logger.info('[OpenAI Sentiment Analyzer] Prompting OpenAI...', { text: input.text })

      try {
        // We'll ask the model to ONLY return JSON with a "sentiment" field
        const systemPrompt =
          'You are an assistant that returns only JSON: {"sentiment":"positive|negative","analysis":"..."}'
        const userPrompt = `Analyze the sentiment of this text: "${input.text}". Return JSON with keys "sentiment" and "analysis".`

        // 4) Use the new openai syntax:
        const response = await openai.chat.completions.create({
          model: 'gpt-3.5-turbo',
          messages: [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: userPrompt },
          ],
        })

        // 5) Log and parse the response
        const content = response.choices[0]?.message?.content || ''
        logger.info('[OpenAI Sentiment Analyzer] Raw response', { content })

        let parsed: { sentiment?: string; analysis?: string } = {}
        try {
          parsed = JSON.parse(content.trim())
        } catch (err) {
          logger.error('[OpenAI Sentiment Analyzer] Unable to parse JSON', { error: err })
          // If it's not JSON, we bail or handle differently
          return
        }

        // 6) Decide how to route the event
        if (parsed.sentiment) {
          if (parsed.sentiment.toLowerCase() === 'positive') {
            await enqueue({
              topic: 'openai.positiveSentiment',
              data: { ...parsed, sentiment: parsed.sentiment },
            })
          } else {
            // default to negative
            await enqueue({
              topic: 'openai.negativeSentiment',
              data: { ...parsed, sentiment: parsed.sentiment },
            })
          }
        } else {
          logger.error('[OpenAI Sentiment Analyzer] Sentiment is missing from the parsed response', { parsed })
        }
      } catch (err) {
        if (err instanceof Error) {
          logger.error('[OpenAI Sentiment Analyzer] Error calling OpenAI', { error: err.message })
        } else {
          logger.error('[OpenAI Sentiment Analyzer] An unknown error occurred while calling OpenAI', { error: err })
        }
      }
    }
    ```
  </Tab>
  <Tab value="handlePositive">
    A specialized responder that listens for the `openai.positiveSentiment` event and logs a confirmation message. In a real-world application, this could trigger a Slack notification, send an email, or kick off another workflow.

    ```ts
    // Handles "openai.positiveSentiment"
    import { type Handlers, type StepConfig } from 'motia'
    import { z } from 'zod'

    export const config = {
      name: 'handlePositive',
      description: 'Handles positive sentiment responses.',
      triggers: [
        { type: 'queue', topic: 'openai.positiveSentiment', input: z.object({
          sentiment: z.string(),
          analysis: z.string().optional(),
        }) },
      ],
      enqueues: [],
      flows: ['sentiment-demo'],
    } as const satisfies StepConfig

    export const handler: Handlers<typeof config> = async (input, { logger }) => {
      logger.info('[Positive Responder] The sentiment is positive!', { analysis: input.analysis })
      // Maybe notify a Slack channel: "All good vibes here!"
    }
    ```

  </Tab>
  <Tab value="handleNegative">
    Similar to the positive handler, this step listens for the `openai.negativeSentiment` event. This is where you could implement logic to escalate a customer complaint, create a support ticket, or alert the on-call team.

    ```ts
    // Handles "openai.negativeSentiment"
    import { type Handlers, type StepConfig } from 'motia'
    import { z } from 'zod'

    export const config = {
      name: 'handleNegative',
      description: 'Handles negative or unknown sentiment responses.',
      triggers: [
        { type: 'queue', topic: 'openai.negativeSentiment', input: z.object({
          sentiment: z.string(),
          analysis: z.string().optional(),
        }) },
      ],
      enqueues: [],
      flows: ['sentiment-demo'],
    } as const satisfies StepConfig

    export const handler: Handlers<typeof config> = async (input, { logger }) => {
      logger.info('[Negative Responder] The sentiment is negative or unknown.', { analysis: input.analysis })
      // Could escalate to a service, or respond gently, etc.
    }
    ```

  </Tab>
</Tabs>

---

## Explore the Workflow

You can explore the workflow visually in the [iii development console](https://iii.dev/docs).

<div className="my-8">![Flow](./../img/sentimental-analyzer.png)</div>

You can also read your files and watch logs, traces, and debug your architecture directly in the console.

---

## Trying It Out

Ready to see it in action? Let's get the project running.

<Steps>

### Install Dependencies

First, install the necessary npm packages.

```shell
npm install
```

### Set Your Environment Variables

You'll need an OpenAI API key for this project. Export it as an environment variable.

```shell
export OPENAI_API_KEY="sk-..."
```

### Run the Project

Start the Motia development server.

```shell
npm run dev
```

### Test the API

Now you can send requests to your API and see the workflow in action.

#### Positive Sentiment

```shell
curl -X POST http://localhost:3111/api/analyze-sentiment \
  -H "Content-Type: application/json" \
  -d '{"text":"I absolutely love this new device! It is amazing and works perfectly."}'
```

Check your logs, and you should see the `[Positive Responder]` has been triggered.

#### Negative Sentiment

```shell
curl -X POST http://localhost:3111/api/analyze-sentiment \
  -H "Content-Type: application/json" \
  -d '{"text":"This is the worst product I have ever used. It broke after one day."}'
```

This time, the `[Negative Responder]` will fire.

</Steps>

---

## 💻 Dive into the Code

Want to explore the complete implementation? Check out the full source code and additional examples in our GitHub repository:

<div className="not-prose">
  <div className="bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-blue-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Explore More Examples</h3>
        <p className="text-gray-600 mb-4">Get hands-on with the complete source code, configuration files, and additional examples to accelerate your learning.</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/foundational/api-patterns/sentimental-analysis" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-blue-600 hover:bg-blue-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            View Sentiment Example
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            More Examples →
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Conclusion: The Power of a Simple Primitive

This sentiment analysis application is a powerful demonstration of the Motia philosophy. By embracing the `step` as a core primitive, we've turned a potentially complex, branching workflow into a series of simple, understandable, and scalable components.

This is just the beginning. From here, you can extend the application by adding new steps to handle neutral sentiment, send notifications, or store results in a database. The event-driven architecture of Motia makes it easy to add new functionality without disrupting the existing flow.

We encourage you to explore, experiment, and see for yourself how Motia can simplify your most complex backend challenges. Happy coding!

-   [trello-automation](/docs/examples/trello-automation): Documentation for trello-automation.
---
title: 'Trello Automation'
description: Build an automated card progression system for Trello boards with AI-powered summaries
---

---

## Workflow Overview

<div className="my-8">![Trello Automation](./../img/trello.png)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/integrations/communication/trello-flow)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## Let's build a Trello automation system that:

1. Automatically progresses cards across board lists
2. Validates card completeness
3. Generates AI-powered summaries for code review
4. Integrates with Slack for notifications
5. Monitors due dates and sends overdue alerts

## Board Structure

The Trello board is organized into four main lists:

- **New Cards**: Entry point for all new cards
- **In Progress**: Active development stage
- **Needs Review**: Code review stage with AI summaries
- **Completed**: Successfully reviewed and approved cards

## The Steps

<Folder name="steps" defaultOpen>
  <File name="trello-webhook.step.ts" />
  <File name="trello-webhook-validation.step.ts" />
  <File name="validate-card-requirements.step.ts" />
  <File name="start-assigned-card.step.ts" />
  <File name="mark-card-for-review.step.ts" />
  <File name="complete-approved-card.step.ts" />
  <File name="check-overdue-cards.step.ts" />
  <File name="slack-notifier.step.ts" />
</Folder>

<Callout type="info">
This example uses the `steps/` directory, but you can also use `src/` or both. Motia discovers step files from either location automatically.
</Callout>

View the source code for each step in the [GitHub repository](https://github.com/MotiaDev/motia-examples/tree/main/examples/integrations/communication/trello-flow).

## Visual Overview

Here's how the automation flow works:

<div className="my-8">![Flow: Trello Automation Steps](./../img/trello.png)</div>

1. **Card Validation** → Checks for required information
2. **Progress Tracking** → Moves cards between lists
3. **Review Process** → Generates AI summaries and notifies reviewers
4. **Completion Handling** → Processes approved cards

## Try It Out

<Steps>

### Prerequisites

Make sure you have:

- Trello account with API access
- Node.js installed
- Slack workspace (for notifications)
- OpenAI API key (for AI summaries)

### Clone the Repository

```bash
git clone git@github.com:MotiaDev/motia-examples.git
cd examples/trello-flow
```

### Install Dependencies

```bash
pnpm install
```

### Configure Environment Variables

Create a `.env` file by copying the example:

```bash
cp .env.example .env
```

Update your `.env` with the following credentials:

```bash
TRELLO_API_KEY=your_trello_api_key
TRELLO_TOKEN=your_trello_token

OPENAI_API_KEY=your_openai_api_key
OPENAI_MODEL=your_openai_model

SLACK_WEBHOOK_URL=your_slack_webhook_url

TRELLO_NEW_TASKS_LIST_ID=your_new_tasks_list_id
TRELLO_IN_PROGRESS_LIST_ID=your_in_progress_list_id
TRELLO_NEEDS_REVIEW_LIST_ID=your_needs_review_list_id
TRELLO_COMPLETED_LIST_ID=your_completed_list_id
```

### Set Up Trello Board

1. Create a new Trello board with these lists:

   - New Tasks
   - In Progress
   - Needs Review
   - Completed

2. Add a custom field:
   - Status (dropdown: Todo, In Progress, Done)

### Run the Application

```bash
pnpm dev
```

### Test the Flow

1. Create a new card in the "New Tasks" list
2. Assign a member to see it move to "In Progress"
3. Add an "approved" comment to see it move to "Completed"
4. Check Slack for notifications

</Steps>

<Callout type="info">
  For more detailed setup instructions and configuration options, check out the [full
  documentation](https://github.com/MotiaDev/motia-examples/tree/main/examples/integrations/communication/trello-flow).
</Callout>{' '}



## Examples
[trello-automation](/docs/examples/trello-automation): Code example
---
title: 'Trello Automation'
description: Build an automated card progression system for Trello boards with AI-powered summaries
---

---

## Workflow Overview

<div className="my-8">![Trello Automation](./../img/trello.png)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/integrations/communication/trello-flow)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## Let's build a Trello automation system that:

1. Automatically progresses cards across board lists
2. Validates card completeness
3. Generates AI-powered summaries for code review
4. Integrates with Slack for notifications
5. Monitors due dates and sends overdue alerts

## Board Structure

The Trello board is organized into four main lists:

- **New Cards**: Entry point for all new cards
- **In Progress**: Active development stage
- **Needs Review**: Code review stage with AI summaries
- **Completed**: Successfully reviewed and approved cards

## The Steps

<Folder name="steps" defaultOpen>
  <File name="trello-webhook.step.ts" />
  <File name="trello-webhook-validation.step.ts" />
  <File name="validate-card-requirements.step.ts" />
  <File name="start-assigned-card.step.ts" />
  <File name="mark-card-for-review.step.ts" />
  <File name="complete-approved-card.step.ts" />
  <File name="check-overdue-cards.step.ts" />
  <File name="slack-notifier.step.ts" />
</Folder>

<Callout type="info">
This example uses the `steps/` directory, but you can also use `src/` or both. Motia discovers step files from either location automatically.
</Callout>

View the source code for each step in the [GitHub repository](https://github.com/MotiaDev/motia-examples/tree/main/examples/integrations/communication/trello-flow).

## Visual Overview

Here's how the automation flow works:

<div className="my-8">![Flow: Trello Automation Steps](./../img/trello.png)</div>

1. **Card Validation** → Checks for required information
2. **Progress Tracking** → Moves cards between lists
3. **Review Process** → Generates AI summaries and notifies reviewers
4. **Completion Handling** → Processes approved cards

## Try It Out

<Steps>

### Prerequisites

Make sure you have:

- Trello account with API access
- Node.js installed
- Slack workspace (for notifications)
- OpenAI API key (for AI summaries)

### Clone the Repository

```bash
git clone git@github.com:MotiaDev/motia-examples.git
cd examples/trello-flow
```

### Install Dependencies

```bash
pnpm install
```

### Configure Environment Variables

Create a `.env` file by copying the example:

```bash
cp .env.example .env
```

Update your `.env` with the following credentials:

```bash
TRELLO_API_KEY=your_trello_api_key
TRELLO_TOKEN=your_trello_token

OPENAI_API_KEY=your_openai_api_key
OPENAI_MODEL=your_openai_model

SLACK_WEBHOOK_URL=your_slack_webhook_url

TRELLO_NEW_TASKS_LIST_ID=your_new_tasks_list_id
TRELLO_IN_PROGRESS_LIST_ID=your_in_progress_list_id
TRELLO_NEEDS_REVIEW_LIST_ID=your_needs_review_list_id
TRELLO_COMPLETED_LIST_ID=your_completed_list_id
```

### Set Up Trello Board

1. Create a new Trello board with these lists:

   - New Tasks
   - In Progress
   - Needs Review
   - Completed

2. Add a custom field:
   - Status (dropdown: Todo, In Progress, Done)

### Run the Application

```bash
pnpm dev
```

### Test the Flow

1. Create a new card in the "New Tasks" list
2. Assign a member to see it move to "In Progress"
3. Add an "approved" comment to see it move to "Completed"
4. Check Slack for notifications

</Steps>

<Callout type="info">
  For more detailed setup instructions and configuration options, check out the [full
  documentation](https://github.com/MotiaDev/motia-examples/tree/main/examples/integrations/communication/trello-flow).
</Callout>{' '}


-   [uptime-discord-monitor](/docs/examples/uptime-discord-monitor): Documentation for uptime-discord-monitor.
---
title: 'Uptime Monitor'
description: 'Real-Time Uptime Monitoring: Building a Resilient Website Monitor with Motia'
---

In today's modern era, website uptime is critical for business success. Whether you're monitoring a personal blog or enterprise applications, you need a reliable system that can detect outages, send alerts, and provide visibility into your site's health. Traditional monitoring solutions often involve complex infrastructure and vendor lock-in, but there's a better way.

This comprehensive guide explores how to build a production-ready uptime monitoring system using Motia's event-driven architecture. We'll cover:

1.  **Event-Driven Monitoring**: How Motia's `steps` create a scalable, maintainable monitoring pipeline.
2.  **Building the Architecture**: A detailed walkthrough of our five-component monitoring system.
3.  **Smart Alerting**: Implementing rate limiting and status change detection to prevent spam.

Let's build a monitoring system that actually works for you.

---

## Workflow Overview

<div className="my-8">![Uptime Monitor](./../img/uptime-monitor-architecture.png)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/foundational/infrastructure/motia-uptime-monitor)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## The Power of Event-Driven Monitoring

<div className="my-8">![Uptime Monitor Architecture](./../img/uptime-monitor.gif)</div>

At its core, our uptime monitoring system solves a fundamental challenge: how do you continuously monitor multiple websites without creating a brittle, monolithic application? Traditional monitoring tools often suffer from tight coupling, making them difficult to scale and customize. Our Motia-powered solution breaks this down into discrete, event-driven components that each handle a specific aspect of monitoring.

The magic happens through the integration of proven technologies and patterns:

-   **[Cron-Based Scheduling](https://en.wikipedia.org/wiki/Cron)**: Configurable check intervals using familiar cron expressions
-   **[Discord Webhooks](https://discord.com/developers/docs/resources/webhook)**: Instant notifications with rich formatting
-   **[Token Bucket Rate Limiting](https://en.wikipedia.org/wiki/Token_bucket)**: Intelligent alert throttling to prevent spam
-   **[Motia Framework](https://motia.dev)**: Event-driven orchestration with built-in observability

Instead of a monolithic monitoring daemon, we get a resilient architecture where each component can be scaled, modified, or replaced independently.

---

## The Anatomy of Our Monitoring System

Our application consists of five specialized steps, each handling a specific part of the monitoring workflow. Let's explore the complete architecture.

<Folder name="steps" defaultOpen>
  <File name="cron.step.js" />
  <File name="checker.step.js" />
  <File name="alerter.step.js" />
  <File name="health.step.js" />
</Folder>

<Folder name="lib" defaultOpen>
  <File name="env.js" />
  <File name="rate-limiter.js" />
  <File name="streams.js" />
</Folder>

<Tabs items={['cron', 'checker', 'alerter', 'health', 'utilities']}>
  <Tab value="cron">
    The heartbeat of our monitoring system. This cron-triggered step periodically enqueues check requests for all configured websites, acting as the central scheduler.

    ```js
    import { config as envConfig } from '../lib/env.js';
    import { cron } from 'motia'

    export const config = {
      name: 'UptimeCronTrigger',
      triggers: [
        cron(envConfig.cron),
      ],
      enqueues: ['check.requested'],
      flows: ['uptime-monitoring']
    };

    export async function handler(context) {
      context.logger.info(`Starting uptime checks for ${envConfig.sites.length} sites`);
      context.logger.info(`Sites configured: ${JSON.stringify(envConfig.sites)}`);

      try {
        for (const url of envConfig.sites) {
          context.logger.info(`Scheduling check for: ${url}`);

          await context.enqueue({
            topic: 'check.requested',
            data: { url: url }
          });

          context.logger.info(`Successfully enqueued for: ${url}`);
        }

        context.logger.info(`Successfully scheduled checks for all ${envConfig.sites.length} sites`);
      } catch (error) {
        context.logger.error('Error during cron execution:', error);
        throw error;
      }
    }
    ```

  </Tab>
  <Tab value="checker">
    The core monitoring component that performs HTTP checks on websites. It handles timeouts, errors, and response code analysis, then enqueues results for further processing.

    ```js
    import { z } from 'zod'

    export const config = {
      name: 'WebsiteChecker',
      description: 'Performs HTTP checks on websites and enqueues results',
      triggers: [
        { type: 'queue', topic: 'check.requested', input: z.object({
          url: z.string().url('Must be a valid URL')
        }) },
      ],
      enqueues: ['check.result', 'status.stream'],
      flows: ['uptime-monitoring'],
    }

    export const handler = async (input, { logger, enqueue }) => {
      const { url } = input
      
      logger.info('Starting website check', { url })

      const startTime = performance.now()
      let result

      try {
        // Validate URL format before making request
        const urlObj = new URL(url)
        if (!['http:', 'https:'].includes(urlObj.protocol)) {
          throw new Error('Only HTTP and HTTPS protocols are supported')
        }

        // Perform HTTP request with timeout handling
        const controller = new AbortController()
        const timeoutId = setTimeout(() => controller.abort(), 10000) // 10 second timeout

        const response = await fetch(url, {
          method: 'GET',
          signal: controller.signal,
          headers: {
            'User-Agent': 'Motia-Uptime-Monitor/1.0',
            'Accept': '*/*',
            'Cache-Control': 'no-cache'
          },
          redirect: 'manual'
        })

        clearTimeout(timeoutId)
        const endTime = performance.now()
        const responseTime = Math.round(endTime - startTime)

        // Determine status: 2xx and 3xx as UP, everything else as DOWN
        const status = (response.status >= 200 && response.status < 400) ? 'UP' : 'DOWN'

        result = {
          url,
          status,
          code: response.status,
          responseTime,
          checkedAt: new Date().toISOString(),
          error: null
        }

        logger.info('Website check completed', {
          url,
          status,
          code: response.status,
          responseTime
        })

      } catch (error) {
        const endTime = performance.now()
        const responseTime = Math.round(endTime - startTime)

        let errorMessage = error.message

        // Handle specific error types with detailed messages
        if (error.name === 'AbortError') {
          errorMessage = 'Request timeout (10s)'
        } else if (error.name === 'TypeError' && error.message.includes('fetch')) {
          errorMessage = 'Network error - unable to connect'
        } else if (error.code === 'ENOTFOUND') {
          errorMessage = 'DNS resolution failed'
        } else if (error.code === 'ECONNREFUSED') {
          errorMessage = 'Connection refused'
        }

        result = {
          url,
          status: 'DOWN',
          code: null,
          responseTime,
          checkedAt: new Date().toISOString(),
          error: errorMessage
        }

        logger.error('Website check failed', {
          url,
          error: errorMessage,
          responseTime,
          originalError: error.code || error.name
        })
      }

      await enqueue({ topic: 'check.result', data: result })
      await enqueue({ topic: 'status.stream', data: result })

      logger.info('Check results enqueued successfully', { url, status: result.status })
    }
    ```

  </Tab>
  <Tab value="alerter">
    The intelligent alerting system that detects status changes, applies rate limiting, and sends Discord notifications. Only triggers alerts when status actually changes, preventing noise.

    ```js
    import { z } from 'zod'
    import { getPreviousStatus } from '../lib/streams.js'
    import { createRateLimiter } from '../lib/rate-limiter.js'
    import { config as envConfig } from '../lib/env.js'

    // Create a rate limiter instance for Discord alerts
    const rateLimiter = createRateLimiter({
      burst: envConfig.alertBurst,
      windowSec: envConfig.alertWindowSec
    })

    export const config = {
      name: 'DiscordAlerter',
      description: 'Sends Discord notifications when website status changes',
      triggers: [
        { type: 'queue', topic: 'check.result', input: z.object({
          url: z.string().url(),
          status: z.enum(['UP', 'DOWN']),
          code: z.number().nullable(),
          responseTime: z.number(),
          checkedAt: z.string(),
          error: z.string().nullable()
        }) },
      ],
      enqueues: [],
      flows: ['uptime-monitoring'],
    }

    function createDiscordMessage(result, previousStatus) {
      const { url, status, code, responseTime, checkedAt, error } = result

      const isUp = status === 'UP'
      const emoji = isUp ? '🟢' : '🔴'
      const color = isUp ? 0x00ff00 : 0xff0000

      const content = `${emoji} ${url} is ${status}${code ? ` (${code})` : ''}`

      const fields = [
        {
          name: 'Response Time',
          value: `${responseTime}ms`,
          inline: true
        }
      ]

      if (code !== null) {
        fields.push({
          name: 'Status Code',
          value: code.toString(),
          inline: true
        })
      }

      if (error) {
        fields.push({
          name: 'Error',
          value: error,
          inline: false
        })
      }

      fields.push({
        name: 'Previous Status',
        value: previousStatus,
        inline: true
      })

      return {
        content,
        embeds: [{
          title: `Website Status Change: ${status}`,
          description: `${url} changed from ${previousStatus} to ${status}`,
          color,
          timestamp: checkedAt,
          fields
        }]
      }
    }

    export const handler = async (input, { logger }) => {
      const { url, status } = input

      // Get the previous status for comparison
      const previousResult = getPreviousStatus(url)

      // Handle first-time checks
      if (!previousResult) {
        logger.info('First-time check for site, no alert needed', { url, status })
        const { updateLastStatus } = await import('../lib/streams.js')
        updateLastStatus(input)
        return
      }

      const previousStatus = previousResult.status

      // Only trigger alerts when status actually changes
      if (status === previousStatus) {
        logger.debug('Status unchanged, no alert needed', { url, status, previousStatus })
        const { updateLastStatus } = await import('../lib/streams.js')
        updateLastStatus(input)
        return
      }

      // Status has changed - check rate limiting
      logger.info('Status change detected', {
        url,
        previousStatus,
        newStatus: status,
        transition: `${previousStatus} → ${status}`
      })

      if (!rateLimiter.consume(url)) {
        const timeUntilNext = rateLimiter.getTimeUntilNextToken(url)
        logger.warn('Alert rate limited', {
          url,
          status,
          previousStatus,
          timeUntilNextMs: timeUntilNext,
          tokensRemaining: rateLimiter.getTokenCount(url)
        })
        return
      }

      // Send Discord notification
      const message = createDiscordMessage(input, previousStatus)
      
      try {
        const response = await fetch(envConfig.discordWebhook, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'User-Agent': 'Motia-Uptime-Monitor/1.0'
          },
          body: JSON.stringify(message)
        })

        if (response.ok) {
          logger.info('Discord alert sent successfully', { url, status, previousStatus })
        } else {
          const errorText = await response.text().catch(() => 'Unknown error')
          logger.error('Discord webhook failed', {
            status: response.status,
            error: errorText
          })
        }
      } catch (error) {
        logger.error('Failed to send Discord webhook', {
          error: error.message
        })
      }

      // Update status store after sending alert
      const { updateLastStatus } = await import('../lib/streams.js')
      updateLastStatus(input)
    }
    ```

  </Tab>
  <Tab value="health">
    A health check endpoint that provides system status and monitoring metrics. Essential for monitoring the monitor itself and integrating with external health check services.

    ```js
    import { z } from 'zod'
    import { getSnapshot } from '../lib/streams.js'
    import { config as envConfig } from '../lib/env.js'

    export const config = {
      name: 'HealthCheck',
      description: 'Provides system health status endpoint',
      triggers: [
        { type: 'http', method: 'GET', path: '/healthz' },
      ],
      enqueues: [],
      responseSchema: {
        200: z.object({
          status: z.literal('ok'),
          sitesConfigured: z.number(),
          lastKnown: z.record(z.any()),
          now: z.string()
        })
      },
      flows: ['uptime-monitoring'],
    }

    export const handler = async (_, { logger }) => {
      logger.info('Health check endpoint accessed')
      
      try {
        const now = new Date().toISOString()
        const sitesConfigured = envConfig.sites.length
        const lastKnown = getSnapshot()
        
        const response = {
          status: 'ok',
          sitesConfigured,
          lastKnown,
          now
        }
        
        logger.info('Health check completed successfully', { 
          sitesConfigured,
          sitesWithStatus: Object.keys(lastKnown).length
        })
        
        return {
          status: 200,
          body: response
        }
        
      } catch (error) {
        logger.error('Health check failed', { 
          error: error.message,
          stack: error.stack
        })
        
        return {
          status: 200,
          body: {
            status: 'ok',
            sitesConfigured: 0,
            lastKnown: {},
            now: new Date().toISOString(),
            error: error.message
          }
        }
      }
    }
    ```

  </Tab>
  <Tab value="utilities">
    Three essential utility libraries that power the monitoring system: environment validation, rate limiting, and persistent status storage.

    **Environment Configuration (`lib/env.js`)**
    ```js
    // Validates Discord webhook URLs
    function isValidDiscordWebhook(url) {
      if (!url || typeof url !== 'string') return false;
      
      try {
        const parsed = new URL(url);
        return parsed.hostname === 'discord.com' || parsed.hostname === 'discordapp.com';
      } catch {
        return false;
      }
    }

    // Parses and validates the SITES environment variable
    function parseSites(sitesJson) {
      if (!sitesJson) {
        throw new Error('SITES environment variable is required');
      }

      let sites;
      try {
        sites = JSON.parse(sitesJson);
      } catch (error) {
        throw new Error(`Invalid SITES JSON format: ${error.message}`);
      }

      if (!Array.isArray(sites) || sites.length === 0) {
        throw new Error('SITES must be a non-empty JSON array of URLs');
      }

      // Validate each URL
      sites.forEach(site => {
        if (typeof site !== 'string') {
          throw new Error(`Invalid site URL: ${site} (must be string)`);
        }
        try {
          new URL(site);
        } catch {
          throw new Error(`Invalid site URL format: ${site}`);
        }
      });

      return sites;
    }

    export const config = {
      discordWebhook: process.env.DISCORD_WEBHOOK,
      sites: parseSites(process.env.SITES),
      cron: process.env.CHECK_INTERVAL_CRON || '0 */1 * * * * *',
      alertBurst: parseInt(process.env.ALERT_BURST) || 3,
      alertWindowSec: parseInt(process.env.ALERT_WINDOW_SEC) || 300
    };
    ```

    **Rate Limiter (`lib/rate-limiter.js`)**
    ```js
    // Token bucket rate limiter with per-site isolation
    export function createRateLimiter({ burst, windowSec }) {
      const buckets = new Map()
      const refillRate = burst / (windowSec * 1000)

      function consume(siteUrl) {
        const bucket = getBucket(siteUrl)
        refillBucket(bucket)
        
        if (bucket.tokens >= 1) {
          bucket.tokens -= 1
          return true
        }
        
        return false
      }

      function getBucket(siteUrl) {
        if (!buckets.has(siteUrl)) {
          buckets.set(siteUrl, {
            tokens: burst,
            lastRefill: Date.now()
          })
        }
        return buckets.get(siteUrl)
      }

      function refillBucket(bucket) {
        const now = Date.now()
        const timePassed = now - bucket.lastRefill
        
        if (timePassed > 0) {
          const tokensToAdd = timePassed * refillRate
          bucket.tokens = Math.min(burst, bucket.tokens + tokensToAdd)
          bucket.lastRefill = now
        }
      }

      return { consume, /* other methods */ }
    }
    ```

    **Status Storage (`lib/streams.js`)**
    ```js
    // File-based persistent storage for site status
    import { readFileSync, writeFileSync, existsSync } from 'fs'

    const STORE_FILE = join(process.cwd(), '.motia', 'status-store.json')

    export function updateLastStatus(result) {
      // Validate input
      if (!result?.url || !['UP', 'DOWN'].includes(result.status)) {
        throw new Error('Invalid result object')
      }

      const store = loadStatusStore()
      store[result.url] = { ...result }
      saveStatusStore(store)
    }

    export function getPreviousStatus(url) {
      const store = loadStatusStore()
      const result = store[url]
      return result ? { ...result } : null
    }

    export function getSnapshot() {
      const store = loadStatusStore()
      const snapshot = {}
      
      for (const [url, result] of Object.entries(store)) {
        snapshot[url] = { ...result }
      }
      
      return snapshot
    }
    ```

  </Tab>
</Tabs>

---

## Explore the Workflow

The [iii development console](https://iii.dev/docs) provides a visual representation of your monitoring pipeline, making it easy to understand the event flow and debug issues in real-time.

<div className="my-8">![Uptime Monitor workflow](./../img/uptime-monitor.gif)</div>

You can monitor real-time status checks, view Discord alert logs, and trace the execution of each step directly in the iii development console. This makes development and debugging significantly easier compared to traditional monitoring solutions.

---

## Key Features & Benefits

### ⚡ **Event-Driven Architecture**
Each component is independent and communicates through events, making the system highly scalable and maintainable.

### 🎯 **Smart Status Detection**  
Only triggers alerts when status actually changes (UP ↔ DOWN), eliminating noise from temporary fluctuations.

### 🚨 **Intelligent Rate Limiting**
Token bucket algorithm prevents alert spam during site flapping while ensuring critical alerts get through.

### 📊 **Built-in Observability**
Comprehensive logging, health checks, and real-time status tracking with persistent storage.

### 🔧 **Production-Ready**
Robust error handling, timeout management, and configurable check intervals ensure reliability.

### 🎨 **Rich Discord Alerts**
Beautiful embedded messages with response times, error details, and status transitions.

---

## Data Flow & Event Architecture

![Uptime Monitor Event Flow](./../img/uptime-monitor-flow.png)

### Event Flow
1. **Cron Trigger** → Enqueues `check.requested` events for each configured site
2. **Website Checker** → Receives `check.requested`, performs HTTP check
3. **Status Update** → Checker enqueues `check.result` with result
4. **Alert Processing** → Alerter receives `check.result`, detects status changes
5. **Discord Notification** → Alerter sends webhook if status changed and rate limit allows
6. **Status Storage** → Status is persisted for health endpoint and future comparisons

---

## Trying It Out

Ready to build your own production-ready monitoring system? Let's get it running.

<Steps>

### Install Dependencies

Install the necessary npm packages and set up the development environment.

```shell
npm install
```

### Configure Environment Variables

Create a `.env` file with your monitoring configuration. You'll need a Discord webhook URL and the sites you want to monitor.

```shell
# Required: Discord webhook for alerts
DISCORD_WEBHOOK="https://discord.com/api/webhooks/123456789/your-webhook-token"

# Required: JSON array of URLs to monitor
SITES='["https://example.com", "https://api.yourdomain.com", "https://blog.yoursite.org"]'

# Optional: Check frequency (default: every minute)
CHECK_INTERVAL_CRON="0 */1 * * * * *"

# Optional: Rate limiting (default: 3 alerts per 5 minutes)
ALERT_BURST="3"
ALERT_WINDOW_SEC="300"
```

### Set Up Discord Webhook

Create a Discord webhook to receive alerts:

1. Go to your Discord server settings
2. Navigate to **Integrations** → **Webhooks**
3. Click **New Webhook**
4. Copy the webhook URL and add it to your `.env` file

### Run the Monitoring System

Start the Motia development server to begin monitoring your websites.

```shell
npm run dev
```

### Check System Health

Verify your monitoring system is working correctly:

```shell
curl http://localhost:3111/healthz
```

You should see a response with your configured sites and their current status:

```json
{
  "status": "ok",
  "sitesConfigured": 3,
  "lastKnown": {
    "https://example.com": {
      "url": "https://example.com",
      "status": "UP",
      "code": 200,
      "responseTime": 245,
      "checkedAt": "2024-01-15T10:30:00.000Z",
      "error": null
    }
  },
  "now": "2024-01-15T10:35:00.000Z"
}
```

### Monitor the Logs

Watch the logs to see your monitoring system in action:

- **Cron triggers**: Check scheduling for all configured sites
- **Website checks**: HTTP requests and response analysis  
- **Status changes**: UP/DOWN transitions and Discord alerts
- **Rate limiting**: Alert suppression during site flapping

</Steps>

---

## Advanced Configuration

### Custom Check Intervals

Modify the cron expression to change monitoring frequency:

```shell
# Every 5 minutes
CHECK_INTERVAL_CRON="0 */5 * * * * *"

# Every hour
CHECK_INTERVAL_CRON="0 0 * * * * *"

# Every 6 hours
CHECK_INTERVAL_CRON="0 0 */6 * * * *"

# Business hours only (9 AM - 5 PM, Mon-Fri)
CHECK_INTERVAL_CRON="0 * 9-17 * * 1-5 *"
```

### Alert Rate Limiting

Fine-tune the rate limiting to match your needs:

```shell
# Very strict: 1 alert per 10 minutes
ALERT_BURST="1"
ALERT_WINDOW_SEC="600"

# More permissive: 5 alerts per 2 minutes
ALERT_BURST="5"  
ALERT_WINDOW_SEC="120"
```

### Multi-Environment Monitoring

Set up different monitoring configurations for different environments:

```shell
# Production sites
SITES='["https://app.production.com", "https://api.production.com"]'

# Staging sites  
SITES='["https://app.staging.com", "https://api.staging.com"]'

# Development sites
SITES='["https://app.dev.com", "http://localhost:8080"]'
```

### Custom Discord Alert Formatting

Modify the `createDiscordMessage` function in `alerter.step.js` to customize alert appearance:

```js
function createDiscordMessage(result, previousStatus) {
  const { url, status, code, responseTime } = result
  
  // Custom colors for your brand
  const color = status === 'UP' ? 0x2ecc71 : 0xe74c3c
  
  // Custom emoji and formatting
  const emoji = status === 'UP' ? '✅' : '❌'
  const urgency = responseTime > 5000 ? '🐌 SLOW' : '⚡ FAST'
  
  return {
    content: `${emoji} **${url}** is ${status}`,
    embeds: [{
      title: `${urgency} Website ${status}`,
      description: `**${url}** changed from ${previousStatus} to ${status}`,
      color,
      timestamp: result.checkedAt,
      fields: [
        {
          name: '⏱️ Response Time',
          value: `${responseTime}ms`,
          inline: true
        },
        {
          name: '📊 Status Code', 
          value: code?.toString() || 'N/A',
          inline: true
        }
      ]
    }]
  }
}
```

---

## Troubleshooting

### Common Issues

**Sites not being checked:**
- Verify `SITES` environment variable is valid JSON
- Check cron expression syntax using [crontab.guru](https://crontab.guru)
- Review logs for parsing errors

**Discord alerts not working:**
- Verify `DISCORD_WEBHOOK` URL is correct
- Test webhook manually: `curl -X POST $DISCORD_WEBHOOK -H "Content-Type: application/json" -d '{"content":"Test message"}'`
- Check Discord webhook permissions

**High memory usage:**
- Monitor status store size with health endpoint
- Consider implementing status history cleanup
- Reduce check frequency for many sites

**False positive alerts:**
- Increase timeout values in checker step
- Implement retry logic before marking as DOWN
- Adjust rate limiting to reduce noise

### Performance Tips

- **Large Site Lists**: Consider sharding across multiple instances
- **Slow Sites**: Implement custom timeout values per site
- **High Frequency**: Use Redis for status storage instead of file system
- **Alert Fatigue**: Implement escalation policies and alert grouping

### Monitoring the Monitor

Set up monitoring for your monitoring system:

```shell
# Monitor the health endpoint itself
curl -f http://localhost:3111/healthz || echo "Monitor is down!"

# Check for recent status updates
curl http://localhost:3111/healthz | jq '.lastKnown | to_entries | map(select(.value.checkedAt > (now - 300)))'

# Verify all sites are being checked
curl http://localhost:3111/healthz | jq '.sitesConfigured == (.lastKnown | length)'
```

---

## 💻 Dive into the Code

Want to explore the complete monitoring implementation? Check out the full source code, including all steps, utilities, and configuration examples:

<div className="not-prose">
  <div className="bg-gradient-to-r from-green-50 to-emerald-50 border border-green-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-green-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Complete Uptime Monitor</h3>
        <p className="text-gray-600 mb-4">Access the full implementation with steps, utility libraries, Discord integration, and production-ready configuration.</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/foundational/infrastructure/motia-uptime-monitor" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-green-600 hover:bg-green-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            View Monitor Example
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            More Examples →
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Conclusion: Monitoring That Actually Works

This uptime monitoring system demonstrates the power of event-driven architecture for infrastructure monitoring. By breaking down monitoring into discrete, specialized components, we've created a system that's not only reliable but also extensible and maintainable.

The event-driven approach means you can easily:
- **Add new notification channels** (Slack, PagerDuty, email) by creating new steps
- **Implement custom health checks** (database connectivity, API endpoints, SSL certificates)
- **Scale monitoring** across multiple regions or environments
- **Integrate with existing systems** without disrupting the core monitoring loop

Key architectural benefits:
- **Resilience**: Component failures don't bring down the entire system
- **Observability**: Built-in logging and tracing at every step
- **Flexibility**: Easy to modify check intervals, alert logic, or add new features
- **Testing**: Each component can be tested in isolation

From here, you can extend the system by:
- Adding support for different check types (TCP, database, custom health endpoints)
- Implementing escalation policies and on-call rotations
- Building a web dashboard for historical data and trends
- Adding integration with incident management systems
- Implementing multi-region monitoring with failover

The event-driven architecture makes all of these extensions straightforward to implement without disrupting the existing monitoring pipeline.

Ready to build monitoring infrastructure that scales with your business? Start building with Motia today!



## Examples
[uptime-discord-monitor](/docs/examples/uptime-discord-monitor): Code example
---
title: 'Uptime Monitor'
description: 'Real-Time Uptime Monitoring: Building a Resilient Website Monitor with Motia'
---

In today's modern era, website uptime is critical for business success. Whether you're monitoring a personal blog or enterprise applications, you need a reliable system that can detect outages, send alerts, and provide visibility into your site's health. Traditional monitoring solutions often involve complex infrastructure and vendor lock-in, but there's a better way.

This comprehensive guide explores how to build a production-ready uptime monitoring system using Motia's event-driven architecture. We'll cover:

1.  **Event-Driven Monitoring**: How Motia's `steps` create a scalable, maintainable monitoring pipeline.
2.  **Building the Architecture**: A detailed walkthrough of our five-component monitoring system.
3.  **Smart Alerting**: Implementing rate limiting and status change detection to prevent spam.

Let's build a monitoring system that actually works for you.

---

## Workflow Overview

<div className="my-8">![Uptime Monitor](./../img/uptime-monitor-architecture.png)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/foundational/infrastructure/motia-uptime-monitor)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## The Power of Event-Driven Monitoring

<div className="my-8">![Uptime Monitor Architecture](./../img/uptime-monitor.gif)</div>

At its core, our uptime monitoring system solves a fundamental challenge: how do you continuously monitor multiple websites without creating a brittle, monolithic application? Traditional monitoring tools often suffer from tight coupling, making them difficult to scale and customize. Our Motia-powered solution breaks this down into discrete, event-driven components that each handle a specific aspect of monitoring.

The magic happens through the integration of proven technologies and patterns:

-   **[Cron-Based Scheduling](https://en.wikipedia.org/wiki/Cron)**: Configurable check intervals using familiar cron expressions
-   **[Discord Webhooks](https://discord.com/developers/docs/resources/webhook)**: Instant notifications with rich formatting
-   **[Token Bucket Rate Limiting](https://en.wikipedia.org/wiki/Token_bucket)**: Intelligent alert throttling to prevent spam
-   **[Motia Framework](https://motia.dev)**: Event-driven orchestration with built-in observability

Instead of a monolithic monitoring daemon, we get a resilient architecture where each component can be scaled, modified, or replaced independently.

---

## The Anatomy of Our Monitoring System

Our application consists of five specialized steps, each handling a specific part of the monitoring workflow. Let's explore the complete architecture.

<Folder name="steps" defaultOpen>
  <File name="cron.step.js" />
  <File name="checker.step.js" />
  <File name="alerter.step.js" />
  <File name="health.step.js" />
</Folder>

<Folder name="lib" defaultOpen>
  <File name="env.js" />
  <File name="rate-limiter.js" />
  <File name="streams.js" />
</Folder>

<Tabs items={['cron', 'checker', 'alerter', 'health', 'utilities']}>
  <Tab value="cron">
    The heartbeat of our monitoring system. This cron-triggered step periodically enqueues check requests for all configured websites, acting as the central scheduler.

    ```js
    import { config as envConfig } from '../lib/env.js';
    import { cron } from 'motia'

    export const config = {
      name: 'UptimeCronTrigger',
      triggers: [
        cron(envConfig.cron),
      ],
      enqueues: ['check.requested'],
      flows: ['uptime-monitoring']
    };

    export async function handler(context) {
      context.logger.info(`Starting uptime checks for ${envConfig.sites.length} sites`);
      context.logger.info(`Sites configured: ${JSON.stringify(envConfig.sites)}`);

      try {
        for (const url of envConfig.sites) {
          context.logger.info(`Scheduling check for: ${url}`);

          await context.enqueue({
            topic: 'check.requested',
            data: { url: url }
          });

          context.logger.info(`Successfully enqueued for: ${url}`);
        }

        context.logger.info(`Successfully scheduled checks for all ${envConfig.sites.length} sites`);
      } catch (error) {
        context.logger.error('Error during cron execution:', error);
        throw error;
      }
    }
    ```

  </Tab>
  <Tab value="checker">
    The core monitoring component that performs HTTP checks on websites. It handles timeouts, errors, and response code analysis, then enqueues results for further processing.

    ```js
    import { z } from 'zod'

    export const config = {
      name: 'WebsiteChecker',
      description: 'Performs HTTP checks on websites and enqueues results',
      triggers: [
        { type: 'queue', topic: 'check.requested', input: z.object({
          url: z.string().url('Must be a valid URL')
        }) },
      ],
      enqueues: ['check.result', 'status.stream'],
      flows: ['uptime-monitoring'],
    }

    export const handler = async (input, { logger, enqueue }) => {
      const { url } = input
      
      logger.info('Starting website check', { url })

      const startTime = performance.now()
      let result

      try {
        // Validate URL format before making request
        const urlObj = new URL(url)
        if (!['http:', 'https:'].includes(urlObj.protocol)) {
          throw new Error('Only HTTP and HTTPS protocols are supported')
        }

        // Perform HTTP request with timeout handling
        const controller = new AbortController()
        const timeoutId = setTimeout(() => controller.abort(), 10000) // 10 second timeout

        const response = await fetch(url, {
          method: 'GET',
          signal: controller.signal,
          headers: {
            'User-Agent': 'Motia-Uptime-Monitor/1.0',
            'Accept': '*/*',
            'Cache-Control': 'no-cache'
          },
          redirect: 'manual'
        })

        clearTimeout(timeoutId)
        const endTime = performance.now()
        const responseTime = Math.round(endTime - startTime)

        // Determine status: 2xx and 3xx as UP, everything else as DOWN
        const status = (response.status >= 200 && response.status < 400) ? 'UP' : 'DOWN'

        result = {
          url,
          status,
          code: response.status,
          responseTime,
          checkedAt: new Date().toISOString(),
          error: null
        }

        logger.info('Website check completed', {
          url,
          status,
          code: response.status,
          responseTime
        })

      } catch (error) {
        const endTime = performance.now()
        const responseTime = Math.round(endTime - startTime)

        let errorMessage = error.message

        // Handle specific error types with detailed messages
        if (error.name === 'AbortError') {
          errorMessage = 'Request timeout (10s)'
        } else if (error.name === 'TypeError' && error.message.includes('fetch')) {
          errorMessage = 'Network error - unable to connect'
        } else if (error.code === 'ENOTFOUND') {
          errorMessage = 'DNS resolution failed'
        } else if (error.code === 'ECONNREFUSED') {
          errorMessage = 'Connection refused'
        }

        result = {
          url,
          status: 'DOWN',
          code: null,
          responseTime,
          checkedAt: new Date().toISOString(),
          error: errorMessage
        }

        logger.error('Website check failed', {
          url,
          error: errorMessage,
          responseTime,
          originalError: error.code || error.name
        })
      }

      await enqueue({ topic: 'check.result', data: result })
      await enqueue({ topic: 'status.stream', data: result })

      logger.info('Check results enqueued successfully', { url, status: result.status })
    }
    ```

  </Tab>
  <Tab value="alerter">
    The intelligent alerting system that detects status changes, applies rate limiting, and sends Discord notifications. Only triggers alerts when status actually changes, preventing noise.

    ```js
    import { z } from 'zod'
    import { getPreviousStatus } from '../lib/streams.js'
    import { createRateLimiter } from '../lib/rate-limiter.js'
    import { config as envConfig } from '../lib/env.js'

    // Create a rate limiter instance for Discord alerts
    const rateLimiter = createRateLimiter({
      burst: envConfig.alertBurst,
      windowSec: envConfig.alertWindowSec
    })

    export const config = {
      name: 'DiscordAlerter',
      description: 'Sends Discord notifications when website status changes',
      triggers: [
        { type: 'queue', topic: 'check.result', input: z.object({
          url: z.string().url(),
          status: z.enum(['UP', 'DOWN']),
          code: z.number().nullable(),
          responseTime: z.number(),
          checkedAt: z.string(),
          error: z.string().nullable()
        }) },
      ],
      enqueues: [],
      flows: ['uptime-monitoring'],
    }

    function createDiscordMessage(result, previousStatus) {
      const { url, status, code, responseTime, checkedAt, error } = result

      const isUp = status === 'UP'
      const emoji = isUp ? '🟢' : '🔴'
      const color = isUp ? 0x00ff00 : 0xff0000

      const content = `${emoji} ${url} is ${status}${code ? ` (${code})` : ''}`

      const fields = [
        {
          name: 'Response Time',
          value: `${responseTime}ms`,
          inline: true
        }
      ]

      if (code !== null) {
        fields.push({
          name: 'Status Code',
          value: code.toString(),
          inline: true
        })
      }

      if (error) {
        fields.push({
          name: 'Error',
          value: error,
          inline: false
        })
      }

      fields.push({
        name: 'Previous Status',
        value: previousStatus,
        inline: true
      })

      return {
        content,
        embeds: [{
          title: `Website Status Change: ${status}`,
          description: `${url} changed from ${previousStatus} to ${status}`,
          color,
          timestamp: checkedAt,
          fields
        }]
      }
    }

    export const handler = async (input, { logger }) => {
      const { url, status } = input

      // Get the previous status for comparison
      const previousResult = getPreviousStatus(url)

      // Handle first-time checks
      if (!previousResult) {
        logger.info('First-time check for site, no alert needed', { url, status })
        const { updateLastStatus } = await import('../lib/streams.js')
        updateLastStatus(input)
        return
      }

      const previousStatus = previousResult.status

      // Only trigger alerts when status actually changes
      if (status === previousStatus) {
        logger.debug('Status unchanged, no alert needed', { url, status, previousStatus })
        const { updateLastStatus } = await import('../lib/streams.js')
        updateLastStatus(input)
        return
      }

      // Status has changed - check rate limiting
      logger.info('Status change detected', {
        url,
        previousStatus,
        newStatus: status,
        transition: `${previousStatus} → ${status}`
      })

      if (!rateLimiter.consume(url)) {
        const timeUntilNext = rateLimiter.getTimeUntilNextToken(url)
        logger.warn('Alert rate limited', {
          url,
          status,
          previousStatus,
          timeUntilNextMs: timeUntilNext,
          tokensRemaining: rateLimiter.getTokenCount(url)
        })
        return
      }

      // Send Discord notification
      const message = createDiscordMessage(input, previousStatus)
      
      try {
        const response = await fetch(envConfig.discordWebhook, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'User-Agent': 'Motia-Uptime-Monitor/1.0'
          },
          body: JSON.stringify(message)
        })

        if (response.ok) {
          logger.info('Discord alert sent successfully', { url, status, previousStatus })
        } else {
          const errorText = await response.text().catch(() => 'Unknown error')
          logger.error('Discord webhook failed', {
            status: response.status,
            error: errorText
          })
        }
      } catch (error) {
        logger.error('Failed to send Discord webhook', {
          error: error.message
        })
      }

      // Update status store after sending alert
      const { updateLastStatus } = await import('../lib/streams.js')
      updateLastStatus(input)
    }
    ```

  </Tab>
  <Tab value="health">
    A health check endpoint that provides system status and monitoring metrics. Essential for monitoring the monitor itself and integrating with external health check services.

    ```js
    import { z } from 'zod'
    import { getSnapshot } from '../lib/streams.js'
    import { config as envConfig } from '../lib/env.js'

    export const config = {
      name: 'HealthCheck',
      description: 'Provides system health status endpoint',
      triggers: [
        { type: 'http', method: 'GET', path: '/healthz' },
      ],
      enqueues: [],
      responseSchema: {
        200: z.object({
          status: z.literal('ok'),
          sitesConfigured: z.number(),
          lastKnown: z.record(z.any()),
          now: z.string()
        })
      },
      flows: ['uptime-monitoring'],
    }

    export const handler = async (_, { logger }) => {
      logger.info('Health check endpoint accessed')
      
      try {
        const now = new Date().toISOString()
        const sitesConfigured = envConfig.sites.length
        const lastKnown = getSnapshot()
        
        const response = {
          status: 'ok',
          sitesConfigured,
          lastKnown,
          now
        }
        
        logger.info('Health check completed successfully', { 
          sitesConfigured,
          sitesWithStatus: Object.keys(lastKnown).length
        })
        
        return {
          status: 200,
          body: response
        }
        
      } catch (error) {
        logger.error('Health check failed', { 
          error: error.message,
          stack: error.stack
        })
        
        return {
          status: 200,
          body: {
            status: 'ok',
            sitesConfigured: 0,
            lastKnown: {},
            now: new Date().toISOString(),
            error: error.message
          }
        }
      }
    }
    ```

  </Tab>
  <Tab value="utilities">
    Three essential utility libraries that power the monitoring system: environment validation, rate limiting, and persistent status storage.

    **Environment Configuration (`lib/env.js`)**
    ```js
    // Validates Discord webhook URLs
    function isValidDiscordWebhook(url) {
      if (!url || typeof url !== 'string') return false;
      
      try {
        const parsed = new URL(url);
        return parsed.hostname === 'discord.com' || parsed.hostname === 'discordapp.com';
      } catch {
        return false;
      }
    }

    // Parses and validates the SITES environment variable
    function parseSites(sitesJson) {
      if (!sitesJson) {
        throw new Error('SITES environment variable is required');
      }

      let sites;
      try {
        sites = JSON.parse(sitesJson);
      } catch (error) {
        throw new Error(`Invalid SITES JSON format: ${error.message}`);
      }

      if (!Array.isArray(sites) || sites.length === 0) {
        throw new Error('SITES must be a non-empty JSON array of URLs');
      }

      // Validate each URL
      sites.forEach(site => {
        if (typeof site !== 'string') {
          throw new Error(`Invalid site URL: ${site} (must be string)`);
        }
        try {
          new URL(site);
        } catch {
          throw new Error(`Invalid site URL format: ${site}`);
        }
      });

      return sites;
    }

    export const config = {
      discordWebhook: process.env.DISCORD_WEBHOOK,
      sites: parseSites(process.env.SITES),
      cron: process.env.CHECK_INTERVAL_CRON || '0 */1 * * * * *',
      alertBurst: parseInt(process.env.ALERT_BURST) || 3,
      alertWindowSec: parseInt(process.env.ALERT_WINDOW_SEC) || 300
    };
    ```

    **Rate Limiter (`lib/rate-limiter.js`)**
    ```js
    // Token bucket rate limiter with per-site isolation
    export function createRateLimiter({ burst, windowSec }) {
      const buckets = new Map()
      const refillRate = burst / (windowSec * 1000)

      function consume(siteUrl) {
        const bucket = getBucket(siteUrl)
        refillBucket(bucket)
        
        if (bucket.tokens >= 1) {
          bucket.tokens -= 1
          return true
        }
        
        return false
      }

      function getBucket(siteUrl) {
        if (!buckets.has(siteUrl)) {
          buckets.set(siteUrl, {
            tokens: burst,
            lastRefill: Date.now()
          })
        }
        return buckets.get(siteUrl)
      }

      function refillBucket(bucket) {
        const now = Date.now()
        const timePassed = now - bucket.lastRefill
        
        if (timePassed > 0) {
          const tokensToAdd = timePassed * refillRate
          bucket.tokens = Math.min(burst, bucket.tokens + tokensToAdd)
          bucket.lastRefill = now
        }
      }

      return { consume, /* other methods */ }
    }
    ```

    **Status Storage (`lib/streams.js`)**
    ```js
    // File-based persistent storage for site status
    import { readFileSync, writeFileSync, existsSync } from 'fs'

    const STORE_FILE = join(process.cwd(), '.motia', 'status-store.json')

    export function updateLastStatus(result) {
      // Validate input
      if (!result?.url || !['UP', 'DOWN'].includes(result.status)) {
        throw new Error('Invalid result object')
      }

      const store = loadStatusStore()
      store[result.url] = { ...result }
      saveStatusStore(store)
    }

    export function getPreviousStatus(url) {
      const store = loadStatusStore()
      const result = store[url]
      return result ? { ...result } : null
    }

    export function getSnapshot() {
      const store = loadStatusStore()
      const snapshot = {}
      
      for (const [url, result] of Object.entries(store)) {
        snapshot[url] = { ...result }
      }
      
      return snapshot
    }
    ```

  </Tab>
</Tabs>

---

## Explore the Workflow

The [iii development console](https://iii.dev/docs) provides a visual representation of your monitoring pipeline, making it easy to understand the event flow and debug issues in real-time.

<div className="my-8">![Uptime Monitor workflow](./../img/uptime-monitor.gif)</div>

You can monitor real-time status checks, view Discord alert logs, and trace the execution of each step directly in the iii development console. This makes development and debugging significantly easier compared to traditional monitoring solutions.

---

## Key Features & Benefits

### ⚡ **Event-Driven Architecture**
Each component is independent and communicates through events, making the system highly scalable and maintainable.

### 🎯 **Smart Status Detection**  
Only triggers alerts when status actually changes (UP ↔ DOWN), eliminating noise from temporary fluctuations.

### 🚨 **Intelligent Rate Limiting**
Token bucket algorithm prevents alert spam during site flapping while ensuring critical alerts get through.

### 📊 **Built-in Observability**
Comprehensive logging, health checks, and real-time status tracking with persistent storage.

### 🔧 **Production-Ready**
Robust error handling, timeout management, and configurable check intervals ensure reliability.

### 🎨 **Rich Discord Alerts**
Beautiful embedded messages with response times, error details, and status transitions.

---

## Data Flow & Event Architecture

![Uptime Monitor Event Flow](./../img/uptime-monitor-flow.png)

### Event Flow
1. **Cron Trigger** → Enqueues `check.requested` events for each configured site
2. **Website Checker** → Receives `check.requested`, performs HTTP check
3. **Status Update** → Checker enqueues `check.result` with result
4. **Alert Processing** → Alerter receives `check.result`, detects status changes
5. **Discord Notification** → Alerter sends webhook if status changed and rate limit allows
6. **Status Storage** → Status is persisted for health endpoint and future comparisons

---

## Trying It Out

Ready to build your own production-ready monitoring system? Let's get it running.

<Steps>

### Install Dependencies

Install the necessary npm packages and set up the development environment.

```shell
npm install
```

### Configure Environment Variables

Create a `.env` file with your monitoring configuration. You'll need a Discord webhook URL and the sites you want to monitor.

```shell
# Required: Discord webhook for alerts
DISCORD_WEBHOOK="https://discord.com/api/webhooks/123456789/your-webhook-token"

# Required: JSON array of URLs to monitor
SITES='["https://example.com", "https://api.yourdomain.com", "https://blog.yoursite.org"]'

# Optional: Check frequency (default: every minute)
CHECK_INTERVAL_CRON="0 */1 * * * * *"

# Optional: Rate limiting (default: 3 alerts per 5 minutes)
ALERT_BURST="3"
ALERT_WINDOW_SEC="300"
```

### Set Up Discord Webhook

Create a Discord webhook to receive alerts:

1. Go to your Discord server settings
2. Navigate to **Integrations** → **Webhooks**
3. Click **New Webhook**
4. Copy the webhook URL and add it to your `.env` file

### Run the Monitoring System

Start the Motia development server to begin monitoring your websites.

```shell
npm run dev
```

### Check System Health

Verify your monitoring system is working correctly:

```shell
curl http://localhost:3111/healthz
```

You should see a response with your configured sites and their current status:

```json
{
  "status": "ok",
  "sitesConfigured": 3,
  "lastKnown": {
    "https://example.com": {
      "url": "https://example.com",
      "status": "UP",
      "code": 200,
      "responseTime": 245,
      "checkedAt": "2024-01-15T10:30:00.000Z",
      "error": null
    }
  },
  "now": "2024-01-15T10:35:00.000Z"
}
```

### Monitor the Logs

Watch the logs to see your monitoring system in action:

- **Cron triggers**: Check scheduling for all configured sites
- **Website checks**: HTTP requests and response analysis  
- **Status changes**: UP/DOWN transitions and Discord alerts
- **Rate limiting**: Alert suppression during site flapping

</Steps>

---

## Advanced Configuration

### Custom Check Intervals

Modify the cron expression to change monitoring frequency:

```shell
# Every 5 minutes
CHECK_INTERVAL_CRON="0 */5 * * * * *"

# Every hour
CHECK_INTERVAL_CRON="0 0 * * * * *"

# Every 6 hours
CHECK_INTERVAL_CRON="0 0 */6 * * * *"

# Business hours only (9 AM - 5 PM, Mon-Fri)
CHECK_INTERVAL_CRON="0 * 9-17 * * 1-5 *"
```

### Alert Rate Limiting

Fine-tune the rate limiting to match your needs:

```shell
# Very strict: 1 alert per 10 minutes
ALERT_BURST="1"
ALERT_WINDOW_SEC="600"

# More permissive: 5 alerts per 2 minutes
ALERT_BURST="5"  
ALERT_WINDOW_SEC="120"
```

### Multi-Environment Monitoring

Set up different monitoring configurations for different environments:

```shell
# Production sites
SITES='["https://app.production.com", "https://api.production.com"]'

# Staging sites  
SITES='["https://app.staging.com", "https://api.staging.com"]'

# Development sites
SITES='["https://app.dev.com", "http://localhost:8080"]'
```

### Custom Discord Alert Formatting

Modify the `createDiscordMessage` function in `alerter.step.js` to customize alert appearance:

```js
function createDiscordMessage(result, previousStatus) {
  const { url, status, code, responseTime } = result
  
  // Custom colors for your brand
  const color = status === 'UP' ? 0x2ecc71 : 0xe74c3c
  
  // Custom emoji and formatting
  const emoji = status === 'UP' ? '✅' : '❌'
  const urgency = responseTime > 5000 ? '🐌 SLOW' : '⚡ FAST'
  
  return {
    content: `${emoji} **${url}** is ${status}`,
    embeds: [{
      title: `${urgency} Website ${status}`,
      description: `**${url}** changed from ${previousStatus} to ${status}`,
      color,
      timestamp: result.checkedAt,
      fields: [
        {
          name: '⏱️ Response Time',
          value: `${responseTime}ms`,
          inline: true
        },
        {
          name: '📊 Status Code', 
          value: code?.toString() || 'N/A',
          inline: true
        }
      ]
    }]
  }
}
```

---

## Troubleshooting

### Common Issues

**Sites not being checked:**
- Verify `SITES` environment variable is valid JSON
- Check cron expression syntax using [crontab.guru](https://crontab.guru)
- Review logs for parsing errors

**Discord alerts not working:**
- Verify `DISCORD_WEBHOOK` URL is correct
- Test webhook manually: `curl -X POST $DISCORD_WEBHOOK -H "Content-Type: application/json" -d '{"content":"Test message"}'`
- Check Discord webhook permissions

**High memory usage:**
- Monitor status store size with health endpoint
- Consider implementing status history cleanup
- Reduce check frequency for many sites

**False positive alerts:**
- Increase timeout values in checker step
- Implement retry logic before marking as DOWN
- Adjust rate limiting to reduce noise

### Performance Tips

- **Large Site Lists**: Consider sharding across multiple instances
- **Slow Sites**: Implement custom timeout values per site
- **High Frequency**: Use Redis for status storage instead of file system
- **Alert Fatigue**: Implement escalation policies and alert grouping

### Monitoring the Monitor

Set up monitoring for your monitoring system:

```shell
# Monitor the health endpoint itself
curl -f http://localhost:3111/healthz || echo "Monitor is down!"

# Check for recent status updates
curl http://localhost:3111/healthz | jq '.lastKnown | to_entries | map(select(.value.checkedAt > (now - 300)))'

# Verify all sites are being checked
curl http://localhost:3111/healthz | jq '.sitesConfigured == (.lastKnown | length)'
```

---

## 💻 Dive into the Code

Want to explore the complete monitoring implementation? Check out the full source code, including all steps, utilities, and configuration examples:

<div className="not-prose">
  <div className="bg-gradient-to-r from-green-50 to-emerald-50 border border-green-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-green-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Complete Uptime Monitor</h3>
        <p className="text-gray-600 mb-4">Access the full implementation with steps, utility libraries, Discord integration, and production-ready configuration.</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/foundational/infrastructure/motia-uptime-monitor" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-green-600 hover:bg-green-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            View Monitor Example
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            More Examples →
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Conclusion: Monitoring That Actually Works

This uptime monitoring system demonstrates the power of event-driven architecture for infrastructure monitoring. By breaking down monitoring into discrete, specialized components, we've created a system that's not only reliable but also extensible and maintainable.

The event-driven approach means you can easily:
- **Add new notification channels** (Slack, PagerDuty, email) by creating new steps
- **Implement custom health checks** (database connectivity, API endpoints, SSL certificates)
- **Scale monitoring** across multiple regions or environments
- **Integrate with existing systems** without disrupting the core monitoring loop

Key architectural benefits:
- **Resilience**: Component failures don't bring down the entire system
- **Observability**: Built-in logging and tracing at every step
- **Flexibility**: Easy to modify check intervals, alert logic, or add new features
- **Testing**: Each component can be tested in isolation

From here, you can extend the system by:
- Adding support for different check types (TCP, database, custom health endpoints)
- Implementing escalation policies and on-call rotations
- Building a web dashboard for historical data and trends
- Adding integration with incident management systems
- Implementing multi-region monitoring with failover

The event-driven architecture makes all of these extensions straightforward to implement without disrupting the existing monitoring pipeline.

Ready to build monitoring infrastructure that scales with your business? Start building with Motia today!


-   [migration-guide](/docs/getting-started/migration-guide): Documentation for migration-guide.
---
title: 0.17 to 1.0 Migration Guide
description: Migrating from Motia v0.17.x to the Motia 1.0-RC Framework powered by iii.
---

This guide covers migrating from **Motia v0.17.x** to the **Motia 1.0-RC** framework. It is organized by area of concern so you can migrate incrementally.

<Callout title="iii is required" type="warn">
  Motia now requires the **iii engine** to run. Install iii from [iii.dev](https://iii.dev) before proceeding with the migration. All adapter and infrastructure configuration is now done through iii via a `config.yaml` file -- the SDK itself no longer handles any of this.
</Callout>

<Callout title="MD Migration Guide" type="warn">
  A Markdown version of this guide is available at [motia/MIGRATION_GUIDE.md](https://github.com/MotiaDev/motia/blob/main/MIGRATION_GUIDE.md).
</Callout>

## Configuration

### Project Config

The old `motia.config.ts` (using `defineConfig`) is replaced by two files managed by iii:

| Concern | Old | New |
|---|---|---|
| Project config & plugins | `motia.config.ts` (`defineConfig({...})`) | Removed (handled by iii engine via `config.yaml`) |
| Module/adapter config | N/A | `config.yaml` (iii engine config) |
| Auth & hooks | `streamAuth` in `motia.config.ts` | `motia.config.ts` (simplified, exports only auth hooks) |
| Build externals | `.esbuildrc.json` | Removed |
| Workbench UI layout | `motia-workbench.json` | Removed (see [Workbench, Plugins, and Console](#workbench-plugins-and-console)) |

<Tabs items={['Old (motia.config.ts)', 'New (config.yaml)', 'New (motia.config.ts)']}>
<Tab value="Old (motia.config.ts)">

```typescript
import path from 'node:path'
import { defineConfig, type MotiaPlugin, type MotiaPluginContext, type StreamAuthRequest } from '@motiadev/core'
import bullmqPlugin from '@motiadev/plugin-bullmq/plugin'
import endpointPlugin from '@motiadev/plugin-endpoint/plugin'
import examplePlugin from '@motiadev/plugin-example/plugin'
import logsPlugin from '@motiadev/plugin-logs/plugin'
import observabilityPlugin from '@motiadev/plugin-observability/plugin'
import statesPlugin from '@motiadev/plugin-states/plugin'
import { z } from 'zod'

const streamAuthContextSchema = z.object({
  userId: z.string(),
  permissions: z.enum(['nodejs', 'python']).optional(),
})

const demoTokens: Record<string, z.infer<typeof streamAuthContextSchema>> = {
  'token-nodejs': { userId: 'anderson', permissions: 'nodejs' },
  'token-python': { userId: 'sergio', permissions: 'python' },
}

const extractAuthToken = (request: StreamAuthRequest): string | undefined => {
  const protocol = request.headers['sec-websocket-protocol'] as string | undefined
  if (protocol?.includes('Authorization')) {
    const [, token] = protocol.split(',')
    if (token) return token.trim()
  }
  try {
    const url = new URL(request.url)
    return url.searchParams.get('authToken') ?? undefined
  } catch {
    return undefined
  }
}

export default defineConfig({
  plugins: [
    observabilityPlugin,
    statesPlugin,
    endpointPlugin,
    logsPlugin,
    examplePlugin,
    bullmqPlugin,
  ],
  streamAuth: {
    contextSchema: z.toJSONSchema(streamAuthContextSchema),
    authenticate: async (request: StreamAuthRequest) => {
      const token = extractAuthToken(request)
      if (!token) return null
      const tokenData = demoTokens[token]
      if (!tokenData) throw new Error(`Invalid token: ${token}`)
      return tokenData
    },
  },
})
```

</Tab>
<Tab value="New (config.yaml)">

```yaml
modules:
  # ── Stream Module ──────────────────────────────────────────────────────
  # Manages real-time data streams with WebSocket support.
  # Adapters: KvStore (file_based | in_memory), RedisAdapter
  - class: modules::stream::StreamModule
    config:
      port: ${STREAM_PORT:3112}       # WebSocket server port (default: 3112)
      host: 0.0.0.0                   # Host address to bind (default: 0.0.0.0)
      # auth_function: motia.stream.authenticate  # Reference to auth fn in motia.config.ts
      adapter:
        class: modules::stream::adapters::KvStore
        config:
          store_method: file_based    # "file_based" or "in_memory" (default: in_memory)
          file_path: ./data/stream_store  # Directory for file-based persistence
          # save_interval_ms: 5000    # Disk flush interval in ms (default: 5000)

  # ── State Module ───────────────────────────────────────────────────────
  # Key-value state storage grouped by namespace.
  # Adapters: KvStore (file_based | in_memory), RedisAdapter
  - class: modules::state::StateModule
    config:
      adapter:
        class: modules::state::adapters::KvStore
        config:
          store_method: file_based    # "file_based" or "in_memory" (default: in_memory)
          file_path: ./data/state_store.db  # Directory for file-based persistence
          # save_interval_ms: 5000    # Disk flush interval in ms (default: 5000)

  # ── REST API Module ────────────────────────────────────────────────────
  # Serves HTTP endpoints defined by step triggers.
  - class: modules::api::RestApiModule
    config:
      port: 3111                      # HTTP server port (default: 3111)
      host: 0.0.0.0                   # Host address to bind (default: 0.0.0.0)
      default_timeout: 30000          # Request timeout in ms (default: 30000)
      concurrency_request_limit: 1024 # Max concurrent requests (default: 1024)
      cors:
        allowed_origins:              # Origins allowed to make cross-origin requests
          - http://localhost:3000
          - http://localhost:5173
        allowed_methods:              # HTTP methods allowed in CORS preflight
          - GET
          - POST
          - PUT
          - DELETE
          - OPTIONS

  # ── OpenTelemetry Module ───────────────────────────────────────────────
  # Observability: distributed traces, metrics, and structured logs.
  # Exporter types — traces: "otlp", "memory", "both"
  #                  metrics: "memory", "otlp"
  #                  logs:    "memory", "otlp", "both"
  - class: modules::observability::OtelModule
    config:
      enabled: true                   # Enable tracing (default: false)
      service_name: my-service        # Service name reported to OTEL collector
      service_version: 0.1.0          # Service version (OTEL semantic convention)
      # service_namespace: production # Service namespace (OTEL semantic convention)
      exporter: memory                # Trace exporter: "otlp", "memory", or "both" (default: otlp)
      # endpoint: http://localhost:4317  # OTLP gRPC endpoint (for otlp/both exporters)
      sampling_ratio: 1.0             # 0.0 to 1.0, fraction of traces to sample (1.0 = all)
      memory_max_spans: 10000         # Max spans in memory (for memory/both exporters)
      metrics_enabled: true           # Enable metrics collection (default: false)
      metrics_exporter: memory        # Metrics exporter: "memory" or "otlp" (default: memory)
      # metrics_retention_seconds: 3600  # Metrics retention in seconds (default: 3600)
      # metrics_max_count: 10000      # Max metric data points in memory (default: 10000)
      logs_enabled: true              # Enable structured log storage (default: false)
      logs_exporter: memory           # Logs exporter: "memory", "otlp", or "both" (default: memory)
      logs_max_count: 1000            # Max log entries in memory (default: 1000)
      # logs_retention_seconds: 3600  # Logs retention in seconds (default: 3600)
      # logs_sampling_ratio: 1.0     # Fraction of logs to keep, 0.0-1.0 (default: 1.0)
      # logs_console_output: true    # Also output OTEL logs to console (default: true)
      # level: info                  # Engine log level: trace, debug, info, warn, error
      # format: default              # Log format: "default" (human-readable) or "json"

  # ── Queue Module ───────────────────────────────────────────────────────
  # Message queues for async step-to-step communication via enqueue().
  # Adapters: BuiltinQueueAdapter, RedisAdapter, RabbitMQAdapter
  - class: modules::queue::QueueModule
    config:
      adapter:
        class: modules::queue::BuiltinQueueAdapter  # In-process queue (no external deps)
        # For Redis:  class: modules::queue::RedisAdapter
        #             config: { redis_url: "redis://localhost:6379" }
        # For RabbitMQ: class: modules::queue::RabbitMQAdapter
        #               config: { amqp_url: "amqp://localhost:5672" }

  # ── PubSub Module ─────────────────────────────────────────────────────
  # Internal publish/subscribe messaging between engine components.
  # Adapters: LocalAdapter, RedisAdapter
  - class: modules::pubsub::PubSubModule
    config:
      adapter:
        class: modules::pubsub::LocalAdapter  # In-process pubsub (no external deps)
        # For Redis: class: modules::pubsub::RedisAdapter
        #            config: { redis_url: "redis://localhost:6379" }

  # ── Cron Module ────────────────────────────────────────────────────────
  # Schedules and executes cron-based triggers.
  # Adapters: KvCronAdapter, RedisCronAdapter
  - class: modules::cron::CronModule
    config:
      adapter:
        class: modules::cron::KvCronAdapter  # KV-based scheduler (no external deps)
        # For Redis: class: modules::cron::RedisCronAdapter
        #            config: { redis_url: "redis://localhost:6379" }

  # ── Exec Module ────────────────────────────────────────────────────────
  # Manages the SDK process lifecycle. Watches files and restarts on change.
  - class: modules::shell::ExecModule
    config:
      watch:                          # Glob patterns to watch for hot-reload
        - steps/**/*.ts
        - motia.config.ts
      exec:                           # Choose ONE based on your runtime
        - npx motia dev               # Node.js (default)
        # - bun run --enable-source-maps dist/index-dev.js  # Bun (alternative)
```

</Tab>
<Tab value="New (motia.config.ts)">

```typescript
import type { AuthenticateStream } from 'motia'

export const authenticateStream: AuthenticateStream = async (req, context) => {
  context.logger.info('Authenticating stream', { req })
  return { context: { userId: 'sergio' } }
}
```

</Tab>
</Tabs>

### Dev Command

| Old | New |
|---|---|
| `motia dev` | `iii` |
| `motia build` | `motia build` (unchanged) |

### Files to Delete

- `motia-workbench.json`
- `.motia/` directory — **warning:** this will delete any local stream and state data persisted by the old engine; back up first if needed

<Callout type="info">
  `motia.config.ts` is **not deleted** -- it is simplified. Remove the `defineConfig` wrapper, all plugin imports, and the `plugins` array. Keep only the authentication hook exports (see the "New" tab above).
</Callout>

---

## Module System and Runtime

The new Motia **does not enforce a specific module system or runtime**. You are free to use CommonJS, ESM, Node.js, Bun, or any compatible runtime. The framework adapts to your project's setup.

### Runtime Support

Motia now has first-class support for **Bun** in addition to Node.js. You can choose whichever runtime fits your project:

| Runtime | Dev Command Example | Production Example |
|---|---|---|
| Node.js | `npx motia dev` | `node dist/index-production.js` |
| Bun | `bun run dist/index-dev.js` | `bun run --enable-source-maps dist/index-production.js` |

### Module System

You can use either CommonJS or ESM -- the choice is yours. If you want to adopt ESM (recommended for Bun compatibility and modern tooling), update your project:

```json title="package.json (optional)"
{
  "type": "module"
}
```

```jsonc title="tsconfig.json (optional)"
{
  "compilerOptions": {
    "module": "ESNext",
    "moduleResolution": "bundler",
    "moduleDetection": "force"
  }
}
```

If you prefer to stay on CommonJS, that works too. Motia does not force a migration.

---

## Steps and Triggers

<Callout title="No more step types" type="info">
  This is the most important conceptual change in new Motia: **there are no longer separate "step types"**. In the old version, you had API steps, Event steps, and Cron steps -- each with its own config type. In the new version, **everything is just a Step**. What used to determine the "type" of a step is now expressed through its **triggers** -- an array of trigger definitions that describe how and when the step is activated. A single step can have multiple triggers of different kinds (HTTP, queue, cron, state, stream).
</Callout>

### Config Type Changes

| Old | New |
|---|---|
| `ApiRouteConfig` | `StepConfig` |
| `EventConfig` | `StepConfig` |
| `CronConfig` | `StepConfig` |
| `type: 'api' \| 'event' \| 'cron'` | `triggers: [{ type: 'http' \| 'queue' \| 'cron' \| 'state' \| 'stream' }]` |
| `emits: ['topic']` | `enqueues: ['topic']` |
| `subscribes: ['topic']` | Moved into trigger: `{ type: 'queue', topic: '...' }` |

### Handler Type Changes

| Old | New |
|---|---|
| `Handlers['StepName']` | `Handlers<typeof config>` |
| `ctx.emit({ topic, data })` | `ctx.enqueue({ topic, data })` |

### Type Safety

The new version uses `as const satisfies StepConfig` for full type inference:

<Tabs items={['Old', 'New']}>
<Tab value="Old">

```typescript
export const config: ApiRouteConfig = {
  type: 'api',
  name: 'MyStep',
  // ...
}
export const handler: Handlers['MyStep'] = async (req, ctx) => { /* ... */ }
```

</Tab>
<Tab value="New">

```typescript
export const config = {
  name: 'MyStep',
  // ...
  triggers: [{ type: 'http', method: 'GET', path: '/my-step' }],
  enqueues: [],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (req, ctx) => { /* ... */ }
```

</Tab>
</Tabs>

---

## HTTP Triggers

In the old version these were "API steps" -- a dedicated step type with `type: 'api'`. In the new version, HTTP is just a **trigger type** (`type: 'http'`) on a regular step.

<Tabs items={['Old', 'New']}>
<Tab value="Old">

```typescript
import { ApiRouteConfig, Handlers } from 'motia'
import { z } from 'zod'

const bodySchema = z.object({ name: z.string(), email: z.string() })

export const config: ApiRouteConfig = {
  type: 'api',
  name: 'CreateUser',
  description: 'Create a new user',
  method: 'POST',
  path: '/users',
  bodySchema,
  responseSchema: {
    200: z.object({ id: z.string() }),
    400: z.object({ error: z.string() }),
  },
  emits: ['user-created'],
  flows: ['User Flow'],
  middleware: [coreMiddleware, validateBearerToken],
}

export const handler: Handlers['CreateUser'] = async (req, { emit, logger }) => {
  const { name, email } = req.body
  logger.info('Creating user', { name, email })
  await emit({ topic: 'user-created', data: { name, email } })
  return { status: 200, body: { id: 'user-123' } }
}
```

</Tab>
<Tab value="New">

```typescript
import type { Handlers, StepConfig } from 'motia'
import { z } from 'zod'

const bodySchema = z.object({ name: z.string(), email: z.string() })

export const config = {
  name: 'CreateUser',
  description: 'Create a new user',
  flows: ['user-flow'],
  triggers: [
    {
      type: 'http',
      method: 'POST',
      path: '/users',
      bodySchema,
      responseSchema: {
        200: z.object({ id: z.string() }),
        400: z.object({ error: z.string() }),
      },
      middleware: [coreMiddleware, validateBearerToken],
    },
  ],
  enqueues: ['user-created'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (req, { enqueue, logger }) => {
  const { name, email } = req.body
  logger.info('Creating user', { name, email })
  await enqueue({ topic: 'user-created', data: { name, email } })
  return { status: 200, body: { id: 'user-123' } }
}
```

</Tab>
</Tabs>

**Key differences:**

1. `type: 'api'` is now `type: 'http'` inside a trigger object.
2. `method`, `path`, `bodySchema`, `responseSchema`, `middleware` all move inside the trigger.
3. `emits` becomes `enqueues` at the config level.
4. `emit()` becomes `enqueue()` in the handler context.
5. Config type changes from `ApiRouteConfig` to `StepConfig` with `as const satisfies`.

### HTTP Helper Shorthand

```typescript
import { http } from 'motia'

export const config = {
  name: 'CreateTodo',
  flows: ['todo-app'],
  triggers: [
    http('POST', '/todo', {
      bodySchema: z.object({ description: z.string() }),
      responseSchema: { 200: todoSchema, 400: z.object({ error: z.string() }) },
    }),
  ],
  enqueues: [],
} as const satisfies StepConfig
```

---

## Queue Triggers (formerly Event Steps)

The concept of "event steps" that subscribe to topics no longer exists as a step type. Instead, subscribing to a topic is now a **queue trigger** on a regular step.

<Tabs items={['Old', 'New']}>
<Tab value="Old">

```typescript
import { EventConfig, Handlers } from 'motia'
import { z } from 'zod'

export const config: EventConfig = {
  type: 'event',
  name: 'DeployEnvironment',
  description: 'Creates or updates an environment',
  subscribes: ['deploy-environment-v2'],
  emits: ['deploy-version-v2'],
  input: z.object({
    deploymentId: z.string(),
    envVars: z.record(z.string()),
  }),
  flows: ['Deployment'],
}

export const handler: Handlers['DeployEnvironment'] = async (data, { logger, emit, streams }) => {
  logger.info('Deploying environment', { deploymentId: data.deploymentId })
  await emit({ topic: 'deploy-version-v2', data: { deploymentId: data.deploymentId } })
}
```

</Tab>
<Tab value="New">

```typescript
import type { Handlers, StepConfig } from 'motia'
import { z } from 'zod'

export const config = {
  name: 'DeployEnvironment',
  description: 'Creates or updates an environment',
  flows: ['deployment'],
  triggers: [
    {
      type: 'queue',
      topic: 'deploy-environment-v2',
      input: z.object({
        deploymentId: z.string(),
        envVars: z.record(z.string()),
      }),
    },
  ],
  enqueues: ['deploy-version-v2'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (input, { logger, enqueue, streams }) => {
  logger.info('Deploying environment', { deploymentId: input.deploymentId })
  await enqueue({ topic: 'deploy-version-v2', data: { deploymentId: input.deploymentId } })
}
```

</Tab>
</Tabs>

| Old | New |
|---|---|
| `type: 'event'` | `triggers: [{ type: 'queue', topic, input }]` |
| `subscribes: ['topic']` | `topic` field inside trigger |
| `emits: ['topic']` | `enqueues: ['topic']` |
| `input: schema` | `input: schema` inside trigger (or wrap with `jsonSchema()`) |
| `infrastructure: {...}` at config root | `infrastructure: {...}` inside the queue trigger |
| `emit({ topic, data })` | `enqueue({ topic, data })` |

### Using `jsonSchema()` Wrapper

When the input schema needs JSON schema conversion for the engine, use the `jsonSchema()` wrapper:

```typescript
import { jsonSchema } from 'motia'

triggers: [
  {
    type: 'queue',
    topic: 'notification',
    input: jsonSchema(
      z.object({ email: z.string(), templateId: z.string() })
    ),
  },
]
```

---

## Cron Triggers

<Tabs items={['Old', 'New']}>
<Tab value="Old">

```typescript
import { CronConfig, Handlers } from 'motia'

export const config: CronConfig = {
  type: 'cron',
  name: 'DailyMetricsCollection',
  description: 'Collects metrics daily at midnight',
  cron: '0 5 * * *',
  emits: ['collect-metrics'],
  flows: ['Metrics Collection Flow'],
}

export const handler: Handlers['DailyMetricsCollection'] = async ({ logger, emit }) => {
  logger.info('Collecting metrics')
  await emit({ topic: 'collect-metrics', data: { targetDate: new Date().toISOString() } })
}
```

</Tab>
<Tab value="New">

```typescript
import type { Handlers, StepConfig } from 'motia'

export const config = {
  name: 'DailyMetricsCollection',
  description: 'Collects metrics daily at midnight',
  flows: ['metrics-collection-flow'],
  triggers: [{ type: 'cron', expression: '0 0 5 * * * *' }],
  enqueues: ['collect-metrics'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (input, { logger, enqueue }) => {
  logger.info('Collecting metrics')
  await enqueue({ topic: 'collect-metrics', data: { targetDate: new Date().toISOString() } })
}
```

</Tab>
</Tabs>

| Old | New |
|---|---|
| `type: 'cron'` at config root | `triggers: [{ type: 'cron', expression }]` |
| `cron: '0 5 * * *'` (5-field) | `expression: '0 0 5 * * * *'` (7-field, includes seconds and year) |
| Handler: `async ({ logger, emit })` | Handler: `async (input, { logger, enqueue })` |
| `emit()` | `enqueue()` |

### Cron Expression Format

The new engine uses a 7-field cron expression:

```
┌──────────── second (0-59)
│ ┌────────── minute (0-59)
│ │ ┌──────── hour (0-23)
│ │ │ ┌────── day of month (1-31)
│ │ │ │ ┌──── month (1-12)
│ │ │ │ │ ┌── day of week (0-6, Sun=0)
│ │ │ │ │ │ ┌ year (optional)
│ │ │ │ │ │ │
* * * * * * *
```

| Old (5-field) | New (7-field) | Meaning |
|---|---|---|
| `0 5 * * *` | `0 0 5 * * * *` | Daily at 5:00 AM |
| `0 2 * * *` | `0 0 2 * * * *` | Daily at 2:00 AM |
| `*/5 * * * *` | `0 */5 * * * * *` | Every 5 minutes |
| `0 0 * * 0` | `0 0 0 * * 0 *` | Weekly on Sunday at midnight |

---

## Streams

Stream definitions remain similar but the access API has changed.

### Stream Config

<Tabs items={['Old', 'New']}>
<Tab value="Old">

```typescript
import { StreamConfig } from 'motia'
import { z } from 'zod'

export const config: StreamConfig = {
  name: 'deployment',
  baseConfig: { storageType: 'default' },
  schema: z.object({
    id: z.string(),
    status: z.enum(['pending', 'progress', 'completed', 'failed']),
    message: z.string().optional(),
  }),
}
```

</Tab>
<Tab value="New">

```typescript
import type { StreamConfig } from 'motia'
import { z } from 'zod'

export const config: StreamConfig = {
  name: 'deployment',
  baseConfig: { storageType: 'default' },
  schema: z.object({
    id: z.string(),
    status: z.enum(['pending', 'progress', 'completed', 'failed']),
    message: z.string().optional(),
  }),
  onJoin: async (subscription, context, authContext) => {
    context.logger.info('Client joined stream', { subscription, authContext })
    return { unauthorized: false }
  },
  onLeave: async (subscription, context, authContext) => {
    context.logger.info('Client left stream', { subscription, authContext })
  },
}
```

</Tab>
</Tabs>

### Stream Operations API

| Operation | Old | New |
|---|---|---|
| Get | `streams.name.get(id, key)` | `streams.name.get(groupId, id)` |
| Set | `streams.name.set(id, key, value)` | `streams.name.set(groupId, id, value)` |
| Update | N/A | `streams.name.update(groupId, id, UpdateOp[])` |
| Delete | `streams.name.delete(id, key)` | `streams.name.delete(groupId, id)` |

The parameter naming changed from `(id, key)` to `(groupId, id)` to better reflect the data model: a stream is partitioned by groups, and within each group items are identified by id.

### Atomic Updates with `UpdateOp`

```typescript
import type { UpdateOp } from 'motia'

await streams.deployment.update('merge-groups', traceId, [
  { type: 'increment', path: 'completedSteps', by: 1 },
  { type: 'set', path: 'status', value: 'progress' },
  { type: 'decrement', path: 'retries', by: 1 },
])
```

| Type | Fields | Description |
|---|---|---|
| `set` | `path`, `value` | Set a field to a value (overwrite) |
| `merge` | `path` (optional), `value` | Merge an object into the existing value (object-only) |
| `increment` | `path`, `by` | Increment a numeric field |
| `decrement` | `path`, `by` | Decrement a numeric field |
| `remove` | `path` | Remove a field entirely |

### Migration Example

<Tabs items={['Old', 'New']}>
<Tab value="Old">

```typescript
const streamData = await streams.deployment.get(deploymentId, 'data')
streamData.status = 'completed'
streamData.message = 'Done'
await streams.deployment.set(deploymentId, 'data', streamData)
```

</Tab>
<Tab value="New">

```typescript
await streams.deployment.update('data', deploymentId, [
  { type: 'set', path: 'status', value: 'completed' },
  { type: 'set', path: 'message', value: 'Done' },
])
```

</Tab>
</Tabs>

### Stream Triggers

Steps can now react to stream changes. The handler receives a `StreamWrapperMessage`:

```typescript
type StreamWrapperMessage<TStreamData> = {
  type: 'stream'
  timestamp: number
  streamName: string
  groupId: string
  id?: string
  event: StreamCreate<TStreamData> | StreamUpdate<TStreamData> | StreamDelete<TStreamData> | StreamEvent
}
```

Where the `event` field contains one of:
- `{ type: 'create', data: TStreamData }` -- a new item was created
- `{ type: 'update', data: TStreamData }` -- an existing item was updated
- `{ type: 'delete', data: TStreamData }` -- an item was deleted
- `{ type: 'event', data: { type: string, data: TEventData } }` -- a custom event

```typescript
triggers: [
  {
    type: 'stream',
    streamName: 'deployment',
    groupId: 'data',
    condition: (input: StreamWrapperMessage) => input.event.type === 'update',
  },
]
```

---

## State

State provides key-value storage grouped by a namespace. The core `get`, `set`, and `list` operations remain the same. The new version introduces two additions: **atomic updates** via the `update` method, and **state triggers**.

### Existing API (unchanged)

```typescript
await ctx.state.set('orders', orderId, orderData)
const order = await ctx.state.get<Order>('orders', orderId)
const allOrders = await ctx.state.list<Order>('orders')
```

### Atomic Updates with `update()`

<Callout title="New feature" type="info">
  The `update()` method eliminates race conditions from manual get-then-set patterns by performing atomic operations.
</Callout>

```typescript
await ctx.state.update<Order>('orders', orderId, [
  { type: 'increment', path: 'completedSteps', by: 1 },
  { type: 'set', path: 'status', value: 'shipped' },
  { type: 'decrement', path: 'retries', by: 1 },
])
```

Uses the same `UpdateOp` interface as streams. See [Streams](#atomic-updates-with-updateop) for the full list of operations.

### State Triggers

<Callout title="Brand new feature" type="info">
  State triggers enable powerful reactive patterns -- for example, triggering a step when a parallel merge completes, without polling or manual coordination.
</Callout>

```typescript
import type { StateTriggerInput } from 'motia'

export const config = {
  name: 'OnAllStepsComplete',
  triggers: [
    {
      type: 'state',
      condition: (input: StateTriggerInput<MyType>) => {
        return (
          input.group_id === 'tasks' &&
          !!input.new_value &&
          input.new_value.totalSteps === input.new_value.completedSteps
        )
      },
    },
  ],
  flows: ['my-flow'],
} as const satisfies StepConfig
```

The handler receives the state change event as its first argument, including `new_value`, `old_value`, `item_id`, and `group_id`.

---

## Middleware

### Old Approach

```typescript
import { ApiMiddleware } from 'motia'

export const validateBearerToken: ApiMiddleware = async (req, ctx, next) => {
  const authToken = req.headers['authorization'] as string
  if (!authToken) {
    return { status: 401, body: { error: 'Unauthorized' } }
  }
  const [, token] = authToken.split(' ')
  const decoded = jwt.verify(token, process.env.JWT_SECRET!) as TokenData
  req.tokenInfo = decoded
  return next()
}

// In step config (root level):
export const config: ApiRouteConfig = {
  type: 'api',
  name: 'GetUser',
  middleware: [coreMiddleware, validateBearerToken],
}
```

### New Approach

The `middleware` field has moved from the config root **into the HTTP trigger object**:

```typescript
export const config = {
  name: 'GetUser',
  flows: ['users'],
  triggers: [
    {
      type: 'http',
      method: 'GET',
      path: '/users',
      middleware: [validateBearerToken],
    },
  ],
  enqueues: [],
} as const satisfies StepConfig
```

**Stream authentication** is configured separately in `motia.config.ts` via `authenticateStream`.

You can also use shared utility functions called directly within handlers as an alternative:

```typescript title="Alternative: handler-level auth"
export async function requireAuth(request: ApiRequest<any>): Promise<TokenData> {
  const authToken = request.headers['authorization'] as string
  if (!authToken) {
    throw new HttpError(401, 'Unauthorized')
  }
  const [, token] = authToken.split(' ')
  return jwt.verify(token, process.env.JWT_SECRET!) as TokenData
}

export const handler: Handlers<typeof config> = async (request, { logger }) => {
  const tokenData = await requireAuth(request)
  // ... rest of handler
}
```

---

## New Features

### Multi-Trigger Steps

A single step can now respond to multiple trigger types:

```typescript
export const config = {
  name: 'ProcessOrder',
  flows: ['orders'],
  triggers: [
    { type: 'queue', topic: 'order.created', input: orderSchema },
    { type: 'http', method: 'POST', path: '/orders/manual', bodySchema: orderSchema },
    { type: 'cron', expression: '0 * * * * * *' },
  ],
  enqueues: ['order.processed'],
} as const satisfies StepConfig
```

### The `step()` Helper

For multi-trigger steps, the `step()` helper provides `ctx.getData()` and `ctx.match()`:

```typescript
import { http, queue, step } from 'motia'

export const stepConfig = {
  name: 'ProcessOrder',
  flows: ['orders'],
  triggers: [
    queue('order.created', { input: orderSchema }),
    http('POST', '/orders', { bodySchema: orderSchema }),
  ],
  enqueues: ['notification'],
}

export const { config, handler } = step(stepConfig, async (input, ctx) => {
  const data = ctx.getData()

  return ctx.match({
    http: async (request) => {
      return { status: 200, body: { success: true } }
    },
    queue: async (queueInput) => {
      ctx.logger.info('Processing from queue', { queueInput })
    },
  })
})
```

### Conditional Triggers

Triggers can include a `condition` function that determines whether the step should execute:

```typescript
triggers: [
  {
    type: 'queue',
    topic: 'order.created',
    input: orderSchema,
    condition: (input, ctx) => {
      return input.amount > 1000
    },
  },
  {
    type: 'http',
    method: 'POST',
    path: '/orders/manual',
    bodySchema: orderSchema,
    condition: (input, ctx) => {
      if (ctx.trigger.type !== 'http') return false
      return input.body.user.verified === true
    },
  },
]
```

### Helper Functions

Shorthand helpers for creating triggers:

```typescript
import { http, queue } from 'motia'

triggers: [
  http('POST', '/todo', { bodySchema: schema, responseSchema: { 200: schema } }),
  queue('process-todo', { input: schema }),
]
```

---

## Migration Checklist

### Project Setup

- Install the iii engine from [iii.dev](https://iii.dev)
- Create `config.yaml` with module definitions (stream, state, api, queue, cron, exec)
- Create `motia.config.ts` for authentication hooks (if needed)
- Simplify `motia.config.ts`: remove `defineConfig`, all plugin imports, and the `plugins` array; keep only auth hook exports
- Delete `motia-workbench.json`
- Delete `.motia/` directory (**warning:** this will delete any local stream and state data persisted by the old engine; back up first if needed)
- Update dev script from `motia dev` to `iii`
- Choose your runtime (Node.js or Bun) and module system (CommonJS or ESM)

### Steps

- Replace all `ApiRouteConfig` / `EventConfig` / `CronConfig` imports with `StepConfig`
- Convert all step configs to use `triggers[]` and `enqueues[]`
- Add `as const satisfies StepConfig` to all configs
- Replace `Handlers['StepName']` with `Handlers<typeof config>`
- Rename all `emit()` calls to `enqueue()`
- Rename all `emits` config fields to `enqueues`
- Move `subscribes` into queue triggers
- Move `method`, `path`, `bodySchema`, `responseSchema`, `middleware` into HTTP triggers
- Move `infrastructure` from config root into queue triggers
- Change `type: 'api'` to `type: 'http'` in all triggers
- Move `cron` into cron triggers as `expression` (and convert to 7-field format)
- Remove `type` field from config root
- Remove `middleware` field from all step configs
- Replace `virtualEmits` with `virtualEnqueues` (format changes from `[{ topic, label }]` to `['topic']`)

### Streams

- Update stream access calls: `get(id, key)` to `get(groupId, id)`
- Update stream access calls: `set(id, key, value)` to `set(groupId, id, value)`
- Replace read-modify-write patterns with `update(groupId, id, UpdateOp[])` where possible
- Add `onJoin` / `onLeave` hooks to stream configs if real-time subscription auth is needed

### State

- Adopt `state.update()` with `UpdateOp[]` to replace manual get-then-set patterns
- Consider using state triggers for reactive workflows

### Middleware

- Move `middleware` arrays from config root into the corresponding HTTP trigger objects
- Alternatively, extract authentication logic into shared utility functions called in handlers

### Cron Expressions

- Convert all 5-field cron expressions to 7-field format (prepend seconds, append year)
- Rename `cron` field to `expression` inside trigger objects

### Python (if applicable)

- Install `motia` as a standalone Python package (npm/Node.js no longer required)
- Add a separate ExecModule entry in `config.yaml` for the Python runtime
- Refer to the dedicated Python migration guide for step-level changes

### Workbench and Plugins

- Delete `motia-workbench.json`
- Remove any `.ui.step.ts` or noop step files used exclusively for workbench rendering
- Remove any workbench plugin code (React/JSX components for workbench panels)
- Familiarize with the iii Console as the replacement for the Workbench

---

## Python Runtime

<Callout title="Major change for Python developers" type="warn">
  In the old Motia, Python steps were managed by the Node.js runtime. Python developers **previously needed Node.js and npm installed**. This is no longer the case. Python is now a fully independent runtime.
</Callout>

In the new Motia, **runtimes are fully independent**. There is a dedicated **Motia Python** SDK (`motia-py`) that runs as its own standalone process, communicating directly with the iii engine. **Python developers no longer need Node.js, npm, or any JavaScript tooling whatsoever.**

| Aspect | Old | New |
|---|---|---|
| Python execution | Spawned as child process by Node runtime | Independent process managed by iii engine |
| Node.js required for Python? | Yes | **No** |
| SDK | Single `motia` npm package handled both | Separate `motia-py` (Python) and `motia` (Node) packages |
| Configuration | Shared with Node steps | Own `config.yaml` ExecModule entry |

### For Mixed Projects (Node + Python)

Configure **separate ExecModule entries** in `config.yaml`:

```yaml
modules:
  - class: modules::shell::ExecModule
    config:
      watch:                          # Glob patterns to watch for hot-reload
        - steps/**/*.ts
        - motia.config.ts
      exec:                           # Choose ONE based on your runtime
        - npx motia dev               # Node.js (default)
        # - bun run --enable-source-maps dist/index-dev.js  # Bun (alternative)

  - class: modules::shell::ExecModule
    config:
      watch:                          # Glob patterns to watch for hot-reload
        - steps/**/*.py
      exec:
        - uv run motia dev --dir steps
```

<Callout type="info">
  A dedicated migration guide for Python projects and steps will be provided in a separate document. This guide focuses on the Node.js/TypeScript migration path.
</Callout>

---

## Workbench, Plugins, and Console

### Workbench Replaced by iii Console

The Motia Workbench (the local visual flow editor, configured via `motia-workbench.json`) has been replaced by the **iii Console**. The console provides a richer experience for visualizing and managing your flows, traces, and infrastructure.

<Callout type="info">
  Refer to the [iii quickstart documentation](https://iii.dev/docs/tutorials/quickstart) for iii Console installation instructions.
</Callout>

### Workbench Plugins Sunset

Workbench plugins (custom UI panels and extensions rendered inside the Workbench) have been **sunset** and are no longer supported. If your project relied on workbench plugins, you will need to find alternative approaches for any custom UI functionality they provided.

- Delete any `.ui.step.ts` or noop step files that were used exclusively for workbench rendering.
- Remove any React/JSX workbench plugin code that is no longer needed.

---

## OpenAPI Generation

<Callout type="info">
  OpenAPI spec generation from HTTP step schemas is planned but **not yet available** in the new Motia version. This section will be updated once the feature is released.
</Callout>



-   [quick-start](/docs/getting-started/quick-start): Documentation for quick-start.
---
title: Quick Start
description: Get up and running with a new Motia project in just a few seconds.
---

Motia is a unified backend framework where everything is a **Step** — a file with a config and a handler. Python developers don't need npm; Node.js developers don't need Python. Choose your language or use both in a mixed project. In this guide you will create a new project with the motia-cli, start it with the iii engine, and trigger your first workflow.

## Prerequisites

<Tabs items={['Node.js', 'Python', 'Mixed']}>
  <Tab value="Node.js">
    - **Git** installed
    - **Node.js** 18+
    - **iii** (install in Step 1)
  </Tab>
  <Tab value="Python">
    - **Git** installed
    - **Python** 3.10+
    - **[uv](https://docs.astral.sh/uv/)** for Python package management
    - **iii** (install in Step 1)
  </Tab>
  <Tab value="Mixed">
    - **Git** installed
    - **Node.js** 18+
    - **Python** 3.10+
    - **[uv](https://docs.astral.sh/uv/)**
    - **iii** (install in Step 1)
  </Tab>
</Tabs>

<Steps>

<Step>
### 1. Install iii

The iii engine is the runtime that powers Motia. Install it with:

```bash
curl -fsSL https://install.iii.dev/iii/main/install.sh | sh
```

Verify the installation:

```bash
iii -v
```

</Step>

<Step>
### 2. Install motia-cli

Install the Motia project scaffolding CLI:

```bash
curl -fsSL https://raw.githubusercontent.com/MotiaDev/motia-cli/main/install.sh | sh
```

Or via Homebrew:

```bash
brew tap MotiaDev/tap
brew install motia-cli
```

</Step>

<Step>
### 3. Create Your Project

Run the create command and follow the prompts to choose your project name and language:

```bash
motia-cli create my-project
```

Select your preferred language when prompted:

- **Node.js** — TypeScript/Node.js only (no Python required)
- **Python** — Python only (no npm required)
- **Mixed** — Node.js handles HTTP APIs, Python handles background processing; both share the same iii infrastructure

</Step>

<Step>
### 4. Start the Project

The `iii-config.yaml` in the project tells the iii engine how to run Motia — starting iii starts everything.

```bash
cd my-project
iii -c iii-config.yaml
```

</Step>

<Step>
### 5. Run Your First Flow

This example is a ticketing system for user issues. Try it out:

```bash
# Create a ticket
curl -X POST http://localhost:3111/tickets \
  -H "Content-Type: application/json" \
  -d '{"title":"Login issue","description":"User is having trouble creating an account","priority":"high","customerEmail":"user@example.com"}' | jq
```

```bash
# List all tickets
curl http://localhost:3111/tickets | jq
```

</Step>

<Step>
### 6. What Just Happened?

When you created a ticket, here is what Motia did behind the scenes:

1. **HTTP trigger** — The `POST /tickets` request hit a Step with an `http` trigger, which validated the input and stored the ticket in state.
2. **Queue trigger** — That Step enqueued a message to a topic. Another Step with a `queue` trigger picked it up and processed the ticket asynchronously (e.g., classification, notification).
3. **State** — The ticket data was persisted using Motia's built-in key-value state, so the `GET /tickets` endpoint could retrieve it.

<Tabs items={['Node.js', 'Python', 'Mixed']}>
  <Tab value="Node.js">

All of this was defined in simple Step files inside the `src/` folder. Each one uses the `.step.ts` pattern and exports a `config` (defining triggers and topics) and a `handler` (business logic).

  </Tab>
  <Tab value="Python">

All of this was defined in simple Step files inside the `steps/` folder. Each one uses the `_step.py` pattern, defines a `config` dict (triggers and topics), and an `async def handler` (business logic).

  </Tab>
  <Tab value="Mixed">

In the mixed template, Node.js handles the HTTP API endpoints (`create-ticket`, `list-tickets`) in `nodejs/src/`, while Python handles queue and cron triggers (`triage`, `notify`, `sla-monitor`, `escalate`) in `python/steps/`. Both run as subprocesses connected to the same iii infrastructure.

  </Tab>
</Tabs>

</Step>

<Step>
### 7. Try the iii Console

<Callout title="iii is in alpha" type="warn">
  Motia and iii are under very active development. We will be regularly updating Motia, iii, and the iii console to address any issues.
</Callout>

The iii console gives you complete observability of your Motia project — flow diagrams, real-time logs, state inspection, and stream monitoring. Install and start it in a new terminal:

```bash
curl -fsSL https://install.iii.dev/console/main/install.sh | sh
iii-console --enable-flow
```

Then open your browser to: [http://localhost:3113/](http://localhost:3113/)

The console dashboard gives you a system overview of your running application:

![iii Console Dashboard](/console/dashboard.png)

Navigate to the **Flow** tab to see your Steps connected as a visual workflow:

![Flow diagram in iii Console](/console/flow-view.png)

</Step>

<Step>
### Manual Setup (Alternative)

If you prefer to clone the example repository directly instead of using motia-cli:

<Tabs items={['Node.js', 'Python', 'Mixed']}>
  <Tab value="Node.js">

```bash
git clone https://github.com/MotiaDev/motia-iii-example.git
cd motia-iii-example/nodejs
npm install
```

  </Tab>
  <Tab value="Python">

```bash
git clone https://github.com/MotiaDev/motia-iii-example.git
cd motia-iii-example/python
uv sync
```

  </Tab>
  <Tab value="Mixed">

```bash
git clone https://github.com/MotiaDev/motia-iii-example.git
cd motia-iii-example/mixed
(cd nodejs && npm install)
(cd python && uv sync)
```

  </Tab>
</Tabs>

</Step>

<Step>
### Next Steps

You have successfully run your first Motia workflow. Here is where to go next:

<Cards>
  <Card title="Core Concepts" href="/docs/concepts/overview">
    Understand Steps, triggers, and the event-driven architecture that powers Motia.
  </Card>
  <Card title="Examples" href="/docs/examples">
    Explore real-world examples covering APIs, AI agents, workflows, and more.
  </Card>
  <Card title="The iii Engine" href="/docs/concepts/iii-engine">
    Learn how iii manages infrastructure through config.yaml modules.
  </Card>
</Cards>

</Step>

</Steps>


-   [index](/docs/): Documentation for index.
---
title: Welcome to Motia
description: "Build production-grade backends with a single primitive. APIs, background jobs, workflows, AI agents, streaming, state management, and observability — unified in one framework."
---

**Motia** is a unified backend framework where everything is built around one core primitive: **the Step**. Instead of juggling separate frameworks for APIs, queues, cron jobs, AI agents, and real-time streaming, you write Steps — simple files with a `config` and a `handler` — and Motia connects them automatically.

```typescript
import type { Handlers, StepConfig } from 'motia'

export const config = {
  name: 'CreateUser',
  triggers: [{ type: 'http', method: 'POST', path: '/users' }],
  enqueues: ['user.created'],
  flows: ['onboarding'],
} as const satisfies StepConfig

export const handler: Handlers<typeof config> = async (req, { enqueue, logger }) => {
  logger.info('Creating user', { email: req.body.email })
  await enqueue({ topic: 'user.created', data: req.body })
  return { status: 201, body: { success: true } }
}
```

Drop this file in your project and Motia auto-discovers it. No registration, no boilerplate wiring.

---

## What You Get

Motia gives you a complete backend toolkit from a single primitive:

| Capability | How It Works |
|---|---|
| **HTTP APIs** | Steps with `http` triggers become REST endpoints with validation and routing |
| **Background Jobs** | Steps with `queue` triggers process messages asynchronously with retries |
| **Scheduled Tasks** | Steps with `cron` triggers run on a schedule |
| **Reactive Workflows** | Steps with `state` or `stream` triggers react to data changes automatically |
| **AI Agents** | Build agentic workflows with streaming support and tool calling |
| **State Management** | Built-in key-value storage shared across all Steps, with atomic updates |
| **Real-Time Streaming** | Push live updates to connected clients via WebSocket streams |
| **Observability** | Structured logging, distributed tracing, and metrics out of the box |
| **Multi-Language** | Write Steps in TypeScript, Python, or JavaScript — they all work together |

---

## Powered by iii

Motia runs on the [iii engine](https://iii.dev), which manages all infrastructure concerns — queues, pub/sub, state storage, stream servers, cron scheduling, and observability — through a single `config.yaml` file. You focus on business logic in your Steps; iii handles the rest.



---

### Prerequisites

- **iii** — Install the runtime: `curl -fsSL https://install.iii.dev/iii/main/install.sh | sh`
- **Node.js 18+** — Required for TypeScript/JavaScript Steps
- **Python 3** — Optional, for Python Steps

---

## Get Started

<Cards>
  <Card title="Quick Start" href="/docs/getting-started/quick-start">
    Clone the example project and run your first flow in under 2 minutes.
  </Card>
  <Card title="Core Concepts" href="/docs/concepts/overview">
    Understand Steps, triggers, and the event-driven architecture.
  </Card>
  <Card title="Why Motia?" href="/docs/why-motia">
    Learn why Motia exists and what problems it solves.
  </Card>
  <Card title="Examples" href="/docs/examples">
    Explore real-world examples covering APIs, AI agents, workflows, and more.
  </Card>
</Cards>


-   ['ChessArena AI'](/docs/product-showcase/chessarena-ai): Documentation for 'ChessArena AI'.
---
title: 'ChessArena AI'
---

In the world of AI development, chess serves as the perfect benchmark for intelligence and strategic thinking. But how do you measure which AI models truly "understand" chess beyond simple win/loss statistics? ChessArena.AI solves this challenge by focusing on move quality and game insight rather than just outcomes.

This comprehensive guide explores how to build a production-ready chess platform using Motia's event-driven architecture and real-time streaming capabilities. We'll cover:

1. **Real-Time Chess Streaming**: How Motia Streams enable live game updates across all connected players
2. **Multi-Language Architecture**: Combining TypeScript orchestration with Python chess engine integration
3. **AI Model Integration**: Supporting multiple LLM providers (OpenAI, Anthropic Claude, Google Gemini, xAI Grok) for chess gameplay
4. **Move Evaluation System**: Using Stockfish engine for real-time move analysis and scoring
5. **Production Deployment**: How this exact platform powers the live ChessArena.AI website

Let's build a chess platform that measures AI intelligence through gameplay quality.

---

## 🏭 Production-Grade Chess Platform

**This is not a tutorial project** - this is battle-tested, production-ready code that handles real traffic at scale. Every aspect has been designed for enterprise use:

- **🎮 Live Chess Platform**: Real-time games with multiple AI models competing simultaneously
- **📊 Move Quality Analysis**: Every move evaluated by Stockfish engine for strategic insight
- **⚡ Real-Time Updates**: Live game state synchronization across all connected clients
- **🤖 Multi-AI Support**: OpenAI GPT, Anthropic Claude, XAI Grok, Google Gemini integration
- **🏆 Dynamic Leaderboards**: Real-time scoring based on move quality, not just wins
- **🌍 Global Scale**: Production deployment on Motia Cloud with worldwide accessibility
- **💰 Cost Efficient**: Event-driven architecture that scales efficiently

---

## Live Proof: Powering ChessArena.AI

**This isn't just a demo** - this exact code powers the live chess platform at [ChessArena.AI](https://chessarena.ai)!

Visit the platform and you'll see:
- **🏆 Live AI Leaderboard** ranking models by move quality
- **⚡ Real-Time Games** with instant move updates and evaluations
- **📊 Move Analysis** showing centipawn scores and blunder detection
- **🎮 Multi-Model Battles** with GPT-5, Claude Opus 4, Gemini 2.5 Flash, and Grok 4 competing

That live chess platform with real-time AI battles? That's this exact implementation in production, processing thousands of moves and providing instant feedback to chess enthusiasts worldwide!

---

## The Power of Strategic AI Evaluation

<div className="my-8">![ChessArena AI](./../img/chessarena.png)</div>

At its core, ChessArena.AI solves a fundamental challenge: how do you measure AI intelligence in chess beyond simple win/loss statistics? Traditional chess platforms focus on game outcomes, but most LLM games end in draws, making it difficult to distinguish between models.

Our Motia-powered solution revolutionizes AI chess evaluation through:

- **[Stockfish Integration](https://stockfishchess.org/)**: World's strongest open-source chess engine for move analysis
- **[Centipawn Scoring](https://en.wikipedia.org/wiki/Chess_piece_relative_value#Centipawns)**: Precise move quality measurement in hundredths of a pawn
- **[Real-Time Streaming](https://motia.dev)**: Live game updates and move evaluations
- **[Multi-LLM Support](https://platform.openai.com/)**: Support for OpenAI, Anthropic, and Google AI models

Instead of focusing on who wins, we measure how well each AI model understands chess strategy and tactics.

---

## The Anatomy of Our Chess Platform

Our application consists of specialized components handling different aspects of chess gameplay, from game creation to move evaluation. Let's explore the complete architecture.

<Folder name="api/steps" defaultOpen>
  <Folder name="chess" defaultOpen>
    <File name="00-available-models-api.step.ts" />
    <File name="01-create-game.step.ts" />
    <File name="02-get-game.step.ts" />
    <File name="03-move-api.step.ts" />
    <File name="04-chess-game-moved.step.ts" />
    <File name="05-ai-player.step.ts" />
    <File name="evaluate_player_move_step.py" />
    <Folder name="streams" defaultOpen>
      <File name="00-chess-game.stream.ts" />
      <File name="00-chess-game-move.stream.ts" />
      <File name="00-chess-leaderboard.stream.ts" />
    </Folder>
  </Folder>
  <Folder name="auth" defaultOpen>
    <File name="00-auth-api.step.ts" />
    <File name="01-get-user-api.step.ts" />
  </Folder>
</Folder>

<Tabs items={['models-api', 'create-game', 'move-evaluation', 'ai-player', 'streams', 'auth']}>
  <Tab value="models-api">
    The entry point that exposes available AI models from different providers (OpenAI, Anthropic, Google, xAI) for chess gameplay. The platform supports cutting-edge models and allows easy extension for new providers.

    ```typescript
    import { AiModelsSchema } from '@chessarena/types/ai-models'
    import { type Handlers, type StepConfig } from 'motia'
    import { z } from 'zod'
    import { supportedModelsByProvider } from '../../services/ai/models'

    export const supportedModelsByProvider: AiModels = {
      openai: [
        'gpt-5-2025-08-07',           // Latest GPT-5
        'o4-mini-2025-04-16',         // O4 Mini
        'gpt-4.1-nano-2025-04-14',   // GPT-4.1 Nano
        'o3-mini-2025-01-31',        // O3 Mini
        'gpt-4o-mini-2024-07-18',    // GPT-4o Mini
      ],
      gemini: [
        'gemini-2.5-flash',          // Latest Gemini 2.5 Flash
        'gemini-2.0-flash-001',      // Gemini 2.0 Flash
      ],
      claude: [
        'claude-opus-4-1-20250805',  // Claude Opus 4.1
        'claude-opus-4-20250514',    // Claude Opus 4
        'claude-sonnet-4-20250514',  // Claude Sonnet 4
        'claude-3-7-sonnet-20250219', // Claude 3.7 Sonnet
        'claude-3-5-sonnet-20241022', // Claude 3.5 Sonnet
        'claude-3-5-haiku-20241022',  // Claude 3.5 Haiku
      ],
      grok: [
        'grok-4',                     // Latest Grok 4
        'grok-3',                     // Grok 3
      ],
    }

    export const config = {
      name: 'AvailableModels',
      description: 'Expose all available AI models for supported providers',
      triggers: [{ type: 'http', path: '/chess/models', method: 'GET' }],
      enqueues: [],
      flows: ['chess'],
      responseSchema: {
        200: z.object({ models: AiModelsSchema() }),
        404: z.object({ message: z.string() }),
        400: z.object({ message: z.string() }),
      },
    } as const satisfies StepConfig

    export const handler: Handlers<typeof config> = async (_, { logger }) => {
      logger.info('Received available models request')

      return {
        status: 200,
        body: {
          models: supportedModelsByProvider,
        },
      }
    }
    ```

  </Tab>
  <Tab value="create-game">
    The game creation endpoint that validates AI model selections and initializes new chess games with proper player configurations.

    ```typescript
    import { AiModelProviderSchema } from '@chessarena/types/ai-models'
    import { GameSchema, Player } from '@chessarena/types/game'
    import { type Handlers, type StepConfig } from 'motia'
    import { RefinementCtx, z } from 'zod'
    import { supportedModelsByProvider } from '../../services/ai/models'
    import { createGame } from '../../services/chess/create-game'
    import { auth } from '../middlewares/auth.middleware'

    const playerSchema = () => {
      return z
        .object({
          ai: AiModelProviderSchema().optional(),
          model: z.string().optional(),
        })
        .superRefine((data: Player, ctx: RefinementCtx) => {
          if (data.ai && !data.model) {
            ctx.addIssue({
              code: z.ZodIssueCode.custom,
              path: ['model'],
              message: 'Model is required when AI is enabled',
            })
          }

          if (data.ai) {
            const isValidAiProvider = data.ai in supportedModelsByProvider
            const isValidModel = data.model && supportedModelsByProvider[data.ai]?.includes(data.model)

            if (!isValidAiProvider || !isValidModel) {
              ctx.addIssue({
                code: z.ZodIssueCode.custom,
                path: data.ai ? ['model'] : ['ai'],
                message: data.ai ? 'Invalid AI model' : 'Invalid AI provider',
              })
            }
          }
        })
    }

    export const config = {
      name: 'CreateGame',
      description: 'Create a new chess game',
      triggers: [{ type: 'http', path: '/chess/create-game', method: 'POST' }],
      enqueues: ['chess-game-created'],
      flows: ['chess'],
      bodySchema: z.object({
        players: z.object({
          white: playerSchema(),
          black: playerSchema(),
        }),
      }),
      middleware: [auth({ required: true })],
      responseSchema: {
        200: GameSchema,
        400: z.object({ message: z.string(), errors: z.array(z.object({ message: z.string() })) }),
        401: z.object({ message: z.string() }),
      },
    } as const satisfies StepConfig

    export const handler: Handlers<typeof config> = async (req, { logger, enqueue, streams }) => {
      logger.info('[CreateGame] Creating new chess game')

      const game = await createGame(req.body.players, req.user, streams, logger)

      await enqueue({
        topic: 'chess-game-created',
        data: { gameId: game.id, fenBefore: game.fen },
      })

      logger.info('[CreateGame] Game created successfully', { gameId: game.id })

      return { status: 200, body: game }
    }
    ```

  </Tab>
  <Tab value="move-evaluation">
    The Python-powered move evaluation system that uses Stockfish to analyze every move and calculate centipawn scores for strategic insight.

    ```python
    import chess
    import chess.engine
    import os
    from pydantic import BaseModel, Field

    class EvaluatePlayerMoveInput(BaseModel):
        fenBefore: str = Field(description="The FEN of the game before the move")
        fenAfter: str = Field(description="The FEN of the game after the move")
        gameId: str = Field(description="The ID of the game")
        moveId: str = Field(description="The ID of the move")
        player: str = Field(description="The player who made the move")

    config = {
        "name": "EvaluatePlayerMove",
        "description": "Evaluates move quality using Stockfish engine",
        "triggers": [{"type": "queue", "topic": "evaluate-player-move"}],
        "enqueues": [],
        "flows": ["chess"],
        "input": EvaluatePlayerMoveInput.model_json_schema(),
    }

    class Evaluation(BaseModel):
        centipawn_score: int = Field(description="The evaluation in centipawns")
        best_move: str = Field(description="The best move")

    async def evaluate_position(
        engine: chess.engine.SimpleEngine,
        board: chess.Board,
        player: str,
        time_limit: float = 1.5
    ) -> Evaluation:
        """Evaluate a chess position and return analysis results."""
        analysis = await engine.analyse(
            board, 
            chess.engine.Limit(time=time_limit),
            info=chess.engine.INFO_ALL
        )
        
        score = analysis["score"]
        centipawn_score = score.white().score() if player == "white" else score.black().score()
        move = analysis.get("pv", [None])[0]

        return Evaluation(
            centipawn_score=centipawn_score if centipawn_score is not None else 0,
            best_move=move.uci() if move is not None else None
        )

    async def handler(input: EvaluatePlayerMoveInput, ctx):
        logger = ctx.logger
        
        # Initialize Stockfish engine
        engine_path = os.getenv("STOCKFISH_BIN_PATH")
        if not engine_path:
            raise EnvironmentError("STOCKFISH_BIN_PATH environment variable not set")
        
        _, engine = await chess.engine.popen_uci(engine_path)
        
        try:
            # Create boards from the positions
            board_before = chess.Board(input.fenBefore)
            board_after = chess.Board(input.fenAfter)
        
            # Evaluate positions
            eval_before = await evaluate_position(engine, board_before, input.player)
            eval_after = await evaluate_position(engine, board_after, input.player)

            # Calculate best move evaluation
            best_move = chess.Move.from_uci(eval_before.best_move)
            board_before.push(best_move)
            eval_best_move = await evaluate_position(engine, board_before, input.player)

            # Calculate move quality metrics
            evaluation_swing = max(0, eval_best_move.centipawn_score - eval_after.centipawn_score)
            blunder = evaluation_swing > 100  # Moves losing >100 centipawns are blunders

            evaluation = {
                "centipawnScore": eval_after.centipawn_score,
                "bestMove": eval_after.best_move,
                "evaluationSwing": evaluation_swing,
                "blunder": blunder,
            }

            # Update move in streams with evaluation
            move_stream = await ctx.streams.chessGameMove.get(input.gameId, input.moveId)
            move_stream["evaluation"] = evaluation
            await ctx.streams.chessGameMove.set(input.gameId, input.moveId, move_stream)

            logger.info("Move evaluation completed", { "evaluation": evaluation })

        finally:
            await engine.quit()
    ```

  </Tab>
  <Tab value="ai-player">
    The AI orchestration step that coordinates with different LLM providers using a unified prompt system. Features retry logic, move validation, and real-time thought streaming.

    ```typescript
    import { type Handlers, type StepConfig } from 'motia'
    import { z } from 'zod'
    import { makePrompt } from '../../services/ai/make-prompt'
    import { evaluateBestMoves } from '../../services/chess/evaluate-best-moves'
    import { move } from '../../services/chess/move'
    import mustache from 'mustache'

    const MAX_ATTEMPTS = 3

    const responseSchema = z.object({
      thought: z.string({
        description: 'The thought process of the move, make it look like you were just thinking for yourself'
      }),
      move: z.object({
        from: z.string({ description: 'The square to move from, example: e2' }),
        to: z.string({ description: 'The square to move to, example: e4' }),
        promote: z.enum(['queen', 'rook', 'bishop', 'knight']).optional(),
      }),
    })

    export const config = {
      name: 'AI_Player',
      description: 'AI Player with unified provider system and retry logic',
      triggers: [{ type: 'queue', topic: 'ai-move' }],
      enqueues: ['chess-game-moved', 'chess-game-ended', 'evaluate-player-move'],
      flows: ['chess'],
      includeFiles: ['05-ai-player.mustache'],
    } as const satisfies StepConfig

    export const handler: Handlers<typeof config> = async (input, { logger, enqueue, streams }) => {
      const game = await streams.chessGame.get('game', input.gameId)
      const player = input.player === 'white' ? game.players.white : game.players.black

      if (!player.ai) {
        logger.error('Player has no AI configured', { gameId: input.gameId })
        return
      }

      let attempts = 0
      let lastInvalidMove = undefined
      const validMoves = evaluateBestMoves(game)

      while (attempts < MAX_ATTEMPTS) {
        const messageId = crypto.randomUUID()

        // Create real-time thinking message
        await streams.chessGameMessage.set(input.gameId, messageId, {
          id: messageId,
          message: 'Thinking...',
          sender: player.ai,
          role: input.player,
          timestamp: Date.now(),
        })

        // Generate prompt using Mustache template
        const prompt = mustache.render(template, {
          fenBefore: input.fenBefore,
          fen: input.fen,
          lastMove: input.lastMove,
          inCheck: input.check,
          player: input.player,
          lastInvalidMove,
          validMoves,
        })

        let action: z.infer<typeof responseSchema> | undefined
        try {
          action = await makePrompt({
            prompt,
            zod: responseSchema,
            provider: player.ai,  // 'openai', 'claude', 'gemini', or 'grok'
            logger,
            model: player.model!, // Specific model like 'gpt-5-2025-08-07'
          })

          // Update message with AI's thought process
          await streams.chessGameMessage.set(input.gameId, messageId, {
            message: action.thought,
            move: action.move,
            sender: player.ai,
            role: input.player,
            timestamp: Date.now(),
          })

          // Execute the chess move
          await move({
            logger,
            streams,
            gameId: input.gameId,
            player: input.player,
            game,
            action: action.move,
            enqueue,
            illegalMoveAttempts: attempts,
          })

          return // Success!

        } catch (err) {
          attempts++
          lastInvalidMove = action?.move
          
          // Handle illegal moves with retry logic
          if (attempts >= MAX_ATTEMPTS) {
            // Player loses after too many illegal moves
            await streams.chessGame.set('game', game.id, {
              ...game,
              status: 'completed',
              winner: input.player === 'white' ? 'black' : 'white',
              endGameReason: 'Too many illegal moves',
            })
            
            await enqueue({
              topic: 'chess-game-ended',
              data: { gameId: input.gameId },
            })
          }
        }
      }
    }
    ```

  </Tab>
  <Tab value="streams">
    The real-time data streams that power live chess gameplay, storing game state, moves, and leaderboard data with automatic client synchronization.

    ```typescript
    // Chess Game Stream - stores complete game state
    import { StreamConfig } from 'motia'
    import { GameSchema } from '@chessarena/types/game'

    export const config: StreamConfig = {
      name: 'chessGame',
      schema: GameSchema,
      baseConfig: { storageType: 'default' },
    }
    ```

    ```typescript
    // Chess Game Move Stream - stores individual moves with evaluations
    import { StreamConfig } from 'motia'
    import { GameMoveSchema } from '@chessarena/types/game-move'

    export const config: StreamConfig = {
      name: 'chessGameMove',
      schema: GameMoveSchema,
      baseConfig: { storageType: 'default' },
    }
    ```

    ```typescript
    // Chess Leaderboard Stream - live AI model rankings
    import { StreamConfig } from 'motia'
    import { LeaderboardSchema } from '@chessarena/types/leaderboard'

    export const config: StreamConfig = {
      name: 'chessLeaderboard',
      schema: LeaderboardSchema,
      baseConfig: { storageType: 'default' },
    }
    ```

  </Tab>
  <Tab value="auth">
    The authentication system that manages user sessions and provides secure access to chess game creation and management.

    ```typescript
    import { type Handlers, type StepConfig } from 'motia'
    import { z } from 'zod'
    import { authenticateUser } from '../../services/auth/auth-service'

    export const config = {
      name: 'AuthAPI',
      description: 'Handle user authentication for chess platform',
      triggers: [{ type: 'http', path: '/auth/login', method: 'POST' }],
      enqueues: ['user-authenticated'],
      flows: ['auth'],
      bodySchema: z.object({
        email: z.string().email(),
        password: z.string().min(6),
      }),
      responseSchema: {
        200: z.object({
          token: z.string(),
          user: z.object({ id: z.string(), email: z.string() })
        }),
        401: z.object({ message: z.string() }),
      },
    } as const satisfies StepConfig

    export const handler: Handlers<typeof config> = async (req, { logger, enqueue }) => {
      const { email, password } = req.body

      try {
        const authResult = await authenticateUser(email, password)
        
        if (!authResult.success) {
          return { status: 401, body: { message: 'Invalid credentials' } }
        }

        await enqueue({
          topic: 'user-authenticated',
          data: { userId: authResult.user.id },
        })

        return {
          status: 200,
          body: {
            token: authResult.token,
            user: authResult.user,
          },
        }
      } catch (error) {
        logger.error('[AuthAPI] Authentication error', { error: error.message })
        return { status: 401, body: { message: 'Authentication failed' } }
      }
    }
    ```

  </Tab>
</Tabs>

---

## Extensible AI Provider System

ChessArena.AI features a plugin-based architecture that makes adding new AI providers incredibly simple. The unified `makePrompt` system handles all provider differences behind a clean interface.

### Adding New AI Providers

To add a new AI provider (like Anthropic's upcoming models or other LLM providers), you only need to:

1. **Create a provider handler** in `services/ai/your-provider.ts`:

```typescript
import { Handler } from './types'

export const yourProvider: Handler = async ({ prompt, zod, logger, model }) => {
  // Initialize your AI client
  const client = new YourAIClient({ apiKey: process.env.YOUR_API_KEY })
  
  // Make the API call with structured output
  const response = await client.chat({
    model: model ?? 'your-default-model',
    messages: [{ role: 'user', content: prompt }],
    responseFormat: { type: 'json_schema', schema: zodToJsonSchema(zod) },
  })
  
  logger.info('Your provider response received', { model })
  
  return JSON.parse(response.content)
}
```

2. **Register the provider** in `services/ai/make-prompt.ts`:

```typescript
import { yourProvider } from './your-provider'

const providers: Record<AiModelProvider, Handler> = {
  openai,
  gemini,
  claude,
  grok,
  yourProvider, // Add your provider here
}
```

3. **Update the type definitions** in `types/ai-models.ts`:

```typescript
export const AiModelProviderSchema = () => 
  z.enum(['openai', 'gemini', 'claude', 'grok', 'yourProvider'])
```

4. **Add supported models** in `services/ai/models.ts`:

```typescript
export const supportedModelsByProvider: AiModels = {
  // ... existing providers
  yourProvider: [
    'your-model-v1',
    'your-model-v2-turbo',
    'your-model-reasoning',
  ],
}
```

That's it! Your new AI provider is now fully integrated and can compete in chess battles alongside GPT, Claude, Gemini, and Grok.

### Current Provider Implementations

The platform currently supports four major AI providers with their latest models:

- **OpenAI**: GPT-5, O4 Mini, GPT-4.1 series, O3 Mini
- **Anthropic**: Claude Opus 4.1, Claude Sonnet 4, Claude 3.7 series  
- **Google**: Gemini 2.5 Flash, Gemini 2.0 Flash
- **xAI**: Grok 4, Grok 3

Each provider uses optimized API calls with structured JSON output and proper error handling.

---

## Real-Time Chess Architecture

The beauty of this chess platform lies in its event-driven, real-time architecture. Here's how live chess games flow through the system:

1. **Game Creation** → User selects AI models and creates a new game
2. **Move Generation** → AI models generate moves using LLM APIs
3. **Move Validation** → Chess rules validation and board state updates
4. **Stockfish Analysis** → Real-time move evaluation and scoring
5. **Stream Updates** → Live game state propagated to all connected clients
6. **Leaderboard Updates** → AI model rankings updated based on move quality

**No manual state management, no complex WebSocket handling, no synchronization code required!**

---

## Key Features & Benefits

### 🎮 **Real-Time Chess Gameplay**
Live games with instant move updates across all connected clients - watch AI models battle in real-time.

### 🏆 **Intelligent Scoring System**  
Move quality evaluation using Stockfish engine with centipawn precision and blunder detection.

### 🤖 **Multi-AI Integration**
Support for OpenAI GPT, Anthropic Claude, and Google Gemini models with unified API interface.

### ⚡ **Event-Driven Architecture**
Scalable, maintainable system where each component handles specific chess functionality.

### 📊 **Live Leaderboards**
Real-time AI model rankings based on move quality, strategic insight, and game performance.

### 🌐 **Production-Ready**
Battle-tested code powering the live ChessArena.AI platform with global accessibility.

---

## Trying It Out

Ready to build your own AI chess platform? Let's get it running.

<Steps>

### Clone and Install

Start by getting the project locally and installing dependencies.

```shell
git clone https://github.com/MotiaDev/chessarena-ai.git
cd chessarena-ai
pnpm install
```

### Install Stockfish Engine

The platform requires Stockfish for move evaluation. Choose your installation method:

**Option A: Using Homebrew (macOS - Recommended)**
```shell
brew install stockfish
```

**Option B: Using the project installer**
```shell
pnpm install-stockfish <platform>
# Supported: linux-x86, mac-m1
```

**Option C: Manual Installation**
Download from [stockfishchess.org](https://stockfishchess.org/)

### Configure Environment Variables

Create a `.env` file with your AI provider API keys:

```shell
# Required: AI Model API Keys
OPENAI_API_KEY="sk-..."
ANTHROPIC_API_KEY="sk-ant-..."
GOOGLE_AI_API_KEY="..."

# Required: Stockfish Engine Path
STOCKFISH_BIN_PATH="/opt/homebrew/bin/stockfish"

# Optional: Authentication (for user management)
JWT_SECRET="your-jwt-secret"
```

### Start the Chess Platform

Launch both the API backend and React frontend:

```shell
pnpm dev
```

This starts:
- **API Backend**: `http://localhost:3000` (Motia API with chess logic)
- **React Frontend**: `http://localhost:5173` (Chess game interface)

### Create Your First AI Battle

1. **Open the Chess Platform**: Navigate to `http://localhost:5173`
2. **Select AI Models**: Choose different models for white and black players
3. **Start the Game**: Watch AI models battle with real-time move evaluation
4. **View Analysis**: See centipawn scores, best moves, and blunder detection
5. **Check Leaderboards**: Monitor AI model performance rankings

### Access Real-Time Data

Your chess games are available via the Motia streams API:

```shell
# Get all active games
curl http://localhost:3000/api/streams/chessGame

# Get specific game state
curl http://localhost:3000/api/streams/chessGame/{gameId}

# Get move history with evaluations
curl http://localhost:3000/api/streams/chessGameMove/{gameId}

# Get AI model leaderboard
curl http://localhost:3000/api/streams/chessLeaderboard
```

### Deploy to Production

Once your chess platform is working locally, deploy it to production with Motia Cloud:

**Option 1: CLI Deployment**
```shell
# Deploy with version and API key
motia cloud deploy --api-key your-api-key --version-name 1.0.0

# Deploy with environment variables
motia cloud deploy --api-key your-api-key \
  --version-name 1.0.0 \
  --env-file .env.production \
  --environment-id your-env-id
```

**Option 2: One-Click Web Deployment**
1. Ensure your local project is running (`pnpm dev`)
2. Go to [Motia Cloud](https://motia.cloud) and import your project
3. Select your local project port
4. Choose project and environment name
5. Upload environment variables (optional)
6. Click **Deploy** and watch the magic happen! ✨

</Steps>

---

## 🚀 Production Deployment Guide

### Environment Variables

Configure these environment variables for production security and functionality:

```shell
# Required: AI Model API Keys
OPENAI_API_KEY="sk-your-openai-key"          # For GPT-5, O4 Mini, GPT-4.1 series
ANTHROPIC_API_KEY="sk-ant-your-anthropic-key" # For Claude Opus 4.1, Sonnet 4
GEMINI_API_KEY="your-google-gemini-key"      # For Gemini 2.5 Flash, 2.0 Flash  
XAI_API_KEY="your-xai-grok-key"              # For Grok 4, Grok 3

# Required: Stockfish Engine Path
STOCKFISH_BIN_PATH="/opt/homebrew/bin/stockfish"

# Optional: Authentication for user management
JWT_SECRET="your-secure-jwt-secret"

# Optional: Database configuration for user data
DATABASE_URL="postgresql://user:password@host:port/database"
```

### Security Best Practices

For production deployments, ensure you:

1. **Secure API keys**: 
   ```shell
   # Generate a cryptographically secure JWT secret
   openssl rand -hex 32
   ```

2. **Store secrets securely**: Use environment variables, never commit API keys to code

3. **Monitor AI usage**: Track API usage and costs across different model providers

4. **Enable rate limiting**: Implement request limits to prevent abuse

### Scaling Considerations

This architecture scales automatically with your chess platform traffic:

- **Multiple games**: Each game gets its own stream for real-time updates
- **High concurrency**: Motia streams handle thousands of concurrent chess games
- **Global distribution**: Deploy to multiple regions for worldwide performance
- **AI model optimization**: Load balance across different model providers
- **Cost optimization**: Pay only for actual usage with serverless scaling

---

## 💻 Dive into the Code

Want to explore the complete chess platform implementation? Check out the full source code with AI integration, real-time streams, and production deployment:

<div className="not-prose">
  <div className="bg-gradient-to-r from-amber-50 to-orange-50 border border-amber-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-amber-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Live ChessArena.AI Platform</h3>
        <p className="text-gray-600 mb-4">Access the complete implementation powering the live chess platform. See exactly how AI models battle with real-time evaluation and scoring!</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/chessarena-ai" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-amber-600 hover:bg-amber-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.30 3.297-1.30.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            View ChessArena.AI Code
          </a>
          <a 
            href="https://chessarena.ai" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            Play Live Chess →
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Conclusion: Intelligence Through Strategic Play

This ChessArena.AI platform demonstrates how to build sophisticated AI evaluation systems using event-driven architecture. By focusing on move quality rather than simple win/loss statistics, we've created a platform that truly measures AI strategic understanding.

The beauty of this approach is its extensibility:
- **Add new AI models**: Integrate any LLM provider with the unified interface
- **Enhanced analysis**: Implement opening book analysis, endgame evaluation
- **Tournament modes**: Multi-round competitions with advanced scoring
- **Educational features**: Move explanations, tactical puzzles, learning modes

Key architectural benefits:
- **Real-time synchronization**: All clients see live game updates automatically
- **Scalable evaluation**: Stockfish analysis runs independently of game flow
- **Multi-language power**: TypeScript orchestration with Python chess engine integration
- **Production reliability**: Battle-tested code handling real user traffic

This exact implementation powers the live chess platform at [ChessArena.AI](https://chessarena.ai) - that real-time AI battle system with move-by-move evaluation? It's this code in action, proven at scale with thousands of chess enthusiasts worldwide.

**Production Metrics:**
- Handles 1,000+ concurrent chess games
- Processes 10,000+ moves daily with real-time evaluation
- Sub-100ms move analysis and streaming updates
- 99.9% uptime with automatic scaling

Ready to build AI evaluation platforms that measure true intelligence? Deploy production-ready chess systems with Motia today!


-   [Product Showcase](/docs/product-showcase): Documentation for Product Showcase.
---
title: Product Showcase
---

Explore full-scale production applications built with Motia that demonstrate the framework's capabilities in real-world scenarios.

<Cards>
  <Card
    title="ChessArena AI"
    href="/docs/product-showcase/chessarena-ai"
    description="Production-grade chess platform with real-time AI battles, move evaluation, and live leaderboards"
  />
</Cards>

<br/>

## 💻 Live Applications

These are not just examples or tutorials - they are fully functional, production-ready applications that handle real user traffic and demonstrate Motia's capabilities at scale.

<div className="not-prose">
  <div className="bg-gradient-to-r from-green-50 to-blue-50 border border-green-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-green-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Production-Ready Applications</h3>
        <p className="text-gray-600 mb-4">These applications demonstrate Motia's enterprise capabilities with real user traffic, production deployments, and battle-tested architectures.</p>
        <div className="grid grid-cols-1 sm:grid-cols-2 gap-3">
          <a 
            href="https://chessarena.ai" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center justify-center px-4 py-2 bg-green-600 hover:bg-green-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            🏆 Live Chess Platform
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center justify-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            📚 Source Code →
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

## Contribute

Have you built something amazing with Motia? We'd love to feature your production application! Please [reach out to us](mailto:hello@motia.dev) with details about your project.


-   [video-showcase](/docs/video-showcase): Documentation for video-showcase.
---
title: Video Showcase
description: Watch Motia in action through our video demonstrations and tutorials
---

# Video Showcase

Explore Motia's capabilities through our collection of demonstration videos and tutorials. These videos showcase real-world examples, feature walkthroughs, and development workflows.

## Featured Videos

- [Next.js Background Jobs Are Easy Now](https://youtu.be/7KZS0syLrUo?si=iahtz0Gta3gTD4km) - Next.js Background Jobs with Motia by Web Dev Simplified
- [The Only Backend For Next.js You Need (Motia)](https://youtu.be/70jKtCdy6eQ?si=IVabS265wVZW_PTf) - Motia unified backend Framework
- [Add AI To Next.js With AI SDK & AI Elements (Shadcn UI) - Tutorial](https://www.youtube.com/watch?v=nX7MlUhupig&t=28s) - Complete tutorial on integrating AI into Next.js applications
- [Tanstack Start + Motia Backend Framework](https://www.youtube.com/watch?v=VhRhGrOt-48&t=1s) - Tanstack Start + Motia Backend Framework

## Other Videos

- [The only AI framework you'll ever need](https://www.youtube.com/watch?v=6EFTemC99AM) - Motia's tutorial for LinkedIn and Twitter Automation on Typefully
- [Motia Framework Tutorial](https://www.youtube.com/watch?v=JECQtMSBJyY) - You have never seen a DX (Developer Experience) like this | Motia

## Adding More Videos

To add more videos to this showcase, simply edit this file and add new video objects to the `videos` array. Each video should have:

- `id`: A unique identifier for the video
- `title`: The display title for the video
- `description`: A brief description of what the video covers
- `url`: The YouTube URL (supports various formats)

```typescript
{
  id: "your-video-id",
  title: "Your Video Title",
  description: "Brief description of the video content",
  url: "https://youtu.be/YOUR_VIDEO_ID"
}
```


-   [why-motia](/docs/why-motia): Documentation for why-motia.
---
title: Why Motia?
description: "Learn why Motia exists — a unified backend framework that replaces juggling separate systems for APIs, queues, workflows, and more."
---

<video controls className="mb-8 w-full rounded-xl" poster="https://assets.motia.dev/images/gifs/v1/1-motia-welcome.gif">
  <source src="https://assets.motia.dev/videos/mp4/site/v1/1-motia-welcome.mp4" type="video/mp4" />
</video>

## Why Motia?

**Build production-grade backends with a single primitive.**

Modern backends shouldn't require juggling frameworks, queues, and services. Motia unifies everything: API endpoints, background jobs, durable workflows, AI agents, streaming, and observability into one runtime with a single core primitive.

**Motia** is your complete backend solution:
- 🌐 **API** - RESTful endpoints with validation and routing
- ⚡ **Background Jobs** - Async processing with built-in queues
- 🔄 **Durable Workflows** - Complex multi-step orchestration
- 🤖 **Agentic** - AI agent workflows with streaming support
- 🏪 **State** - Built-in persistent storage across Steps
- 📊 **Streaming** - Real-time data updates to clients
- 📝 **Logging** - Structured, traceable logs
- 👁️ **Observability** - End-to-end tracing and monitoring

Just as React made frontend development simple by introducing components, **Motia redefines backend development with Steps** - a single primitive that powers everything.

To read more about this, check out our [manifesto](/manifesto).

---

## The Core Primitive: the Step

At the heart of Motia is a single primitive: the **Step** — a file with a `config` and a `handler`. Motia auto-discovers these files and connects them automatically.

Learn more about Steps: [What is a Step?](/docs/concepts/steps)

---

## Working with Multiple Languages

The rapid advancement of AI has reshaped the software industry — many cutting-edge AI tools are available only in specific programming languages, forcing companies to choose between changing their team's skillset or not leveraging these technologies at all.

Motia removes this limitation by allowing each Step to be written in any language, while still sharing a common state.

![Multi-language](./img/what-is-motia/multi-language.png)

_Each rectangle in the diagram above represents a Step, some of them are in TypeScript and others in Python._

Learn more: [Multi-language Support](/docs/concepts/overview#multi-language-support)

---

## Scalability

One of the biggest dilemmas in backend development is choosing between scalability and development velocity. In startup environments, speed often takes priority, resulting in systems that don't scale well and become problematic under increased load.

Motia addresses scalability by leveraging the core primitive of **Steps**: Each step can scale independently avoiding the bottlenecks common in monolithic architectures.

![Scalable](./img/what-is-motia/scalable.png)

---

## Observability

Observability in traditional backends often demands significant engineering effort to implement logging, alerting, and tracing. Typically, these tools are only configured for cloud environments, local development is generally neglected — leading to low productivity and poor dev experience.

Motia offers a complete observability toolkit available in both cloud and local environments.

Learn more: [Observability](/docs/development-guide/observability)

---

## Fault Tolerance

With the rise of AI, many backend tasks have become less deterministic and more error-prone. These scenarios require robust error handling and retry mechanisms. In traditional systems, developers often need to set up and maintain queue infrastructures to ensure resilience, especially when dealing with unreliable responses from LLMs.

Motia provides fault tolerance out of the box, eliminating the need to manually spin up queue infrastructure.

- Using queue triggers, you get retry mechanisms out of the box
- Queue infrastructure configuration is handled by the iii engine through `config.yaml`

---

## Building and Shipping

Building and deploying backends is inherently complex — especially in polyglot environments. Shipping production systems requires tight collaboration between developers and operations, and automation often takes weeks to get right.

Beyond that, cloud provider lock-in, complicated deployment strategies (e.g., rollbacks, blue/green deployments), and a lack of deployment tooling increase the risk of failure.

Motia abstracts these concerns by providing:

- True cloud-provider agnosticism
- Atomic blue/green deployments and one-click rollbacks via Motia Cloud (canary support coming soon)
- First-class polyglot backend support (currently Node.js and Python, with more on the way)

![Deployments](./img/what-is-motia/deployments.png)

_The image above shows several Steps being built to a single Motia deployable that are ultimately deployed to a cloud provider of your choice.
Currently we're supporting AWS and Kubernetes, more Cloud providers coming soon. Check our [roadmap](https://github.com/orgs/MotiaDev/projects/2/views/4?filterQuery=title%3A+BYOC) for more details._

### Rollbacks and Deployment Strategies

Deploying cloud-native, fault-tolerant applications often involves modifying queue systems and other infrastructure components.
These changes can introduce incompatibilities and lead to runtime failures.

Motia Cloud solves this with **Atomic Deployments**, which:

- Each deployment spins up a new isolated service that shares the same data layer
- Ensures safe, rollback-capable deployments without risking service downtime
- Instant rollbacks with one click since each deployment is isolated

---

## Real-time Data Streaming

Handling real-time data is one of the most common — and complex — challenges in backend development. It's necessary when building event-driven applications, and it typically requires setting up and maintaining a significant amount of infrastructure.

Motia provides what we call _Streams_: Developers define the structure of the data — any changes to these objects are streamed to all subscribed clients in real-time.

![Real-time data streaming](./img/what-is-motia/streams.png)

_The image above shows a Stream definition, a Node.js Step mutating the data and a client subscribing to the stream receiving real-time updates._

Learn more: [Streams](/docs/development-guide/streams)



## Optional
-   [https://motiadev.com](https://motiadev.com): Main page for framework.
-   [Github repo](https://github.com/motiadev/motia): Main github repository to file issues.
